<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="By 18069" />


<title>Homework</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Homework</h1>
<h4 class="author"><em>By 18069</em></h4>



<div id="question" class="section level2">
<h2>Question</h2>
<p>Write a .Rmd file to implement at least three examples of different types in the above books (texts, numerical results, tables, and figures).</p>
</div>
<div id="answer" class="section level2">
<h2>Answer</h2>
<div id="example-1" class="section level3">
<h3>Example 1</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">patientID &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)
age &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">25</span>,<span class="dv">34</span>,<span class="dv">28</span>,<span class="dv">52</span>)
diabetes &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Type1&quot;</span>,<span class="st">&quot;Type2&quot;</span>,<span class="st">&quot;Type1&quot;</span>,<span class="st">&quot;Type1&quot;</span>)
status &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Poor&quot;</span>,<span class="st">&quot;Improved&quot;</span>,<span class="st">&quot;Excellent&quot;</span>,<span class="st">&quot;Poor&quot;</span>)
patientdata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(patientID,age,diabetes,status)
patientdata</code></pre></div>
<pre><code>##   patientID age diabetes    status
## 1         1  25    Type1      Poor
## 2         2  34    Type2  Improved
## 3         3  28    Type1 Excellent
## 4         4  52    Type1      Poor</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(patientdata<span class="op">$</span>diabetes,patientdata<span class="op">$</span>status)</code></pre></div>
<pre><code>##        
##         Excellent Improved Poor
##   Type1         1        0    2
##   Type2         0        1    0</code></pre>
</div>
<div id="example-2" class="section level3">
<h3>Example 2</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mpg &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">39.4</span>,<span class="fl">36.4</span>,<span class="fl">33.8</span>,<span class="fl">31.5</span>,<span class="fl">29.6</span>,<span class="fl">27.8</span>,<span class="fl">26.3</span>,<span class="fl">24.9</span>)
wt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1897</span>,<span class="dv">1665</span>,<span class="dv">1559</span>,<span class="dv">1550</span>,<span class="dv">1490</span>,<span class="dv">1500</span>,<span class="dv">1480</span>,<span class="dv">1380</span>)
<span class="kw">lm</span>(mpg<span class="op">~</span>wt)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt)
## 
## Coefficients:
## (Intercept)           wt  
##   -15.66600      0.02995</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmfit &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg<span class="op">~</span>wt)
<span class="kw">summary</span>(lmfit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.36284 -1.53461 -0.06501  1.10441  2.77096 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -15.666005   7.716671  -2.030 0.088645 .  
## wt            0.029952   0.004909   6.102 0.000883 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.035 on 6 degrees of freedom
## Multiple R-squared:  0.8612, Adjusted R-squared:  0.8381 
## F-statistic: 37.23 on 1 and 6 DF,  p-value: 0.0008831</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lmfit)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --><img src="data:image/png;base64,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" /><!-- --><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAhFBMVEUAAAAAADoAAGYAOjoAOpAAZrY6AAA6ADo6AGY6Ojo6OpA6kLY6kNtmAABmADpmZgBmZmZmkJBmtrZmtv+QOgCQOjqQZgCQkGaQtpCQtv+Q2/+2AAC2ZgC2kDq2tma225C2/7a2///bkDrbtmbb/7bb////AAD/tmb/25D//7b//9v///90t3dLAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAMmklEQVR4nO2dCXvjthGGaceWN6m0TZZuunXZpsvEoo7///8KDA4SPDQAiEvUfM9jW5YJgXw9OGYwBKsr6aaq3CdQuggQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChIgAISJAiAgQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChIgAISJAiAgQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChIgAISJAiAgQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChKgiQrcFgCpDuU+pLBEPRD2g82F/bavq5TPn6ZSnHlDz8nnavV6b15ynU540oPOhvnYV+3r+kfWESpMBqGFwWgJkaNDEXs+Hl8/zgZqYoWEnXT19XN6Jjyka5hERIEQCEGteWpE7aahqtg4+TJhq8ElZV8+UC6nUFsRnEuzKnz6mf/IBFBcOV2pAYh46OxaUDkg1s6hNzCDDHJuK/9qwn7W8WP7eXh3QA+rU22aZ0475Rn8BJHnE+fDtAJ8WSoar0b6yKuP+S7pKE2pZO+MOIDcq8bqGn6edIqQB8YYJM7S5MgBWHXE+sHfbuRbsqcFMen/t2Am1kb1V/k8HI+UVQsVfP67wf2EXKt7T3o4CdHmHt58+5srAl3lEyP+y4WqcvvyAr8i6vFdgKP1VdBUYQN3Bv17/RQESb7Dvc2XEmasjwJxC9kwaEP8f8H9MAkBMzOs7vcl2wLqV5z+ENXRyqjELiP19rswAENhgLEDgpTb7yE1MmQAzFfUSfsrm0j31AFiXu2hBwzKpLAhGYDaSxZ0nqlGMdTOqP4EeR/Sx9ejKFvugYZlxHxQPUBJ1ELLs+IjMxxoGTBgCe0ONYv00cn4UM8vsx6NYLEDa20jhaggCck7T8t8b+c9vh2fQiDPaT+dBqgw7ZDwPimxBFFAcadLEKCZtagKITMjUBBDFpE2NAVFMeqTJKEYLh6Yo5IooMKDqbuQGKFhMulh77NR1STaOgMRHSHdmzXmUCqh5+i6iFNXgy0qDcIcYvtZ586UCusowjji/ygeQ8l/WTRTLB3Q8egISAQNkJYG7isBxaTpZNqDjkePxBCRXrG7Gu0WYnDfF+wN03P2bw/Hvg+RQdst+hJFd3nlo/74AMctRoWT/UQyX6qb4AtH9AJLtahRrjwJIdVPX5vVOAKlOZ6oogHTDWg5drwfUBYtpLsLhcp5J761Crq1ckLm8RwAEvQNvCe36gMKy6ajK7M9q9cl41TtfVBRfuTSHwlG1WakYQFX/fYUFWcHpq7M50C+RPHwnrQGddr7uoC2cvjqbA4MkkrtHEaYf0X+H1ARHWZuOUZ3NgWETye0BtcBzsH41mN82bstarnBUbXYHhk0kt6m3t7POaM/wPn/LyYI84EBl1geGTSS3qLe3lFkQrVp3tZCP6QzOwu7AsInkeL1hRqtVcPrTsDnQyRdDA7MugFz74sEQsA5OfxpWtTp86uIE2qHeHlDnFrtUTXOl6RinYXOgEe54+Wz2Nw6eT991rFf3Qbermv3kMHD0x1kd2AfMnj5a3knfPO0OybB1GMUu/3BqYRXACTbv9wu5tjdCYYHrdemCjkdtORkBQX4XA1RW0L5H4xYoReVvQRY3kISoF9dx3OGscWQm8u6D2nVp/EEu4ThhE17eQfuVSfxW9d649gRohEqOBy0SSMQG5L9w6FedQ7jjuGRC6ehc1yw9R64XjGQWRVI+Xp10iMUErN7j4PvcX5LJx4IS5AcdRz+nf0mlMjvp4+SF+j01nzIBHWdfTn5LogIBGVZyNKI7QU/BTuUBGtnMwLPKwac8QCMKlUpkytD9XFXVdgemATSmoAHlweORvBA3DXiCQQHKxaesNOC5VlQds/IpKg14wfOqqkzdD8jfFwseUVz23VfUs1r+3nzoiOIihqx8IqUBe9SbF8OyvCOKfvazFA/K24xuqYx5ULF4CgFUMJ9YS89O9ZbMJ9rSs0O9RfOJtfTMU9D4DkmLQ90gQcX2DPIoztIz8OFb+CxG+CvxmVXheCItPUPzE1mwSw6JDPMcQ6/RB1eUped+o55FO6tUDKN0QnGWnmHvOcyC+hSykhVnHnQ+PP8AE1oMingDCpq6YVOf9YF9J603z7pxuNyFbTERrxp8uShs8o9lhXYHDhYOAU2AcIe7NaRvlj6AvvFNLNNkmI0R3geg+vJe7S0BrbvbZ9Kg7gQQvw/g5U8fC3K722cGx130QWKrxgSbm8zZyz2MYrX4kQdQakWKB7Fe6vbamWcflF5xALVqL+yuWgiKeI5i6eW8smpzW/ggjfGWs3oXimJBgyDHDWf1PhQF0ANbkGXygo6FrO2D8itS8gK62eKGAW19D7ORCkpeKFPlJC8UqmKSF0pV4uQF93pzq4i1+ZLl3wf5Vbd+95fE8h/FEtWbWz6ddIrboYqR16rGlrdLHos6aUQECJEHoCCP8NsyoCCP8NswoDCP8Ns0oBCP8NswoDCP8NswoDCP8NsyoCCP8Ns0oKT15hYBQhRn2efGp2w/3LHtR9dMRMs+iGjZBxEt+yCKtOwTKIGqAMVZ9gmWQJVflP6CyAMQ2nwePYGqQYevx7Ygm5tVHzqBymrhkBKoktWbW97zoFT15lbsldU7eQDbshLHgx4i3JG23tyilVVEkVZWH9lZtVlZfWhn1WJl1cbVuBs5A7JYWbVwVt3lYXPuRVYYtsvKqoUFeZxAiiJBAFmsrOLOqscJpCgSBpCFUGfV4wRSFAkBSD2LKFzvYnkCKYqEBLTu6VAeJ5CiyHpATT/+BetdLE8gRZGQFpRadwMol+4F0Gm3h+2TVj4danuSgMBH5THFlWnA25PqpHlAGhZ+vB6GvWHprSlU2D71PKh0KUC1WhkjQKYGgET3E84N3YYGfRBkvoRZHtuQJKDu6YM/TN1mhf7BpOZBHbjopx01sJGyz6RLFwDyi9Y+hogHIgKEKF+bapVnbO8iqyIi8ms5HxF5zd5+eN8F+ZReIR65hPse+De7GyB0EdhX31IdBNDtKxmr55IWk/b+xFqSjYvcO4wO7hA8LMShkonGRJKaEr9a6eDYXjIAau2vtH35HeZ3TpUMNcKRtqVx50Y0F2ubAH+o+dk2ds4+nfdBjpUMZQBJi6eDixQ9g2X/IIpIp8iCEG9aHJBTJaYGSNIPZ5f3l0/Hc+dFxCsbe1APCgkDKEPuCjtlV+vXV2kRHIbPDtrE3MuvE7tI1/5Tc7EY61vpPDlXMlCuibQ45U4+p8NqBNZF9Aurmpqww3wy6fO2n8PpImKJwXIJuAk1UUwtvtoNraW19gJ0Ef3CphD06vaVjES+KiIChIgAISJAiAgQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChIgAISJAiAgQIgKEiAAhIkCICBAiAoSIACEiQIgIECIChIgAIcqXvKBSU+BWrE5+mVpINwjzKDRLZc3u0OKXPHPZBEiJAE2lAbHLPe30nimtyl/l+Sr/BEAyX4q9llkvrIS8h7S+6gLwGRHAFQGotyBIDOa38PMb+zqR0iNugmTHq9sih4BUAX1fe2iVBUjfVyysphFNjOcWsr/A5hn8DwNAukC0e5Fzj2K1AahTbUpcr+yD+r/wRGkDkC5wPkQiVJYFdWrsb4eAeE5iI/qn5z9MC9IFxA6Gm++D9LBlWBD77X8HuWvGqImZ41wTYeeRsgDpAVwmNssLPh9+5X02h9apJraXLWtoNDHG/1IA7UUHLe5VYd/4i04npjb87jlhPBU/suZ3JLBGVesC+taz0CoDECPARnE1D4Lm1c+DrvqZHzyVt+F3+AOp6puaBwnTirO3DzmriAgQIgKEiAAhIkCICBAiAoQoE6DpnPfyvmoW3NWRtsosBpDDvfBLn9fF2PyoFEAr3SgovtII55UP0Gn3jbkLex4qrYX7brxzevu+k9HXZuh19BK7VFS1jC2tfhT8vHIC4j4p96Ngs3jwRgfvMEy1vPw++mqqBd8Ntv8QBrghZxUA7eUWshC26H/Zy9vFufUwBkb0lYfF+H3w/+K/QBz/V3bE24cAFGOf1ZyA1N6NKq5jvKPXMozYWScalGhKPC709fsXHo8WgGweIueqQgAZv4h33uRuEmb01VCzP/3y19cPeFrBxgHNWJAC1C0Dal/+83pt/vZePwKg/aSJwWYJqg+afUDu6cvf99f2p7eP6+b7IDmKGYAg6HprFGOfAsewHkmuj21sFBsCEvMgA9Bvu36fhef/zi57NVAKTG1j86CJJjPpUXOxWTmNktRQCqCJL9Zvg7OrLbvfLfliU40dqd6CuspuzXRT3vz9iAAh+j8Jr4zDNtIS/wAAAABJRU5ErkJggg==" /><!-- --><img src="data:image/png;base64,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" /><!-- --></p>
</div>
</div>
<div id="question-1" class="section level2">
<h2>Question 1</h2>
<p>A discrete random variable <span class="math inline">\(X\)</span> has probability mass function</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(p(x)\)</span></td>
<td>0.1</td>
<td>0.2</td>
<td>0.2</td>
<td>0.2</td>
<td>0.3</td>
</tr>
</tbody>
</table>
<p>Use the inverse transform method to generate a random sample of size 1000 from the distribution of <span class="math inline">\(X\)</span>. Construct a relative frequency table and compare the empirical with the theoretical probabilities. Repeat using the R sample function.</p>
</div>
<div id="answer-1" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)
p &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">3</span>)
cp &lt;-<span class="st"> </span><span class="kw">cumsum</span>(p)
m &lt;-<span class="st"> </span><span class="dv">1000</span>
r &lt;-<span class="st"> </span><span class="kw">numeric</span>(m);
<span class="co">#find all indexes of x we want under the condition we design: F(x[i-1])&lt;u&lt;=F(x[i])??then x=x[i]</span>
r &lt;-<span class="st"> </span>x[<span class="kw">findInterval</span>(<span class="kw">runif</span>(m),cp)<span class="op">+</span><span class="dv">1</span>]
ct &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">table</span>(r))
ct</code></pre></div>
<pre><code>## [1] 122 193 198 194 293</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#caculate the probabilty in the random sample we generate</span>
tp &lt;-<span class="st"> </span>ct<span class="op">/</span><span class="kw">sum</span>(ct)
ratio &lt;-<span class="st"> </span>tp<span class="op">/</span>p
<span class="kw">data.frame</span>(x,p,tp,ratio)</code></pre></div>
<pre><code>##   x   p    tp     ratio
## 1 0 0.1 0.122 1.2200000
## 2 1 0.2 0.193 0.9650000
## 3 2 0.2 0.198 0.9900000
## 4 3 0.2 0.194 0.9700000
## 5 4 0.3 0.293 0.9766667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># #the relative frequency table comparing the empirical with the theoretical probabilities.</span></code></pre></div>
<p>Next we repeat using the R sample function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
r2 &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),m,<span class="dt">replace=</span><span class="ot">TRUE</span>,<span class="dt">prob=</span><span class="kw">c</span>(.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">3</span>))
ct2 &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">table</span>(r2))
tp2 &lt;-<span class="st"> </span>ct2<span class="op">/</span><span class="kw">sum</span>(ct2)
ratio &lt;-<span class="st"> </span>tp2<span class="op">/</span>p
<span class="kw">data.frame</span>(x,p,tp2,ratio)</code></pre></div>
<pre><code>##   x   p   tp2 ratio
## 1 0 0.1 0.120 1.200
## 2 1 0.2 0.182 0.910
## 3 2 0.2 0.191 0.955
## 4 3 0.2 0.216 1.080
## 5 4 0.3 0.291 0.970</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#R sample function</span></code></pre></div>
</div>
<div id="question-2" class="section level2">
<h2>Question 2</h2>
<p>Write a function to generate a random sample of size n from the <span class="math inline">\(Beta(a, b)\)</span> distribution by the acceptance-rejection method. Generate a random sample of size 1000 from the <span class="math inline">\(Beta(3,2)\)</span> distribution. Graph the histogram of the sample with the theoretical <span class="math inline">\(Beta(3,2)\)</span> density superimposed.</p>
</div>
<div id="answer-2" class="section level2">
<h2>Answer</h2>
<p><span class="math inline">\(Beta(3,2)\)</span> with pdf <span class="math inline">\(f(x)=12x^2(1-x),~0&lt;x&lt;1\)</span>. Let <span class="math inline">\(c=12\)</span> and <span class="math inline">\(g(x)=x,~0&lt;x&lt;1\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
j&lt;-k&lt;-<span class="dv">0</span>
y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
<span class="cf">while</span> (k <span class="op">&lt;</span><span class="st"> </span>n) 
  {
    u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>)
    j &lt;-<span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
    x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>) <span class="co">#random variate from g</span>
    <span class="cf">if</span> (x<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x) <span class="op">&gt;</span><span class="st"> </span>u) 
      {
        <span class="co">#we accept x</span>
        k &lt;-<span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
        y[k] &lt;-<span class="st"> </span>x
      }
   }
j</code></pre></div>
<pre><code>## [1] 12066</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># #(experiments) for n random numbers</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(y, <span class="dt">prob =</span> <span class="ot">TRUE</span>, <span class="dt">main =</span> <span class="kw">expression</span>(<span class="kw">f</span>(x)<span class="op">==</span><span class="dv">12</span><span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x)))
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">001</span>)
<span class="kw">lines</span>(x, <span class="dv">12</span><span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAk1BMVEUAAAAAADoAAGYAOmYAOpAAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZrY6kNtmAABmADpmOgBmOjpmOmZmZmZmkLZmtttmtv+QOgCQOjqQZgCQkGaQkLaQtv+Q27aQ2/+2ZgC2kGa2kJC227a22/+2///bkDrbtpDb////AAD/tmb/tpD/25D/27b//7b//9v///+xikSPAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAKeElEQVR4nO2da2ObNhSGyZqkuyZduy7pbvW2lsaea/P/f90QAlsCpFeXAxzs835ooiIdwRPdJQ5FJfKqWPoGuEsAAQkgIAEEJICABBCQAAISQEACCEgAAQkgIAEEJICABBCQAAISQEACCEgAAQkgIAEEJICABBCQAAISQEACCEgAAQkgoJUB2t8XxdOsOa4L0OHxqdrdfJwzy3UB2t2+VMfnWYvQugApqVI0o2YDdPznz9Pv/71/STdU3r4MDPqUldl8gL6++2SE9u8+pxoqv/k8YtCnjMyq6QEdfm66ncNbu2Xdf+u56a4SfX1bFDc/2X//sm2izwZxlfNmhjQ1oE39jB/rhvWh9/9dRRlRzbR5ZNWl13plPl1Xfs4Gu9g+eTKDmhjQ8bl5onLQNe/v+8g6fWmHOsfn4te6FD0XRsT969bOyeCXkIGROzOsyQGpP97hcfAnbMkNE3woXv3ePPLh8a46/9DaNGXq6WTwHBvcxXhmIZoW0E49z139406H1I+NfqDN+HMd3rx/2ZmXFCAr4dnSSGwza5xZiGYBtGmribrP7tnK4s6d6skMPNgJtaGH8diGAjNDmqOK1a2JfobD4zf/PralfVc4W07zkff3uo6eEzZWjRguQIGZIc0B6PDYPUNZfNf9uiv0zetmpSlonYxH3t/r1thIWFWGwcoNaCyzBM0LqP7Tdxw893x+5LJ49amfsAoFFJYZ0ryA6t+6Ow0AVD9hVzOMhJULUL8shmWGNGsbVD/DL93td82Cu4odjSGQkbAKbIPGMkvQLOOgrtPZNT2afh7ci/W6dbOrDunFAjNDmgVQ29seVKeiuyV1z86hiX7kdqZR1LXDSqhjjDbppkIzQ5pzJK3/nmXz1/cNbvUj74oTIDNhI3No7gAUmhnSPMsdMXOxRIM+MZ6LtTo+99uAnAn2qEGfGM/mOw3Wg37IWcQaMehTVmZzrSgeP5gPFL4cGGjQp7zM5luT/ttYk/4jq34NDfqUmdn6djVmlgACEkBAAghIAAEJICABBCSAgAQQkAACEkBAAghIAAEJICABBCSAgAQQkAACEkBAAghIAAEJICABBCSAgAQQkAACEkBA6wW0bTVxNisFdCYzNaQVAioUksJQNSWiFQLq01CMLGKkua0OUI2i9z+F/u+tFSbTGgCZ1UkVlf5l/eNE6AoBnX5rIDgAnQhdMSCNwAWoI3S9gBwAegXsegG5qpARHq2CJJmzlr5HZy9lhhWhKwW0tYP9y52uFtDWDvYvn7W9TkBbO9i/bGg4kMzOnL0Kiw8ANJiJZGfOX4X9yABQdX2AtpGASAnRAJpoJq01mL33M++HSQkRP9EEgAatLgREWsnYA9oO+u0AQISEuAMaGRpjQJRFiD2godEAQISEOAIy18dGWn4BBNYvQgDREWINaHwBSACdAY0aDQJERogzIMcqfCAgIkKMAbm2KSAgs33PHtyfkh8e013IjJjLN+Lc6AorQa7yl3YzjcqadpbHkYoWkMtoICBHC5Z2M52yGdEBci8hLglII0p3tkMHaJsPqCLZJrOS7xo/oNopEoG5DCNWH8QEUN1Kt67Qdgv7a+rPNpMBUewjGr0YhTN9IkBbEkAVLaA3mk9G8cm/m9aIf401AhDBRusAUOkDdHzu/K4hc1n35F9jDQc0tlgSfTP6x+a8wuDp5k9+6HauWCSAwCL0IoDOJcgjw/G6y20aBaDBLCodEMFOdExyw72+q6UiAOQ4Y+fOgw+geUrQcHOdAaDD44MaBvkbYMPj54Rt0HAXIwdQ/lmGuOQdRedQOxvQ2AGfFQGa3pzvlKYjDz+g3MMe5lTjQU1V81yI5gLyHmN15OEP0wHa3L7s7++qTdCymWs4mQ1ozAgPQM23zdSXFlKmGlSHF9Ax1pDLfUCZa9MWoE0NxzvVCDeXJHjON+RyP0wFqK5byo219aWYHHMpwud8Ay5PBqjuwm8+xvlp9plLkGuZPQ9Qf+obKUbdvPNtlNUAOg223ePtLEAuI0wAwbWeEOf5GYACT4rHA8prhYxGOqD7gk1UOqAtd0BqII3l/AxK31zUPVg7xcPBFBdAFJ8vTQNUxRyljweURehkLbeD75mLTOTbB2MCCNaeSHNxiWLeNVgIUMiCWYS5uERRR+njAeUQ4jBQBPtgAgjsg7EBVFey25dN3gmhJEBgm4cAUAYho5G++Viq2fzs54PQPhgTQGpPR23mzL8ehPbBmABSA0UFaPbDC3CbhwmgrgRtslbt4wHhfTAKQOmE+m1QxtcAbXOBCtgH4wJIDxUzT1HFAxpJxBUQhWLNheyDkQBKJrQsIODOZTy8ECA9F8vbV40HNJqIJaD2m7Zl5ln7OEBh+2AsAO26xnl/P18vFuDvZiycGD2RkE5urJaF7c37zQUqcJuHAyBjBjbfVCN0m4cHIHj6MMZckNx+/YgBGf7zEs5X0ACKPN1h3S/cxSAqQYlv/yxSglSsYI9JVwrI87oTT0Bw1z3GHI4Vs81DBSjt9ahFphqF920eARTrUur6AEW6lLo6QNEupaiip7xgtwCgBJdSRNHXAojuiSOjrwNQkkspmuirAJTmc4soesIbiHMDGluEFkBnpbuUIonOHlCGSymS6NwBOdZY5wOU8IrmnICSPSbRRWcNKNdjEkV0zoDcJ8UvCFCia4r+EutygOJf8o2KnuqaoiByCEQQfVJAyY4FyPzd5EefFFCyawoyfzf50XmWIDp3LvnRY9+CjmyDUlxTkHoryY4+KaAk1xTEzjh4A4o3t6V2xnERgE7jne5rjf5MLxGQ3zWF/vf8fU9OgGJPedCUoN4Yuf1EbMFSiwC6YAkgIOLJ6uWJeLJ6eSKearRGWWs6QMHHrJBRcD3vcm7yjOjhJSgv09UCCpishhm9WEB4shpm9HIBERkVQHnXBZAAyrsugK4e0CVJAAEJICABBCSAgAQQkAACEkBAAghIAAEJICABBCSAgCgB7UwHVrtob1b9FJHe1Kzk6mOfFN6NSQEpDzInLzJWID65Csc5M7KSlypAQ4gOkN4Uap3HWIH45FXrFzQ597vI3N2iA6Q9D7UHh6xAfHL12+1vMYCs5EwBvVblu91ytQLxyZtgVBtkJ2dZxXQD0DYDViA+eVNjogD1MozvIlxiCijaJ6idXH3hYX9PcgKFZxVrAulVLL4FdItnI122J1XCWxEreXz5dYttNx9ZgqzkmlaeJ6ROfAeKkSNpKznLNqipGOoO9SikjO5HrORV9FTDSr4pvN9kjpBMVoEEEJAAAhJAQAIISAABCSAgAQQkgIAEEJAAAhJAQAIISAABCSAgAQQkgIAEEJAAAhJAQAIISAABCSAgAQQkgIAEEJAAAhJAQAIISAABcQfUHIkqSQ70pok7IHVM7PhM81ZBkrgDUl6v9AHNhcQdkKpjfndXE4s9oLqObZZ0ucce0OHNX28WrGH8AR2fv1+yhvEHlP2F90zxB7RoH7YKQD8uWcNWAKhc1m0sd0D7+0WbaP6AFpcAAhJAQAIISAABCSAgAQQkgIAEEJAAAhJAQAIISAABCSAgAQQkgIAEEJAAAhJAQAIISAAB/Q/NaBT3yLE8hwAAAABJRU5ErkJggg==" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># #Histogram of the sample with the theoretical $Beta(3,2)$ density superimposed,which shows that the random sample generated fits the theoretical model $Beta(3,2)$ well. </span></code></pre></div>
</div>
<div id="question-3" class="section level2">
<h2>Question 3</h2>
<p>Simulate a continuous Exponential-Gamma mixture. Suppose that the rate parameter <span class="math inline">\(??\)</span> has <span class="math inline">\(Gamma(r, b)\)</span> distribution and <span class="math inline">\(Y\)</span> has <span class="math inline">\(Exp(??)\)</span> distribution. That is, <span class="math inline">\((Y |?? = ??) ?? fY (y|??) = ??e^{-??y}\)</span>. Generate 1000 random observations from this mixture with <span class="math inline">\(r = 4\)</span> and <span class="math inline">\(b = 2\)</span>.</p>
</div>
<div id="answer-3" class="section level2">
<h2>Answer</h2>
<ul>
<li>Exponential-gamma distribution
<ul>
<li>Suppose <span class="math inline">\(X|\Lambda\sim\)</span>Exponential(<span class="math inline">\(\Lambda\)</span>), and <span class="math inline">\(\Lambda\sim\)</span>Gamma(<span class="math inline">\(r,b\)</span>). Then the marginal distribution of <span class="math inline">\(X\)</span> is generalized Pareto distribution with parameter <span class="math inline">\(\xi=1/r\)</span> and <span class="math inline">\(\beta=b/r)\)</span>.</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(evir)</code></pre></div>
<pre><code>## Warning: 程辑包'evir'是用R版本3.5.2 来建造的</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>; r &lt;-<span class="st"> </span><span class="dv">4</span>; b &lt;-<span class="st"> </span><span class="dv">2</span>
lambda &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n, r, b) <span class="co">#lambda is random</span>
<span class="co">#generate the mixture  </span>
x &lt;-<span class="st"> </span><span class="kw">rexp</span>(n, lambda)
<span class="co">#compare the mixture with the GPD</span>
<span class="kw">hist</span>(x,<span class="dt">prob=</span><span class="ot">TRUE</span>,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Density of GPD(0.25,0,0.5)&quot;</span>)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, .<span class="dv">001</span>)
<span class="kw">lines</span>(y,<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>y)<span class="op">^</span>(<span class="op">-</span><span class="dv">5</span>),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>) <span class="co">#the density function of generalized Pareto distribution:1/2^4*(1/2+1/4*x)^(-5)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># #The figure above shows that the random model generated is good especially when x extends to right further.</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#the theoretical model: generalized Pareto distribution</span>
y1 &lt;-<span class="st"> </span><span class="kw">rgpd</span>(n,<span class="dt">xi=</span><span class="dv">1</span><span class="op">/</span>r,<span class="dt">mu=</span><span class="dv">0</span>,<span class="dt">beta=</span>b<span class="op">/</span>r)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(x,<span class="dt">main=</span><span class="st">&quot;Histogram of Simulation&quot;</span>,<span class="dt">col=</span><span class="st">&quot;pink&quot;</span>)
<span class="kw">hist</span>(y1,<span class="dt">main=</span><span class="st">&quot;Histogram of GPD&quot;</span>,<span class="dt">col=</span><span class="st">&quot;light green&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># #The comparing histograms shows that the simulation is good.</span></code></pre></div>
</div>
<div id="question-1-1" class="section level2">
<h2>Question 1</h2>
<p>Write a function to compute a Monte Carlo estimate of the <span class="math inline">\(Beta\)</span>(3, 3) cdf,and use the function to estimate <span class="math inline">\(F(x)\)</span> for <span class="math inline">\(x = 0.1, 0.2, . . . , 0.9\)</span>. Compare the estimates with the values returned by the <span class="math inline">\(pbeta\)</span> function in R.</p>
</div>
<div id="answer-4" class="section level2">
<h2>Answer</h2>
<p><span class="math display">\[Beta(a,b):B(a,b)=\int_0^1x^{a-1}(1-x)^{b-1}dx=E[g(X)]\]</span></p>
<p><span class="math display">\[g(x)=(1-0)x^{a-1}(1-x)^{b-1}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MCofBeta &lt;-<span class="st"> </span><span class="cf">function</span>(n,t,a,b){
  x &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dv">0</span>, t)    <span class="co">#generate random x</span>
  theta.hat &lt;-<span class="st"> </span><span class="kw">mean</span>(x<span class="op">^</span>(a<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(b<span class="op">-</span><span class="dv">1</span>))<span class="op">*</span>t
}
<span class="kw">print</span>(<span class="kw">c</span>(<span class="kw">MCofBeta</span>(<span class="fl">1e4</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">3</span>),<span class="kw">beta</span>(<span class="dv">3</span>,<span class="dv">3</span>)))   <span class="co">#compare the MC estimation and the theoretical value</span></code></pre></div>
<pre><code>## [1] 0.03295538 0.03333333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##the result shows that the MC estimate works well</code></pre></div>
<p><span class="math display">\[F(x;a,b)=\frac{B(x;a,b)}{B(a,b)}\]</span> <span class="math display">\[B(x;a,b)=\int_0^tx^{a-1}(1-x)^{b-1}dx,B(a,b)=\int_0^1x^{a-1}(1-x)^{b-1}dx\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>y &lt;-<span class="st"> </span>ratio&lt;-<span class="kw">c</span>(.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">3</span>,.<span class="dv">4</span>,.<span class="dv">5</span>,.<span class="dv">6</span>,.<span class="dv">7</span>,.<span class="dv">8</span>,.<span class="dv">9</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>){
  F[i] &lt;-<span class="st"> </span><span class="kw">MCofBeta</span>(<span class="fl">1e4</span>,x[i],<span class="dv">3</span>,<span class="dv">3</span>)<span class="op">/</span><span class="kw">MCofBeta</span>(<span class="fl">1e4</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">3</span>)  <span class="co">#generate F(x) based on estimation B(x;a,b)</span>
  y[i]&lt;-<span class="kw">pbeta</span>(x[i],<span class="dv">3</span>,<span class="dv">3</span>)      <span class="co">#theretical value</span>
  ratio[i] &lt;-<span class="st"> </span>F[i]<span class="op">/</span>y[i]
}
  <span class="kw">data.frame</span>(F,y,ratio)     <span class="co">#compare</span></code></pre></div>
<pre><code>##             F       y     ratio
## 1 0.008653961 0.00856 1.0109768
## 2 0.058798832 0.05792 1.0151732
## 3 0.165073570 0.16308 1.0122245
## 4 0.313431052 0.31744 0.9873710
## 5 0.504825609 0.50000 1.0096512
## 6 0.686506256 0.68256 1.0057816
## 7 0.839889462 0.83692 1.0035481
## 8 0.940439111 0.94208 0.9982582
## 9 0.996510184 0.99144 1.0051140</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##figure above shows that the MC estimate works well,the ratio is almost equal to 1.</code></pre></div>
</div>
<div id="question-2-1" class="section level2">
<h2>Question 2</h2>
<p>The Rayleigh density <span class="math inline">\([156, (18.76)]\)</span> is <span class="math display">\[f(x) = \frac{x}{\sigma^2}e^{-x^2/(2\sigma^2)}, x\geq0, \sigma &gt; 0.\]</span> Implement a function to generate samples from a <span class="math inline">\(Rayleigh(\sigma)\)</span> distribution,using antithetic variables. What is the percent reduction in variance of <span class="math inline">\(\frac{X+ X`}2\)</span> compared with <span class="math inline">\(\frac{X_1+ X_2}2\)</span> for independent <span class="math inline">\(X_1, X_2\)</span>?</p>
</div>
<div id="answer-5" class="section level2">
<h2>Answer</h2>
<p>Implement the function MC.R to generate samples from <span class="math inline">\(Rayleigh(\sigma)\)</span> distribution<span class="math display">\[\theta=E_U(\frac{x^2U}{\sigma^2}e^{-(Ux)^2/(2\sigma^2)})\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MC.R &lt;-<span class="st"> </span><span class="cf">function</span>(x,sigma,n,antithetic) {
n &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
u &lt;-<span class="st"> </span><span class="kw">runif</span>(n<span class="op">/</span><span class="dv">2</span>)       <span class="co">#generate random u ~ U(0,1)</span>

<span class="cf">if</span> (<span class="op">!</span>antithetic) 
  v &lt;-<span class="st"> </span><span class="kw">runif</span>(n<span class="op">/</span><span class="dv">2</span>)     <span class="co">#if not antithentic then generate the other half of n from U(0,1)</span>
<span class="cf">else</span>
  v &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>u          <span class="co">#if antithentic then generate the other half of n as 1-u</span>
u &lt;-<span class="st"> </span><span class="kw">c</span>(u, v)          <span class="co">#combine the whole u </span>

cdf &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">length</span>(x))
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x)) {
  g &lt;-<span class="st"> </span>x[i]<span class="op">^</span><span class="dv">2</span><span class="op">*</span>u<span class="op">/</span>(sigma<span class="op">^</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>(u <span class="op">*</span>x[i])<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sigma<span class="op">^</span><span class="dv">2</span>))  <span class="co">#the estimate of x multipling density of Rayleigh for each x</span>
  cdf[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(g)   <span class="co">#the estimate of cdf</span>
}
cdf
}</code></pre></div>
<p>The cdf of Rayleigh distribution:<span class="math inline">\(F(x;\sigma)=1-e^{-x^2/{2\sigma^2}},x\geq0\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
sigma &lt;-<span class="st"> </span><span class="dv">1</span>;n &lt;-<span class="st"> </span><span class="fl">1e4</span>
x &lt;-<span class="st"> </span>R &lt;-<span class="st"> </span><span class="kw">seq</span>(.<span class="dv">1</span>, <span class="fl">2.5</span>,<span class="dt">length=</span><span class="dv">5</span>) <span class="co">#value the x</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x))
  R[i] &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>x[i]<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sigma<span class="op">^</span><span class="dv">2</span>))   <span class="co">#The theoretical cdf of Rayleigh</span>

  MC1 &lt;-<span class="st"> </span><span class="kw">MC.R</span>(x,sigma,n,<span class="dt">antithetic =</span> <span class="ot">FALSE</span>)  <span class="co">#(x1+x2)/2 with independent x1,x2</span>
  MC2 &lt;-<span class="st"> </span><span class="kw">MC.R</span>(x,sigma,n,<span class="dt">antithetic =</span> <span class="ot">TRUE</span>)   <span class="co">#(x+x`)/2 with negatively correlated x,x`</span>
  
<span class="kw">print</span>(<span class="kw">round</span>(<span class="kw">rbind</span>(x, MC1, MC2, R), <span class="dv">5</span>))</code></pre></div>
<pre><code>##        [,1]    [,2]    [,3]    [,4]    [,5]
## x   0.10000 0.70000 1.30000 1.90000 2.50000
## MC1 0.00501 0.21842 0.57370 0.84038 0.96047
## MC2 0.00499 0.21730 0.57045 0.83556 0.95611
## R   0.00499 0.21730 0.57044 0.83553 0.95606</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##compare the estimate with or without antithetic variables and the theoretical value,which shows that both MC1 and MC2 fit well while MC2 fits better.</code></pre></div>
<p>Next compare the variance and calculate the percent of reduction from MC1 to MC2</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
m &lt;-<span class="st"> </span><span class="fl">1e2</span>;sigma &lt;-<span class="st"> </span><span class="dv">1</span>;x &lt;-<span class="st"> </span><span class="dv">6</span>;n &lt;-<span class="st"> </span><span class="fl">1e4</span>
MC1 &lt;-<span class="st"> </span>MC2 &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {
MC1[i] &lt;-<span class="st"> </span><span class="kw">MC.R</span>(x,sigma,n,<span class="dt">antithetic =</span> <span class="ot">FALSE</span>)
MC2[i] &lt;-<span class="st"> </span><span class="kw">MC.R</span>(x,sigma,n,<span class="dt">antithetic =</span> <span class="ot">TRUE</span>)
}
var1 &lt;-<span class="st"> </span><span class="kw">var</span>(MC1)
var2 &lt;-<span class="st"> </span><span class="kw">var</span>(MC2)
ratio &lt;-<span class="st"> </span>(var1<span class="op">-</span>var2)<span class="op">/</span>var1   <span class="co">#the percent of reduction</span>
<span class="kw">print</span>(<span class="kw">c</span>(var1,var2,ratio))</code></pre></div>
<pre><code>## [1] 8.902540e-05 2.951537e-05 6.684613e-01</code></pre>
</div>
<div id="question-3-1" class="section level2">
<h2>Question 3</h2>
<p>Find two importance functions f1 and f2 that are supported on <span class="math inline">\((1, \infty)\)</span> and are ‘close’ to <span class="math display">\[g(x) = \frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}, x &gt; 1.\]</span> Which of your two importance functions should produce the smaller variance in estimating <span class="math display">\[\int_1^{\infty}\frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}dx\]</span> by importance sampling? Explain.</p>
</div>
<div id="answer-6" class="section level2">
<h2>Answer</h2>
<p><span class="math display">\[g(x) = \frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}, x &gt; 1.\]</span> <span class="math display">\[f_1(x)=\frac1{x^2},x&gt;1;f_2(x)=\frac{x}{\sqrt{2\pi}}e^{(1-x^2)/4},x&gt;1\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">7</span>,.<span class="dv">01</span>)
w&lt;-<span class="dv">2</span>
g &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi) 
f1 &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(x<span class="op">^</span><span class="dv">2</span>)
f2 &lt;-<span class="st"> </span>x<span class="op">*</span><span class="kw">exp</span>((<span class="dv">1</span><span class="op">-</span>x<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)
gs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">expression</span>(<span class="kw">g</span>(x)<span class="op">==</span>e<span class="op">^</span>{<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>}<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)),<span class="kw">expression</span>(f[<span class="dv">1</span>](x)<span class="op">==</span><span class="dv">1</span><span class="op">/</span>(x<span class="op">^</span><span class="dv">2</span>)),<span class="kw">expression</span>(f[<span class="dv">2</span>](x)<span class="op">==</span>x<span class="op">*</span>e<span class="op">^</span>{(<span class="dv">1</span><span class="op">-</span>x<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>}<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)))
    <span class="co">#for color change lty to col</span>
    <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
    <span class="co">#figure (a)</span>
    <span class="kw">plot</span>(x, g, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>),<span class="dt">lwd =</span> w,<span class="dt">col=</span><span class="dv">1</span>,<span class="dt">main=</span><span class="st">'(A)'</span>)
    <span class="kw">lines</span>(x, f1, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> w,<span class="dt">col=</span><span class="dv">2</span>)
    <span class="kw">lines</span>(x, f2, <span class="dt">lty =</span> <span class="dv">3</span>, <span class="dt">lwd =</span> w,<span class="dt">col=</span><span class="dv">3</span>)
    <span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span> gs,
           <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">lwd =</span> w, <span class="dt">inset =</span> <span class="fl">0.02</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)

    <span class="co">#figure (b)</span>
   <span class="kw">plot</span>(x, g<span class="op">/</span>f1,  <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">3.2</span>),<span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,<span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> w,<span class="dt">col=</span><span class="dv">2</span>)
    <span class="kw">lines</span>(x, g<span class="op">/</span>f2, <span class="dt">lty =</span> <span class="dv">3</span>, <span class="dt">lwd =</span> w,<span class="dt">col=</span><span class="dv">3</span>)
    <span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span> gs[<span class="op">-</span><span class="dv">1</span>],
           <span class="dt">lty =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">lwd =</span> w, <span class="dt">inset =</span> <span class="fl">0.02</span>,<span class="dt">col=</span><span class="dv">2</span><span class="op">:</span><span class="dv">3</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The figures above show that f2 is more similiar to g according to figure(A), and it is also more aclinic than f1 in figure(B).f2 is the better estimate than f1.</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="cf">function</span>(x) {x<span class="op">^</span><span class="dv">2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)<span class="op">*</span>(x<span class="op">&gt;</span><span class="dv">1</span>)}
m &lt;-<span class="st"> </span><span class="dv">10000</span>   <span class="co">#size</span>
theta.hat &lt;-<span class="st"> </span>se &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">2</span>)
<span class="co">#using inverse transform method to generate random sample f1</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(m) 
x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>u)
fg &lt;-<span class="st"> </span><span class="kw">g</span>(x)<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span>
theta.hat[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(fg)
se[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sd</span>(fg)           <span class="co">#sigma for f1</span>

<span class="co">#using inverse transform method to generate random sample f2</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
x &lt;-<span class="st"> </span>(<span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">log</span>((<span class="dv">1</span><span class="op">-</span>u)<span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)<span class="op">/</span><span class="dv">2</span>)))<span class="op">^</span><span class="fl">0.5</span>
fg &lt;-<span class="st"> </span><span class="kw">g</span>(x)<span class="op">/</span>(x<span class="op">*</span><span class="kw">exp</span>((<span class="dv">1</span><span class="op">-</span>x<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi))
theta.hat[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(fg)
se[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">sd</span>(fg)
<span class="kw">rbind</span>(theta.hat,se)</code></pre></div>
<pre><code>##                [,1]      [,2]
## theta.hat 0.4005487 0.3975913
## se        0.3069082 0.1761729</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##As we have inferred in the figures, the data also prensents that f2 is the better function to get closer to g with a smaller variance.</code></pre></div>
</div>
<div id="question-4" class="section level2">
<h2>Question 4</h2>
<p>Obtain a Monte Carlo estimate of <span class="math display">\[\int_1^{\infty}\frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}dx\]</span> by importance sampling.</p>
</div>
<div id="answer-7" class="section level2">
<h2>Answer</h2>
<p>We choose the f2 as the f to get close to g according to question 3. <span class="math display">\[f(x)=\frac{x}{\sqrt{2\pi}}exp{(1-x^2)/4}\]</span> <span class="math display">\[\int_1^{\infty}\frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}dx=E(g(x)/f(x))\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="cf">function</span>(x) {x<span class="op">^</span><span class="dv">2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)<span class="op">*</span>(x<span class="op">&gt;</span><span class="dv">1</span>)}
m &lt;-<span class="st"> </span><span class="fl">1e7</span>                  <span class="co">#size</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)             <span class="co">#generate the random u ~U(0,1)</span>
x &lt;-<span class="st"> </span>(<span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">log</span>((<span class="dv">1</span><span class="op">-</span>u)<span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)<span class="op">/</span><span class="dv">2</span>)))<span class="op">^</span><span class="fl">0.5</span>       <span class="co">#using inverse transform method to generate random sample f</span>
fg &lt;-<span class="st"> </span><span class="kw">g</span>(x)<span class="op">/</span>(x<span class="op">*</span><span class="kw">exp</span>((<span class="dv">1</span><span class="op">-</span>x<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi))
theta.hat &lt;-<span class="st"> </span><span class="kw">mean</span>(fg)     <span class="co">#the estimate of E(g(x)/f(x)),also the estimate of integral</span>
theta.hat</code></pre></div>
<pre><code>## [1] 0.3989977</code></pre>
</div>
<div id="question-1-2" class="section level2">
<h2>Question 1</h2>
<p>Let X be a non-negative random variable with <span class="math inline">\(?? = E[X] &lt; \infty\)</span>. For a random sample <span class="math inline">\(x_1, . . . , x_n\)</span> from the distribution of X, the Gini ratio is defined by<span class="math display">\[G=\frac1{2n^2\mu}\sum_{j=0}^n\sum_{i=1}^n|x_i-x_j|.\]</span> The Gini ratio is applied in economics to measure inequality in income distribution (see e.g. [163]). Note that G can be written in terms of the order statistics <span class="math inline">\(x_{(i)}\)</span> as <span class="math display">\[G=\frac1{n^2\mu}\sum_{i=1}^n(2i-n-1)x_{i}\]</span> If the mean is unknown, let <span class="math inline">\(\hat{G}\)</span> be the statistic G with <span class="math inline">\(\mu\)</span> replaced by <span class="math inline">\(\bar{x}\)</span>. Estimate by simulation the mean, median and deciles of <span class="math inline">\(\hat{G}\)</span> if X is standard lognormal.Repeat the procedure for the uniform distribution and Bernoulli(0.1). Also construct density histograms of the replicates in each case.</p>
</div>
<div id="answer-8" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">GiniEstimation &lt;-<span class="st">  </span><span class="cf">function</span>(cdf,mu,n,m,a,b)  <span class="co"># cdf for the supposed distribution,mu for theoritical expectation,n for size of random numbers,m for repeating times, a and b for the better xlim for histogram(u can choose a better one when u observed its distribution in histogram with random a b )</span>
{
Gcdf&lt;-<span class="kw">numeric</span>(m)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
v &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m)  
  {
  x&lt;-<span class="kw">sort</span>(<span class="kw">cdf</span>(n))     <span class="co">#sort the x</span>
  
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)   
    {
    v[j] &lt;-<span class="st"> </span>(<span class="dv">2</span><span class="op">*</span>j<span class="op">-</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>x[j]
  } 
  s &lt;-<span class="st"> </span><span class="kw">sum</span>(v)          
  Gcdf[i]&lt;-(<span class="dv">1</span><span class="op">/</span>(n<span class="op">^</span><span class="dv">2</span><span class="op">*</span>mu))<span class="op">*</span>s   <span class="co">#caculate the G for every i</span>
}
mean&lt;-<span class="kw">mean</span>(Gcdf)
median&lt;-<span class="kw">quantile</span>(Gcdf,<span class="fl">0.5</span>)
deciles&lt;-<span class="kw">quantile</span>(Gcdf,<span class="dt">probs=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>))
<span class="kw">print</span>(mean)
<span class="kw">print</span>(median)
<span class="kw">print</span>(deciles)
<span class="kw">hist</span>(Gcdf,<span class="dt">freq=</span>F,<span class="dt">xlim=</span><span class="kw">c</span>(a,b),<span class="dt">main=</span><span class="st">&quot;Gini ratio of supposed distribution&quot;</span>)  <span class="co">#density histograms of the replicates</span>
}</code></pre></div>
<p>The standard lognormal with theoritical expectation of <span class="math inline">\(X\)</span>: <span class="math inline">\(EX=e^{1/2}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">GiniEstimation</span>(rlnorm,<span class="kw">exp</span>(<span class="fl">0.5</span>),<span class="fl">1e3</span>,<span class="fl">1e2</span>,<span class="fl">0.45</span>,<span class="fl">0.65</span>)</code></pre></div>
<pre><code>## [1] 0.5224026
##       50% 
## 0.5207798 
##        0%       10%       20%       30%       40%       50%       60% 
## 0.4605035 0.4805966 0.4935186 0.5023262 0.5107198 0.5207798 0.5310809 
##       70%       80%       90%      100% 
## 0.5383047 0.5527882 0.5635330 0.6023654</code></pre>
<pre><code>## Warning in if (freq) x$counts else x$density: 条件的长度大于一，因此只能用
## 其第一元素</code></pre>
<pre><code>## Warning in if (!freq) &quot;Density&quot; else &quot;Frequency&quot;: 条件的长度大于一，因此只
## 能用其第一元素</code></pre>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAt1BMVEUAAAAAADoAAGYAOjoAOmYAOpAAZpAAZrY6AAA6ADo6OgA6Ojo6OmY6ZpA6ZrY6kLY6kNtmAABmADpmOgBmOjpmkLZmkNtmtttmtv+QOgCQZgCQZjqQkGaQkLaQtpCQttuQtv+Q29uQ2/+2ZgC2Zjq2ZpC2kDq2kGa227a229u22/+2/7a2/9u2///bkDrbkGbbtmbbtpDb27bb29vb2//b/9vb////tmb/25D/27b//7b//9v///+jaipIAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAKQUlEQVR4nO2da3vbNACF3a2lYcBYKLCGAYN6XFaoGQPqtvH//13ofnHiHPmSxlHP+dDHVqVj+bVutmWlaKidKg6dgbmLgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIA8oL+/Lori+ct/xeZ6VZzdhrE2AmKtf7lBUVS0d4uieDkmt1Bl8exmI2AzazLDblv9dyOhVeGjaZ1c9gZ0f/EsCVAt/V/tjjNSaYBUhq12A7ovXCyrDpJ9ctWhqji56us9Nitb87YlsOscSgNIXNyT14Lyh4W8xhqqOJ+f3xXF6VVUgkTojxfFs+vm7wtB8/Mr6SGx/mmiyJr6/JvggrkAFc8i+uuF2P7i2mXtYSnLltj+XUQ/NeFuO7L1SUWlFZsvb/Xmojh9G5ynDzC5d+l0hm/Mmby3JUgerZ0jEVWbrWzO7z4TnCwgU+muYkBSZ7e1+2cEyCTyRdoHhIAqX1pjQM412g5tg6QikdTpTVAFLKAgIDod8X8HSFn+t3KZ28yRBSR2zoNy5RzF5at8kbKndnbd/CNCPrlt7hbmuts2SATolLapCQN8FZPHu20+FC61ByTKpgg/j7cDl1bSa5MHcb3Ob2WBsoCCAJW1zUP6M9GAzvyRwxzZ03i1DdCl+td5C9ClifbxtxfeMGrrfEkPAzwgYXr6vgljOECXNijedi5BUp1G2LoYIiQ+sApQWds8pDkTm3GVtzLy2gBUm3Ls2qArU7jiNkid5fqNLpMRIBvPoYgCPCBd/nWb0mqDbmzsYDt0CZKKXNtaKELPg+uhjuACbNZahzTZia5scOQIkKliPQDJ453+8HEZA7JVtbbFLAoIerH7C31mP9ncBpXVxA62IxeftC4cIBvDAQoDdO43DtkC5C9knCPLW0buAUgnf1gOK0ES0fcvbNu9AWhXCQqSijS2ttsYYQlyAXa7dUhQgiJArptff7xIA1TbBurVkDbInNV3PrQuEtugIGnYtcA2KDzkVkD+aHGO3BVwetmklaCz2/uVaoMqPxJI7MXEwb9Uhd7+Tzql9WJhUtGyvm7ul3JTd1pluxcrXS8WH1JmpA3IHS3MUbV5q/G6SQHk4p/rmpkwDgpL0Ds/xnFNbTAO0qORYGATuARJzTjI9D/xOCgI0LkP0tVmHBQDcsnDHNX+ZvXj1wvbyqf2YqdvVRcrRxun78OR9LdBRfIBYRX7IJuDz9Vw+E60nl/8bnuxP9/48azbjmyDpPdvFjbG+tdF8fx1OJJ2ASb3Pp3K8HW7DXIj6TBH63k97gjviFLv8PYsAgIiICACApoXoBmKgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAhoToCKtg6dIalZZMKonZdZ5G0WmTAiICACAiIgIAICIiAgAgIiICACAiIgIAICIiCgjAEl3oCD2/V5A2qtTjHWLum/RwVIfzg7dnWfrAE1EzDKHZBGNOJLv56Adj9BnB8g+T35ZbNeobW2Eu3gf4+rBMmv9DWZengRyhjQw3KKBcYyBvQYdkcOqFRrhIzr6HMGVKoG6GE5ariYMaCHpV6saEQL3WQNaL3SlasioEg+E5VaguluwZF0pCATal2hXX39w9IulddZyrIGBKUAVbIttw1WT7unAMigqTruRnIGZFcl626kJaC7hQLU1dflDKiE3dfTLkG6Bd4pvejc+a7IWQPqaHcjCUain+u+IckY0Ho1wSPpnAGJYpFShDpcEt9q7N6fNyCzquWoB655l6BHsMsdkCtk3eUsa0APclndcldnv16h+pczoPrkqpJriu8mBLq6aQHNYWJ59DxIjo93Pw9CXd1eS9BhAcmBogQ04yeK8yhB5fC3hk3WgEwbVI0YLjZ5A9K9+Mi3h1kD2r8dAeUM6AjuxWZRgsb18k8AUFPO99XzPABxoAgOOuNXz7MANOfZHfPoxUbdaeQM6DHsCChnQAnPU/vYJf33qACZZ2HD7uY7HvqhR4JHBWi90mS63rr3tNuyd+Ql6OEr/aBjyoFiVoBsCZryiWJWgOQTRfG3GvfEbL+ADvGSIziK6sfGjRMftQQ9OqDp7QgI2GUGCL967mW3sXfsgFJePfew29w7ckBpr56T7bbsHTmgfbx6zgrQPl49ZwVoH6+e8wK0h1fPmQGa3i4rQPaDuonstuwdOaC0mfbJdlv2jhzQ2JfObbvNvSMHlDB5ofcXh1kBSlDvLw6fIqBe34vlAyj1W6iuLw673mpsPVjn/twBwY7+qZegBEA9vzh8aoCavl8cPkFAaXbb9wioeWRAj/Ia6JgBgejTyAKaYmpHky+gPdkRELAjIGBHQMCOgIAdAQE7AgJ2BATsCAjYERCwIyBg98iA9nLv2s8GLgQ3oxJ0CECVfVDW+cTsaQMKnofM8Zn04QEF7z4S32ocVOPAuHPoETehBOWnnm2QKUJjFy4/IvUriNN8t3lU2s/oKiPtBdBhG2ekOQCaNt5Bog2MPq0pAU0Tj4DmGG1g9GlNCWiaeAQ0x2gDo09rSkDTxMsPUE4iICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgKaCFDdWrOh1F+2yrcsQxbPDe2cy2C7KHPyx1LPm3S3aQDJBeLqgFCt3r3efTpwnYvIzrkMtYvcapExteJxqtskgPSsBr+WuVrLaviX+LGdcxloF7npHblGUqrbJID0l75+aabq7DsJqBq4NHVs51wG2kVuvtykuk0DSB3WXROxq9qg8jNRywdMA4ntnMtAu8itfvbHsp/bJIB0Dbf1XBbjUlV1Ran/KUV2zmWoXeRWyemV8kfAkt32AChex2pAyxHbxS797WJAJ1FZT3CbvoqpHQ/IrEQw2K7l0t8uctNNUR+36RvpyswysXno3zm32/xmVF8fuWlOfdz20s3rEqRzNqCKRXbOZahd5KbnofZx289AUVcxlakhS3tGds5lqF3kJhtIhSzVbaJbjUqP5t2PROo2qPQ1bYSdcxlqF7nVtndPdOPNKhABAREQEAEBERAQAQEREBABAREQEAEBERAQAQEREBABAREQEAEBERAQAQEREBABAREQEAEBERAQAQEREBABAREQ0DwBdfxosJyCUA2a1TdcswSkVrparzbmpghAI3/mtL/mCMjM+3JTRZwUoCl+Bq2H5gjIzt+r1NQwMx9ezmH5/uTHxchfJeitGQKKfr5CzrqU1aqUc78LliCpkIFtcnStKwlISjOQE8DsVEI7mZBtkJLrqORcSzMNtSKgQLaRrlmCtiugErdBFQFp6WWZS9m9y15MDogq9bNmBGSkbjX8xH0/DiKg2YmAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgIAICIiAgAgIiICACAiIgID+B857xQrjhT5FAAAAAElFTkSuQmCC" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The mean is much approaching to median as the data shows and we can also roughly conclude from the histogram.</code></pre></div>
<p>The uniform distribution with<span class="math inline">\(X\sim \mathbb{U}(0,1)\)</span><span class="math inline">\(E(X)=0.5\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">GiniEstimation</span>(runif,<span class="fl">0.5</span>,<span class="fl">1e3</span>,<span class="fl">1e2</span>,<span class="fl">0.32</span>,<span class="fl">0.35</span>)</code></pre></div>
<pre><code>## [1] 0.3331344
##       50% 
## 0.3336176 
##        0%       10%       20%       30%       40%       50%       60% 
## 0.3224468 0.3268978 0.3282684 0.3298462 0.3320880 0.3336176 0.3347927 
##       70%       80%       90%      100% 
## 0.3361681 0.3372652 0.3387707 0.3446976</code></pre>
<pre><code>## Warning in if (freq) x$counts else x$density: 条件的长度大于一，因此只能用
## 其第一元素</code></pre>
<pre><code>## Warning in if (!freq) &quot;Density&quot; else &quot;Frequency&quot;: 条件的长度大于一，因此只
## 能用其第一元素</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The mean is much approaching to median as the data shows and we can also roughly conclude from the histogram.</code></pre></div>
<p>The Bernoulli(0.1) distribution with <span class="math inline">\(X\sim Bernoulli(1000,0.1)\)</span><span class="math inline">\(E(X)=100\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span>m &lt;-<span class="st"> </span><span class="fl">1e3</span>
mu &lt;-<span class="st"> </span><span class="dv">100</span>
Gcdf&lt;-<span class="kw">numeric</span>(m)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
v &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m)  
  {
  x&lt;-<span class="kw">sort</span>(<span class="kw">rbinom</span>(n,<span class="dv">1000</span>,<span class="fl">0.1</span>))     <span class="co">#sort the x</span>
  
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)   
    {
    v[j] &lt;-<span class="st"> </span>(<span class="dv">2</span><span class="op">*</span>j<span class="op">-</span>n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>x[j]
  } 
  s &lt;-<span class="st"> </span><span class="kw">sum</span>(v)          
  Gcdf[i]&lt;-(<span class="dv">1</span><span class="op">/</span>(n<span class="op">^</span><span class="dv">2</span><span class="op">*</span>mu))<span class="op">*</span>s   <span class="co">#caculate the G for every i</span>
}
mean&lt;-<span class="kw">mean</span>(Gcdf)
median&lt;-<span class="kw">quantile</span>(Gcdf,<span class="fl">0.5</span>)
deciles&lt;-<span class="kw">quantile</span>(Gcdf,<span class="dt">probs=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>))
<span class="kw">print</span>(mean)</code></pre></div>
<pre><code>## [1] 0.05348466</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(median)</code></pre></div>
<pre><code>##        50% 
## 0.05349481</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(deciles)</code></pre></div>
<pre><code>##         0%        10%        20%        30%        40%        50% 
## 0.04918666 0.05191771 0.05243589 0.05280906 0.05318438 0.05349481 
##        60%        70%        80%        90%       100% 
## 0.05381938 0.05416515 0.05444951 0.05507521 0.05799861</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(Gcdf,<span class="dt">freq=</span>F,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="fl">0.048</span>,<span class="fl">0.058</span>),<span class="dt">main=</span><span class="st">&quot;Gini ratio of Bernoulli(0.1)&quot;</span>)  <span class="co">#density histograms of the replicates</span></code></pre></div>
<pre><code>## Warning in if (freq) x$counts else x$density: 条件的长度大于一，因此只能用
## 其第一元素</code></pre>
<pre><code>## Warning in if (!freq) &quot;Density&quot; else &quot;Frequency&quot;: 条件的长度大于一，因此只
## 能用其第一元素</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The mean is much approaching to median as the data shows and we can also roughly conclude from the histogram.</code></pre></div>
</div>
<div id="question-2-2" class="section level2">
<h2>Question 2</h2>
<p>Construct an approximate 95% confidence interval for the Gini ratio <span class="math inline">\(\gamma = E[G]\)</span> if X is lognormal with unknown parameters. Assess the coverage rate of the estimation procedure with a Monte Carlo experiment.</p>
</div>
<div id="answer-9" class="section level2">
<h2>Answer</h2>
<p>First we stimulate the <span class="math inline">\(\sigma=sd(logX),logX\sim normal(0,1)\)</span>,then we use the<span class="math inline">\(\sigma\)</span>to caculate<span class="math inline">\(\gamma\)</span><span class="math display">\[\gamma=E[G]=erf(\sigma/2)=\frac2{\sqrt{\pi}}\int_0^{\frac{\sigma}{2}}e^{-t^2}dt\]</span>,then we can caculate the CI.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n&lt;-<span class="dv">1000</span>              <span class="co">#generate 1000 random numbers</span>
m&lt;-<span class="dv">100</span>               <span class="co">#generate 100 gini ratio every times and repeate 100 times</span>
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>
UCL &lt;-<span class="st"> </span>LCL &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)
G &lt;-<span class="st"> </span><span class="cf">function</span>(b)      <span class="co">#the real value of gamma,b for sigma</span>
  {
 
  <span class="kw">return</span>(<span class="dv">2</span><span class="op">*</span><span class="kw">pnorm</span>(b<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>))<span class="op">-</span><span class="dv">1</span>)
}
CI.sigma&lt;-<span class="cf">function</span>(x,n){                     <span class="co">#function to construct confident interval for sigma</span>
  s2&lt;-(<span class="dv">1</span><span class="op">/</span>(n<span class="op">-</span><span class="dv">1</span>))<span class="op">*</span><span class="kw">sum</span>((x<span class="op">-</span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)
  LCL&lt;-<span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>s2<span class="op">/</span><span class="kw">qchisq</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,n<span class="op">-</span><span class="dv">1</span>)
  UCL&lt;-(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>s2<span class="op">/</span><span class="kw">qchisq</span>(alpha<span class="op">/</span><span class="dv">2</span>,n<span class="op">-</span><span class="dv">1</span>)
  <span class="kw">c</span>(LCL,UCL)
}
ciG&lt;-<span class="kw">cbind</span>(<span class="kw">numeric</span>(m),<span class="kw">numeric</span>(m))
C&lt;-CR&lt;-<span class="kw">numeric</span>(m)
e &lt;-<span class="st"> </span><span class="kw">G</span>(<span class="dv">1</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){

  x&lt;-<span class="kw">rlnorm</span>(n)
  ci&lt;-<span class="kw">CI.sigma</span>(<span class="kw">log</span>(x),n)
  ciG[i,<span class="dv">1</span>]&lt;-<span class="kw">G</span>(ci[<span class="dv">1</span>])
  ciG[i,<span class="dv">2</span>]&lt;-<span class="kw">G</span>(ci[<span class="dv">2</span>])
  <span class="cf">if</span>(e<span class="op">&gt;</span>ciG[i,<span class="dv">1</span>] <span class="op">&amp;&amp;</span><span class="st"> </span>e<span class="op">&lt;</span>ciG[i,<span class="dv">2</span>])     <span class="co"># for every ith ci,judge whether real value e in the ci</span>
    C[i]&lt;-<span class="dv">1</span>
  <span class="cf">else</span>
    C[i]&lt;-<span class="dv">0</span>
   }

CR[j]&lt;-<span class="kw">mean</span>(C)
}
<span class="kw">mean</span>(CR)</code></pre></div>
<pre><code>## [1] 0.9544</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The coverage rate of estimation is a little bigger than 0.95.</code></pre></div>
</div>
<div id="question-3-2" class="section level2">
<h2>Question 3</h2>
<p>Tests for association based on Pearson product moment correlation <span class="math inline">\(\rho\)</span>, Spearman??s rank correlation coefficient <span class="math inline">\(\rho_s\)</span>, or Kendall??s coefficient <span class="math inline">\(\tau\)</span>, are implemented in cor.test. Show (empirically) that the nonparametric tests based on <span class="math inline">\(\rho_s\)</span> or <span class="math inline">\(\tau\)</span> are less powerful than the correlation test when the sampled distribution is bivariate normal. Find an example of an alternative (a bivariate distribution (X, Y ) such that X and Y are dependent) such that at least one of the nonparametric tests have better empirical power than the correlation test against this alternative.</p>
</div>
<div id="answer-10" class="section level2">
<h2>Answer</h2>
Assume <span class="math inline">\((X,Y)\sim N(\mu,\Sigma)\)</span>, with <span class="math inline">\(\mu=(0,0)^T\)</span> and <span class="math inline">\(\Sigma\)</span> is of following:
<span class="math display">\[\begin{matrix}
1 &amp; \rho\\
\rho &amp; 1
\end{matrix}\]</span>
<p>Spearman’s rank correlation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
n &lt;-<span class="st"> </span><span class="dv">20</span>
m &lt;-<span class="st"> </span><span class="dv">1000</span>
rho.s &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">0.1</span>),<span class="kw">seq</span>(<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.1</span>))   <span class="co">#alternatives</span>
M &lt;-<span class="st"> </span><span class="kw">length</span>(rho.s)
power.s &lt;-<span class="st"> </span><span class="kw">numeric</span>(M)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>M) {
rho &lt;-rho.s[i]
pvalues.s &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr =</span> {       <span class="co">#simulate under alternative mu1</span>
x &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(n, <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,rho,rho,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>))
cortest.s &lt;-<span class="st"> </span><span class="kw">cor.test</span>(x[,<span class="dv">1</span>],x[,<span class="dv">2</span>],
<span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,<span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>)
cortest.s<span class="op">$</span>p.value } )
power.s[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(pvalues.s<span class="op">&lt;=</span><span class="st"> </span>.<span class="dv">05</span>)
}
power.s</code></pre></div>
<pre><code>##  [1] 0.988 0.918 0.743 0.556 0.356 0.231 0.116 0.054 0.058 0.121 0.234
## [12] 0.370 0.564 0.787 0.931 0.985</code></pre>
<p>Kendall’s coefficient:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">20</span>
m &lt;-<span class="st"> </span><span class="dv">1000</span>
rho.k &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">0.1</span>),<span class="kw">seq</span>(<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.1</span>))    <span class="co">#alternatives</span>
M &lt;-<span class="st"> </span><span class="kw">length</span>(rho.k)
power.k &lt;-<span class="st"> </span><span class="kw">numeric</span>(M)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>M) {
rho &lt;-rho.k[i]
pvalues.k &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr =</span> {       <span class="co">#simulate under alternative mu1</span>
x &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(n, <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,rho,rho,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>))
cortest.k &lt;-<span class="st"> </span><span class="kw">cor.test</span>(x[,<span class="dv">1</span>],x[,<span class="dv">2</span>],
<span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,<span class="dt">method=</span><span class="st">&quot;kendall&quot;</span>)
cortest.k<span class="op">$</span>p.value } )
power.k[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(pvalues.k<span class="op">&lt;=</span><span class="st"> </span>.<span class="dv">05</span>)
}
power.k</code></pre></div>
<pre><code>##  [1] 0.988 0.907 0.730 0.550 0.355 0.203 0.107 0.047 0.062 0.116 0.214
## [12] 0.358 0.544 0.778 0.926 0.985</code></pre>
<p>Pearson’s correlation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">20</span>
m &lt;-<span class="st"> </span><span class="dv">1000</span>
rho.p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">0.1</span>),<span class="kw">seq</span>(<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.1</span>))       <span class="co">#alternatives</span>
M &lt;-<span class="st"> </span><span class="kw">length</span>(rho.p)
power.p &lt;-<span class="st"> </span><span class="kw">numeric</span>(M)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>M) {
rho &lt;-rho.p[i]
pvalues.p &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr =</span> {     <span class="co">#simulate under alternative mu1</span>

x &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(n, <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,rho,rho,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>))
cortest.p &lt;-<span class="st"> </span><span class="kw">cor.test</span>(x[,<span class="dv">1</span>],x[,<span class="dv">2</span>],
<span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,<span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)
cortest.p<span class="op">$</span>p.value } )
power.p[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(pvalues.p<span class="op">&lt;=</span><span class="st"> </span>.<span class="dv">05</span>)
}
power.p</code></pre></div>
<pre><code>##  [1] 0.997 0.960 0.827 0.631 0.429 0.257 0.120 0.058 0.069 0.133 0.258
## [12] 0.418 0.650 0.852 0.953 0.991</code></pre>
<p>Make comparision</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">power.rho&lt;-<span class="kw">rbind</span>(power.s,power.k,power.p)
<span class="kw">colnames</span>(power.rho)&lt;-<span class="kw">c</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">0.1</span>),<span class="kw">seq</span>(<span class="fl">0.1</span>,<span class="fl">0.8</span>,<span class="fl">0.1</span>))
power.rho</code></pre></div>
<pre><code>##          -0.8  -0.7  -0.6  -0.5  -0.4  -0.3  -0.2  -0.1   0.1   0.2   0.3
## power.s 0.988 0.918 0.743 0.556 0.356 0.231 0.116 0.054 0.058 0.121 0.234
## power.k 0.988 0.907 0.730 0.550 0.355 0.203 0.107 0.047 0.062 0.116 0.214
## power.p 0.997 0.960 0.827 0.631 0.429 0.257 0.120 0.058 0.069 0.133 0.258
##           0.4   0.5   0.6   0.7   0.8
## power.s 0.370 0.564 0.787 0.931 0.985
## power.k 0.358 0.544 0.778 0.926 0.985
## power.p 0.418 0.650 0.852 0.953 0.991</code></pre>
<p>the result shows that the nonparametric tests based on <span class="math inline">\(??_s\)</span> or <span class="math inline">\(??\)</span> are less powerful than the correlation test in bivariate normal.</p>
<p>The example <span class="math inline">\(X\sim t_{2}\)</span>, <span class="math inline">\(Y\sim U(-1,0)\)</span> when <span class="math inline">\(X&lt;0\)</span> and <span class="math inline">\(Y\sim U(0,1)\)</span> when <span class="math inline">\(X\ge0\)</span>.<span class="math inline">\(X,Y\)</span> are dependent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">20</span>
m &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
pvalues.s1 &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr =</span> {   <span class="co">#simulate under alternative mu1</span>
x &lt;-<span class="st"> </span><span class="kw">rt</span>(n,<span class="dv">2</span>)
y&lt;-<span class="kw">numeric</span>(n)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n){
  <span class="cf">if</span>(x[i]<span class="op">&lt;</span><span class="dv">0</span>) 
    y[i]&lt;-<span class="kw">runif</span>(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>)
  <span class="cf">else</span>       
    y[i]&lt;-<span class="kw">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)
}
cortest.s1 &lt;-<span class="st"> </span><span class="kw">cor.test</span>(x,y,
<span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,<span class="dt">method=</span><span class="st">&quot;spearman&quot;</span>)
cortest.s1<span class="op">$</span>p.value } )
power.s1 &lt;-<span class="st"> </span><span class="kw">mean</span>(pvalues.s1<span class="op">&lt;=</span><span class="st"> </span>.<span class="dv">05</span>)
power.s1</code></pre></div>
<pre><code>## [1] 0.99</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##nice power</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">20</span>
m &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">set.seed</span>(<span class="dv">431</span>)
pvalues.p1 &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr =</span> {
<span class="co">#simulate under alternative mu1</span>
x &lt;-<span class="st"> </span><span class="kw">rt</span>(n,<span class="dv">2</span>)
y&lt;-<span class="kw">numeric</span>(n)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n){
  <span class="cf">if</span>(x[i]<span class="op">&lt;</span><span class="dv">0</span>) y[i]&lt;-<span class="kw">runif</span>(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>)
  <span class="cf">else</span>       y[i]&lt;-<span class="kw">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)
}
cortest.p1 &lt;-<span class="st"> </span><span class="kw">cor.test</span>(x,y,
<span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,<span class="dt">method=</span><span class="st">&quot;pearson&quot;</span>)
cortest.p1<span class="op">$</span>p.value } )
power.p1 &lt;-<span class="st"> </span><span class="kw">mean</span>(pvalues.p1<span class="op">&lt;=</span><span class="st"> </span>.<span class="dv">05</span>)
power.p1</code></pre></div>
<pre><code>## [1] 0.849</code></pre>
<p>Power of the nonparametric test Spearman’s rank correlation coefficient is much better according to the results.</p>
</div>
<div id="question-1-3" class="section level2">
<h2>Question 1</h2>
<p>Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.</p>
</div>
<div id="answer-11" class="section level2">
<h2>Answer</h2>
<p>This question is about the correlation between LSAT and GPA in law data. An unbiased estimate of the bias <span class="math inline">\(E(\hat\theta)-\theta_0\)</span> is<span class="math display">\[(n-1)(\bar{\hat\theta}_{(\cdot)}-\hat\theta)\]</span> An unbiased estimate of <span class="math inline">\(se(\hat\theta)\)</span> is<span class="math display">\[ \sqrt{\frac{n-1}n\sum_{i=1}^n(\hat\theta_{(i)}-\bar{\hat\theta}_{(\cdot)})^2}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(bootstrap)</code></pre></div>
<pre><code>## 
## 载入程辑包：'bootstrap'</code></pre>
<pre><code>## The following object is masked _by_ '.GlobalEnv':
## 
##     diabetes</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="kw">nrow</span>(law)   <span class="co">#sample size</span>
theta.jack &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta.hat &lt;-<span class="st"> </span><span class="kw">cor</span>(law[,<span class="dv">1</span>], law[,<span class="dv">2</span>]) <span class="co">#law[,1] is LSAT, law[,2] is GPA</span>
b.cor &lt;-<span class="st"> </span><span class="cf">function</span>(x,i)<span class="kw">cor</span>(x[i,<span class="dv">1</span>],x[i,<span class="dv">2</span>])
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
  {
    theta.jack[i] &lt;-<span class="st"> </span><span class="kw">b.cor</span>(law,(<span class="dv">1</span><span class="op">:</span>n)[<span class="op">-</span>i])  <span class="co">#leave one out</span>
}
bias.jack &lt;-<span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(<span class="kw">mean</span>(theta.jack)<span class="op">-</span>theta.hat)     <span class="co">#the eatimate bias </span>
se.jack &lt;-<span class="st"> </span><span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="kw">mean</span>((theta.jack<span class="op">-</span>theta.hat)<span class="op">^</span><span class="dv">2</span>))   <span class="co">#the eatimate standard error</span>
<span class="kw">round</span>(<span class="kw">c</span>(<span class="dt">original=</span>theta.hat,<span class="dt">bias=</span>bias.jack,<span class="dt">se=</span>se.jack),<span class="dv">3</span>)</code></pre></div>
<pre><code>## original     bias       se 
##    0.776   -0.006    0.143</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##Jackknife estimate of the bias and the standard error of the correlation between LSAT and GPA in law data is shown above. </code></pre></div>
</div>
<div id="question-2-3" class="section level2">
<h2>Question 2</h2>
<p>Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the mean time between failures <span class="math inline">\(\frac{1}{\lambda}\)</span> by the standard normal, basic, percentile,and BCa methods. Compare the intervals and explain why they may differ.</p>
</div>
<div id="answer-12" class="section level2">
<h2>Answer</h2>
<p>the MLE of <span class="math inline">\(\lambda\)</span>:<span class="math inline">\(\hat\lambda=\frac{n}{\sum_{i=0}^{n}x_i}=\frac{1}{\bar{X}}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(boot)
n &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co">#sample size</span>
m &lt;-<span class="st"> </span><span class="dv">100</span><span class="co"># times for replicates</span>
ci.norm&lt;-ci.basic&lt;-ci.perc&lt;-ci.bca&lt;-<span class="kw">matrix</span>(<span class="ot">NA</span>,m,<span class="dv">2</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot.mean &lt;-<span class="st"> </span><span class="cf">function</span>(x,i) <span class="kw">mean</span>(x<span class="op">$</span>hours[i])
de &lt;-<span class="st"> </span><span class="kw">boot</span>(aircondit,<span class="dt">statistic=</span>boot.mean,<span class="dt">R =</span> <span class="dv">999</span>)
ci &lt;-<span class="st"> </span><span class="kw">boot.ci</span>(de,<span class="dt">type=</span><span class="kw">c</span>(<span class="st">&quot;norm&quot;</span>,<span class="st">&quot;basic&quot;</span>,<span class="st">&quot;perc&quot;</span>,<span class="st">&quot;bca&quot;</span>)) <span class="co">#the confidence interval</span>
ci</code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 999 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = de, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;, &quot;bca&quot;))
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   ( 33.8, 180.1 )   ( 25.0, 168.4 )  
## 
## Level     Percentile            BCa          
## 95%   ( 47.8, 191.2 )   ( 56.4, 231.8 )  
## Calculations and Intervals on Original Scale
## Some BCa intervals may be unstable</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The four kinds of CIs have been shown above,and they differ greatly,it is may beacause of the small fixed sample size which is not appproching the normal distribution. </code></pre></div>
<p>Compare the four kinds of CI</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4</span>)
mu &lt;-<span class="st"> </span><span class="kw">mean</span>(aircondit<span class="op">$</span>hours)<span class="co">#the estimate of mean time</span>
lambda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>mu
tboot.mean &lt;-<span class="st"> </span><span class="cf">function</span>(x,i) <span class="kw">mean</span>(x[i])
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {
  U&lt;-<span class="kw">runif</span>(n);R&lt;-<span class="op">-</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>U)<span class="op">/</span>lambda <span class="co">#generate random sample with expotential distribution</span>
  de &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data=</span>R,<span class="dt">statistic=</span>tboot.mean, <span class="dt">R =</span> <span class="dv">999</span>)
  ci &lt;-<span class="st"> </span><span class="kw">boot.ci</span>(de,<span class="dt">type=</span><span class="kw">c</span>(<span class="st">&quot;norm&quot;</span>,<span class="st">&quot;basic&quot;</span>,<span class="st">&quot;perc&quot;</span>,<span class="st">&quot;bca&quot;</span>))
  ci.norm[i,]&lt;-ci<span class="op">$</span>norm[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>];ci.basic[i,]&lt;-ci<span class="op">$</span>basic[<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>]
  ci.perc[i,]&lt;-ci<span class="op">$</span>percent[<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>];ci.bca[i,]&lt;-ci<span class="op">$</span>bca[<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>]
}
<span class="kw">cat</span>(<span class="st">'norm ='</span>,<span class="kw">mean</span>(ci.norm[,<span class="dv">1</span>]<span class="op">&lt;=</span>mu <span class="op">&amp;</span><span class="st"> </span>ci.norm[,<span class="dv">2</span>]<span class="op">&gt;=</span>mu),
    <span class="st">'basic ='</span>,<span class="kw">mean</span>(ci.basic[,<span class="dv">1</span>]<span class="op">&lt;=</span>mu <span class="op">&amp;</span><span class="st"> </span>ci.basic[,<span class="dv">2</span>]<span class="op">&gt;=</span>mu),
    <span class="st">'perc ='</span>,<span class="kw">mean</span>(ci.perc[,<span class="dv">1</span>]<span class="op">&lt;=</span>mu <span class="op">&amp;</span><span class="st"> </span>ci.perc[,<span class="dv">2</span>]<span class="op">&gt;=</span>mu),
    <span class="st">'BCa ='</span>,<span class="kw">mean</span>(ci.bca[,<span class="dv">1</span>]<span class="op">&lt;=</span>mu <span class="op">&amp;</span><span class="st"> </span>ci.bca[,<span class="dv">2</span>]<span class="op">&gt;=</span>mu))</code></pre></div>
<pre><code>## norm = 0.93 basic = 0.9 perc = 0.94 BCa = 0.93</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The result above showS that the percentile method has the best effect in expotential distribution with lambda equals the mle of lambda from aircondit data</code></pre></div>
</div>
<div id="quenstion-3" class="section level2">
<h2>Quenstion 3</h2>
<p>Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard error of <span class="math inline">\(\hat\theta\)</span>.</p>
</div>
<div id="answer-13" class="section level2">
<h2>Answer</h2>
<p>We have the empirical <span class="math inline">\(\theta\)</span><span class="math display">\[\hat\theta=\frac{\hat\lambda_1}{\sum_{j=0}^{m}\hat\lambda_j}\]</span>m is the column number of data,<span class="math inline">\(\hat\lambda_j\)</span>is the empirical sorted eigenvalue by decreasing order of covariance matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(bootstrap)
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(scor)
m &lt;-<span class="st"> </span><span class="kw">ncol</span>(scor)
covmatrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>,m,m)<span class="co"># for covariance matrix</span>
eigenvalues &lt;-<span class="st"> </span>lambda &lt;-<span class="st"> </span><span class="kw">numeric</span>(m) <span class="co">#for eigenvalues,sorted eigenvalues(decreasing)</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">covmatrix &lt;-<span class="st"> </span><span class="kw">cov</span>(scor) <span class="co">#covariance matrix</span>
eigenvalues &lt;-<span class="st"> </span><span class="kw">eigen</span>(covmatrix)<span class="op">$</span>values <span class="co">#eigenvalues</span>
lambda &lt;-<span class="st"> </span><span class="kw">sort</span>(eigenvalues) <span class="co">#sort the eigenvalues</span>
theta.hat &lt;-<span class="st"> </span>lambda[<span class="dv">1</span>]<span class="op">/</span><span class="kw">sum</span>(lambda) <span class="co">#the empirical theta </span>
b.theta &lt;-<span class="st"> </span><span class="cf">function</span>(x,i) 
             {
               covmatrix &lt;-<span class="st"> </span><span class="kw">cov</span>(x[i,])
               eigenvalues &lt;-<span class="st"> </span><span class="kw">eigen</span>(covmatrix)<span class="op">$</span>values
               lambda &lt;-<span class="st"> </span><span class="kw">sort</span>(eigenvalues)
               theta.hat &lt;-<span class="st"> </span>lambda[<span class="dv">1</span>]<span class="op">/</span><span class="kw">sum</span>(lambda)
             }
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
  {
    theta.jack[i] &lt;-<span class="st"> </span><span class="kw">b.theta</span>(scor,(<span class="dv">1</span><span class="op">:</span>n)[<span class="op">-</span>i])   <span class="co">#leave one out</span>
  }
bias.jack &lt;-<span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(<span class="kw">mean</span>(theta.jack)<span class="op">-</span>theta.hat)     <span class="co">#the eatimate bias </span>
se.jack &lt;-<span class="st"> </span><span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="kw">mean</span>((theta.jack<span class="op">-</span>theta.hat)<span class="op">^</span><span class="dv">2</span>))   <span class="co">#the eatimate standard error</span>
<span class="kw">round</span>(<span class="kw">c</span>(<span class="dt">original=</span>theta.hat,<span class="dt">bias=</span>bias.jack,<span class="dt">se=</span>se.jack),<span class="dv">3</span>)</code></pre></div>
<pre><code>## original     bias       se 
##    0.029   -0.002    0.004</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##Jackknife estimate of the bias and the standard error of the theta.hat is shown above. </code></pre></div>
</div>
<div id="quenstion-4" class="section level2">
<h2>Quenstion 4</h2>
<p>In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Use leave-two-out cross validation to compare the models.</p>
</div>
<div id="answer-14" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(DAAG)</code></pre></div>
<pre><code>## 载入需要的程辑包：lattice</code></pre>
<pre><code>## 
## 载入程辑包：'lattice'</code></pre>
<pre><code>## The following object is masked from 'package:boot':
## 
##     melanoma</code></pre>
<pre><code>## 
## 载入程辑包：'DAAG'</code></pre>
<pre><code>## The following object is masked from 'package:MASS':
## 
##     hills</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(ironslag)
n &lt;-<span class="st"> </span><span class="kw">length</span>(magnetic) <span class="co">#in DAAG ironslag</span>
e1 &lt;-<span class="st"> </span>e2 &lt;-<span class="st"> </span>e3 &lt;-<span class="st"> </span>e4 &lt;-<span class="st"> </span><span class="kw">numeric</span>(n) <span class="co"># for the prediction error</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># for n-fold cross validation</span>
<span class="co"># fit models on leave-two-out samples</span>
<span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">round</span>(n<span class="op">/</span><span class="dv">2</span>))
  {
y &lt;-<span class="st"> </span>magnetic[<span class="op">-</span>(<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>)] <span class="co">#delete the x_2k-1</span>
y &lt;-<span class="st"> </span>y[<span class="op">-</span><span class="dv">2</span><span class="op">*</span>k]          <span class="co">#delete the x_2k</span>
x &lt;-<span class="st"> </span>chemical[<span class="op">-</span><span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>]
x &lt;-<span class="st"> </span>x[<span class="op">-</span><span class="dv">2</span><span class="op">*</span>k]

J1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x) <span class="co">#Linear model</span>
yhat1.<span class="dv">1</span> &lt;-<span class="st"> </span>J1<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J1<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>]
e1[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>yhat1.<span class="dv">1</span>
yhat1.<span class="dv">2</span> &lt;-<span class="st"> </span>J1<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J1<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k]
e1[<span class="dv">2</span><span class="op">*</span>k] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k] <span class="op">-</span><span class="st"> </span>yhat1.<span class="dv">2</span>

J2 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>)) <span class="co">#Quardratic model</span>
yhat2.<span class="dv">1</span> &lt;-<span class="st"> </span>J2<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J2<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span>
J2<span class="op">$</span>coef[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>]<span class="op">^</span><span class="dv">2</span>
e2[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>yhat2.<span class="dv">1</span>
yhat2.<span class="dv">2</span> &lt;-<span class="st"> </span>J2<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J2<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k] <span class="op">+</span>
J2<span class="op">$</span>coef[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k]<span class="op">^</span><span class="dv">2</span>
e2[<span class="dv">2</span><span class="op">*</span>k] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k] <span class="op">-</span><span class="st"> </span>yhat2.<span class="dv">2</span>

J3 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(y) <span class="op">~</span><span class="st"> </span>x) <span class="co">#Exponential model</span>
logyhat3.<span class="dv">1</span> &lt;-<span class="st"> </span>J3<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J3<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>]
yhat3.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(logyhat3.<span class="dv">1</span>)
e3[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>yhat3.<span class="dv">1</span>
logyhat3.<span class="dv">2</span> &lt;-<span class="st"> </span>J3<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J3<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>chemical[<span class="dv">2</span><span class="op">*</span>k]
yhat3.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(logyhat3.<span class="dv">2</span>)
e3[<span class="dv">2</span><span class="op">*</span>k] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k] <span class="op">-</span><span class="st"> </span>yhat3.<span class="dv">2</span>

J4 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(y) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(x)) <span class="co">#Log-Log model</span>
logyhat4.<span class="dv">1</span> &lt;-<span class="st"> </span>J4<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J4<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(chemical[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>])
yhat4.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(logyhat4.<span class="dv">1</span>)
e4[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>yhat4.<span class="dv">1</span>
logyhat4.<span class="dv">2</span> &lt;-<span class="st"> </span>J4<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>J4<span class="op">$</span>coef[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(chemical[<span class="dv">2</span><span class="op">*</span>k])
yhat4.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(logyhat4.<span class="dv">2</span>)
e4[<span class="dv">2</span><span class="op">*</span>k] &lt;-<span class="st"> </span>magnetic[<span class="dv">2</span><span class="op">*</span>k] <span class="op">-</span><span class="st"> </span>yhat4.<span class="dv">2</span>
}
<span class="kw">c</span>(<span class="kw">mean</span>(e1<span class="op">^</span><span class="dv">2</span>), <span class="kw">mean</span>(e2<span class="op">^</span><span class="dv">2</span>), <span class="kw">mean</span>(e3<span class="op">^</span><span class="dv">2</span>), <span class="kw">mean</span>(e4<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<pre><code>## [1] 18.66796 16.33493 17.14092 19.21681</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The result above shows that the J2 Model 2, the quadratic model,would be the best fit for the data according to the prediction error criterion.</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">J2</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x + I(x^2))
## 
## Coefficients:
## (Intercept)            x       I(x^2)  
##    19.15533     -0.77001      0.03697</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##The related quadratic model is shown above</code></pre></div>
<p>The model is<span class="math display">\[\hat Y=19.15533-0.77001X+0.03697X^2\]</span></p>
</div>
<div id="question-1-4" class="section level2">
<h2>Question 1</h2>
<p>Implement the two-sample Cramer-von Mises test for equal distributions as a permutation test. Apply the test to the data in Examples 8.1 and 8.2.</p>
</div>
<div id="answer-15" class="section level2">
<h2>Answer</h2>
<p>The Cram′er-von Mises statistic<span class="math display">\[W_2=\frac{mn}{(m+n)^2}[\sum_{i=1}^{n}(F_n(x_i)-G_m(x_i))^2+\sum_{j=1}^{n}(F_n(y_j)-G_m(y_j))^2]]\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">attach</span>(chickwts)    <span class="co">#for data</span>
x &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">as.vector</span>(weight[feed <span class="op">==</span><span class="st"> &quot;soybean&quot;</span>]))
y &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">as.vector</span>(weight[feed <span class="op">==</span><span class="st"> &quot;linseed&quot;</span>]))
<span class="kw">detach</span>(chickwts)

z &lt;-<span class="st"> </span><span class="kw">c</span>(x,y) <span class="co">#pool the sample</span>
m &lt;-<span class="st"> </span><span class="kw">length</span>(x);n &lt;-<span class="st"> </span><span class="kw">length</span>(y);N &lt;-<span class="st"> </span><span class="kw">length</span>(z)
S &lt;-<span class="st"> </span><span class="kw">numeric</span>(N) <span class="co">#for Cram′er-von Mises statistic</span>
R&lt;-<span class="st"> </span><span class="dv">999</span> <span class="co">#number of replicates</span>
W &lt;-<span class="st"> </span>k &lt;-<span class="st"> </span><span class="kw">numeric</span>(R) <span class="co">#W for storage of replicates k for permutation</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#caculate the Cram′er-von Mises statistic</span>
cvm &lt;-<span class="st"> </span><span class="cf">function</span>(x1,y1){
Fn &lt;-<span class="st"> </span><span class="kw">ecdf</span>(x1);Gm &lt;-<span class="st"> </span><span class="kw">ecdf</span>(y1);z1 &lt;-<span class="st"> </span><span class="kw">c</span>(x1,y1)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) 
  {
    S[i] &lt;-<span class="st"> </span>(<span class="kw">Fn</span>(z1[i])<span class="op">-</span><span class="kw">Gm</span>(z1[i]))<span class="op">^</span><span class="dv">2</span> 
  }
  m<span class="op">*</span>n<span class="op">/</span>(m<span class="op">+</span>n)<span class="op">^</span><span class="dv">2</span><span class="op">*</span><span class="kw">sum</span>(S)
  }
W0 &lt;-<span class="st"> </span><span class="kw">cvm</span>(x,y)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>R) {
<span class="co">#generate indices k for the first sample</span>
k &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>N, <span class="dt">size =</span> m, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
x1 &lt;-<span class="st"> </span>z[k]
y1 &lt;-<span class="st"> </span>z[<span class="op">-</span>k] <span class="co">#complement of x1</span>
W[i] &lt;-<span class="st"> </span><span class="kw">cvm</span>(x1,y1)
}
p &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">c</span>(W0, W) <span class="op">&gt;=</span><span class="st"> </span>W0)<span class="co">#cacaulate the p value</span>
p</code></pre></div>
<pre><code>## [1] 0.385</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## As the result shows above,it does not support the alternative hypothesis that distributions differ.</code></pre></div>
</div>
<div id="question-2-4" class="section level2">
<h2>Question 2</h2>
<p>Design experiments for evaluating the performance of the NN, energy, and ball methods in various situations.</p>
<ol style="list-style-type: decimal">
<li><p>Unequal variances and equal expectations</p></li>
<li><p>Unequal variances and unequal expectations</p></li>
<li><p>Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)</p></li>
<li><p>Unbalanced samples (say, 1 case versus 10 controls)</p></li>
</ol>
<p>Note: The parameters should be choosen such that the powers are distinguishable (say, range from 0.3 to 0.9).</p>
</div>
<div id="anwer" class="section level2">
<h2>Anwer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(RANN)</code></pre></div>
<pre><code>## Warning: 程辑包'RANN'是用R版本3.5.2 来建造的</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(energy)
<span class="kw">library</span>(Ball)</code></pre></div>
<pre><code>## Warning: 程辑包'Ball'是用R版本3.5.2 来建造的</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(boot)
m &lt;-<span class="st"> </span><span class="dv">103</span>; k&lt;-<span class="dv">3</span>; p&lt;-<span class="dv">2</span>; mu &lt;-<span class="st"> </span><span class="fl">0.5</span>; <span class="kw">set.seed</span>(<span class="dv">12345</span>)
n1 &lt;-<span class="st"> </span>n2 &lt;-<span class="st"> </span><span class="dv">50</span>; R&lt;-<span class="dv">999</span>; n &lt;-<span class="st"> </span>n1<span class="op">+</span>n2; N =<span class="st"> </span><span class="kw">c</span>(n1,n2)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Tn &lt;-<span class="st"> </span><span class="cf">function</span>(z, ix, sizes,k) {
n1 &lt;-<span class="st"> </span>sizes[<span class="dv">1</span>]
n2 &lt;-<span class="st"> </span>sizes[<span class="dv">2</span>]
n &lt;-<span class="st"> </span>n1 <span class="op">+</span><span class="st"> </span>n2
z &lt;-<span class="st"> </span>z[ix, ]
o &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">NROW</span>(z))
z &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">cbind</span>(z, o))
NN &lt;-<span class="st"> </span><span class="kw">nn2</span>(z, <span class="dt">k=</span>k<span class="op">+</span><span class="dv">1</span>)
block1 &lt;-<span class="st"> </span>NN<span class="op">$</span>nn.idx[<span class="dv">1</span><span class="op">:</span>n1,<span class="op">-</span><span class="dv">1</span>]
block2 &lt;-<span class="st"> </span>NN<span class="op">$</span>nn.idx[(n1<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span>n,<span class="op">-</span><span class="dv">1</span>]
i1 &lt;-<span class="st"> </span><span class="kw">sum</span>(block1 <span class="op">&lt;</span><span class="st"> </span>n1 <span class="op">+</span><span class="st"> </span>.<span class="dv">5</span>)
i2 &lt;-<span class="st"> </span><span class="kw">sum</span>(block2 <span class="op">&gt;</span><span class="st"> </span>n1 <span class="op">+</span><span class="st"> </span>.<span class="dv">5</span>)
<span class="kw">return</span>((i1 <span class="op">+</span><span class="st"> </span>i2) <span class="op">/</span><span class="st"> </span>(k <span class="op">*</span><span class="st"> </span>n))
}
eqdist.nn &lt;-<span class="st"> </span><span class="cf">function</span>(z,sizes,k){
  boot.obj &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data=</span>z,<span class="dt">statistic=</span>Tn,<span class="dt">R=</span>R,
  <span class="dt">sim =</span> <span class="st">&quot;permutation&quot;</span>, <span class="dt">sizes =</span> sizes,<span class="dt">k=</span>k)
  ts &lt;-<span class="st"> </span><span class="kw">c</span>(boot.obj<span class="op">$</span>t0,boot.obj<span class="op">$</span>t)
  p.value &lt;-<span class="st"> </span><span class="kw">mean</span>(ts<span class="op">&gt;=</span>ts[<span class="dv">1</span>])
  <span class="kw">list</span>(<span class="dt">statistic=</span>ts[<span class="dv">1</span>],<span class="dt">p.value=</span>p.value)
}
p.values &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>,m,<span class="dv">3</span>)

<span class="co">#Unequal variances and equal expectations</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p);
  y &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rnorm</span>(n2),<span class="kw">rnorm</span>(n2,<span class="dt">mean=</span>mu));
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value  <span class="co">#NN</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value  <span class="co">#energy method</span>
  p.values[i,<span class="dv">3</span>] &lt;-
<span class="st">    </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span>R,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value  <span class="co">#ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>                        <span class="co">#confidence level </span>
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow</code></pre></div>
<pre><code>## [1] 0.1456311 0.6116505 0.4271845</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Unequal variances and unequal expectations</span>
mu &lt;-<span class="st"> </span><span class="fl">0.6</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p);
  y &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rnorm</span>(n2),<span class="kw">rnorm</span>(n2,<span class="dt">mean=</span>mu));
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value  <span class="co">#NN</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value  <span class="co">#energy method</span>
  p.values[i,<span class="dv">3</span>] &lt;-
<span class="st">    </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span>R,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value  <span class="co">#ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>                        <span class="co">#confidence level </span>
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow</code></pre></div>
<pre><code>## [1] 0.2427184 0.7378641 0.5631068</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rt</span>(n1,<span class="dv">1</span>),<span class="kw">rnorm</span>(n2, <span class="dt">mean =</span> <span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">size =</span> n2, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="dt">replace =</span> T), <span class="dt">sd =</span><span class="dv">1</span> ))
  y &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rt</span>(n2,<span class="dv">1</span>),<span class="kw">rnorm</span>(n2, <span class="dt">mean =</span> <span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">size =</span> n2, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="dt">replace =</span> T), <span class="dt">sd =</span><span class="dv">1</span> ))
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value  <span class="co">#NN</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value  <span class="co">#energy method</span>
  p.values[i,<span class="dv">3</span>] &lt;-
<span class="st">    </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span>R,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value  <span class="co">#ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>                        <span class="co">#confidence level </span>
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow</code></pre></div>
<pre><code>## [1] 0.5048544 0.5922330 0.5242718</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Unbalanced samples (say, 1 case versus 10 controls)</span>
n1 &lt;-<span class="st"> </span><span class="dv">10</span>;n2 &lt;-<span class="st"> </span><span class="fl">1e2</span>;N =<span class="st"> </span><span class="kw">c</span>(n1,n2)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p);
  y &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rnorm</span>(n2),<span class="kw">rnorm</span>(n2,<span class="dt">mean=</span>mu));
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value  <span class="co">#NN</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value  <span class="co">#energy method</span>
  p.values[i,<span class="dv">3</span>] &lt;-
<span class="st">    </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span>R,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value  <span class="co">#ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>                        <span class="co">#confidence level </span>
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow</code></pre></div>
<pre><code>## [1] 0.1553398 0.3106796 0.1844660</code></pre>
</div>
<div id="question-3-3" class="section level2">
<h2>Question 3</h2>
<p>Use the Metropolis-Hastings sampler to generate random variables from a standard Cauchy distribution. Discard the first 1000 of the chain, and compare the deciles of the generated observations with the deciles of the standard Cauchy distribution (see qcauchy or qt with df=1). Recall that a <span class="math inline">\(Cauchy(\theta, \eta)\)</span> distribution has density function <span class="math display">\[
f(x) =\frac{1}
{\theta\pi(1 + [(x- \eta)/\theta]^2)}, - \infty &lt; x &lt; \infty, \theta&gt;0.
\]</span> The standard Cauchy has the <span class="math inline">\(Cauchy(\theta= 1, \eta = 0)\)</span> density. (Note that the standard Cauchy density is equal to the Student t density with one degree of freedom.)</p>
</div>
<div id="answer-16" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
<span class="kw">library</span>(stats)
theta &lt;-<span class="st"> </span><span class="dv">1</span>;eta &lt;-<span class="st"> </span><span class="dv">0</span>
m &lt;-<span class="st"> </span><span class="dv">10000</span>
x &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(x, theta,eta) {
<span class="cf">if</span> (theta <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) 
<span class="kw">return</span>(<span class="dv">1</span><span class="op">/</span>(theta<span class="op">*</span>pi<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>((x<span class="op">-</span>eta)<span class="op">/</span>theta)<span class="op">^</span><span class="dv">2</span>)))
}

x[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>,<span class="dt">min=</span><span class="op">-</span><span class="dv">1</span>,<span class="dt">max=</span><span class="dv">1</span>)
k &lt;-<span class="st"> </span><span class="dv">0</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>m) {
xt &lt;-<span class="st"> </span>x[i<span class="op">-</span><span class="dv">1</span>]
y &lt;-<span class="st"> </span>xt<span class="op">+</span><span class="kw">runif</span>(<span class="dv">1</span>,<span class="dt">min=</span><span class="op">-</span><span class="dv">1</span>,<span class="dt">max=</span><span class="dv">1</span>) <span class="co">#proposal distribution</span>
num &lt;-<span class="st"> </span><span class="kw">f</span>(y, theta,eta) <span class="op">*</span><span class="st"> </span><span class="kw">dnorm</span>(xt, <span class="dt">mean =</span> y,<span class="dt">sd=</span><span class="fl">0.5</span>)

den &lt;-<span class="st"> </span><span class="kw">f</span>(xt, theta,eta) <span class="op">*</span><span class="st"> </span><span class="kw">dnorm</span>(y, <span class="dt">mean =</span> xt,<span class="dt">sd=</span><span class="fl">0.5</span>)

<span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span>num<span class="op">/</span>den) x[i] &lt;-<span class="st"> </span>y 
<span class="cf">else</span> {
x[i] &lt;-<span class="st"> </span>xt
k &lt;-<span class="st"> </span>k<span class="op">+</span><span class="dv">1</span> <span class="co">#y is rejected</span>
}
}
<span class="kw">print</span>(k)</code></pre></div>
<pre><code>## [1] 1425</code></pre>
<p>Compare the deciles of the generated observations with the deciles of the standard Cauchy distribution</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b &lt;-<span class="st"> </span><span class="dv">1001</span> <span class="co">#discard the burnin sample</span>
y &lt;-<span class="st"> </span>x[b<span class="op">:</span>m]
a &lt;-<span class="st"> </span><span class="kw">ppoints</span>(<span class="dv">100</span>)
QC &lt;-<span class="st"> </span><span class="kw">qcauchy</span>(a) <span class="co">#quantiles of Cauchy</span>
Q &lt;-<span class="st"> </span><span class="kw">quantile</span>(x, a)
<span class="kw">qqplot</span>(QC, Q, <span class="dt">main=</span><span class="st">&quot;&quot;</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">xlab=</span><span class="st">&quot;Cauchy Quantiles&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Sample Quantiles&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(y, <span class="dt">breaks=</span><span class="st">&quot;scott&quot;</span>, <span class="dt">main=</span><span class="st">&quot;&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">lines</span>(QC, <span class="kw">f</span>(QC,theta,eta))</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="question-4-1" class="section level2">
<h2>Question 4</h2>
<p>Rao <span class="math inline">\([220, Sec. 5g]\)</span> presented an example on genetic linkage of 197 animals in four categories (also discussed in <span class="math inline">\([67, 106, 171, 266])\)</span>. The group sizes are <span class="math inline">\((125, 18, 20, 34)\)</span>. Assume that the probabilities of the corresponding multinomial distribution are <span class="math display">\[
(\frac12+\frac{\theta}{4},\frac{1-\theta}4,\frac{1-\theta}4,\frac{\theta}4).
\]</span> Estimate the posterior distribution of <span class="math inline">\(\theta\)</span> given the observed sample, using one of the methods in this chapter.</p>
</div>
<div id="answer-17" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
gsize &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">125</span>,<span class="dv">18</span>,<span class="dv">20</span>,<span class="dv">34</span>)  <span class="co">#group size</span>
m &lt;-<span class="st"> </span><span class="dv">5000</span>
w &lt;-<span class="st"> </span>.<span class="dv">25</span> 
burn &lt;-<span class="st"> </span><span class="dv">1000</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#the target density</span>
prob &lt;-<span class="st"> </span><span class="cf">function</span>(y, gsize) {
  <span class="cf">if</span> (y <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">||</span><span class="st"> </span>y <span class="op">&gt;</span><span class="dv">1</span>)
    <span class="kw">return</span> (<span class="dv">0</span>)
  <span class="cf">else</span>
  <span class="kw">return</span>((<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">+</span>y<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">1</span>] <span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>y)<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">2</span>]<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>y)<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">3</span>]<span class="op">*</span>(y<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">4</span>])
}

u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)  <span class="co">#for accept/reject step</span>
v &lt;-<span class="st"> </span><span class="kw">runif</span>(m, <span class="op">-</span>w, w)  <span class="co">#proposal distribution</span>
x[<span class="dv">1</span>] &lt;-<span class="st"> </span>.<span class="dv">25</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>m) {
  y &lt;-<span class="st"> </span>x[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>v[i]
  <span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span><span class="kw">prob</span>(y, gsize) <span class="op">/</span><span class="st"> </span><span class="kw">prob</span>(x[i<span class="op">-</span><span class="dv">1</span>], gsize))
    x[i] &lt;-<span class="st"> </span>y 
  <span class="cf">else</span>
    x[i] &lt;-<span class="st"> </span>x[i<span class="op">-</span><span class="dv">1</span>]
}
xtheta &lt;-<span class="st"> </span>x[(burn<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span>m]
theta.hat &lt;-<span class="st"> </span><span class="kw">mean</span>(xtheta)
theta.hat</code></pre></div>
<pre><code>## [1] 0.6199813</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##the estimate of posterior distribution of θ is shown above.</code></pre></div>
</div>
<div id="question-4-2" class="section level2">
<h2>Question 4</h2>
<p>Rao [220, Sec. 5g] presented an example on genetic linkage of 197 animals in four categories (also discussed in [67, 106, 171, 266]). The group sizes are 278 Statistical Computing with R (125, 18, 20, 34). Assume that the probabilities of the corresponding multinomial distribution are<span class="math display">\[(\frac{1}{2}+\frac{\theta}{4},\frac{1-\theta}{4},\frac{1-\theta}{4},\frac{\theta}{4}).\]</span> Estimate the posterior distribution of theta given the observed sample, using one of the methods in this chapter.</p>
</div>
<div id="answer-18" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
gsize &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">125</span>,<span class="dv">18</span>,<span class="dv">20</span>,<span class="dv">34</span>)  <span class="co">#group size</span>
m &lt;-<span class="st"> </span><span class="dv">5000</span>
w &lt;-<span class="st"> </span>.<span class="dv">25</span> 
burn &lt;-<span class="st"> </span><span class="dv">1000</span>
x &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#the target density</span>
prob &lt;-<span class="st"> </span><span class="cf">function</span>(y, gsize) {
  <span class="cf">if</span> (y <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">||</span><span class="st"> </span>y <span class="op">&gt;</span><span class="dv">1</span>)
    <span class="kw">return</span> (<span class="dv">0</span>)
  <span class="cf">else</span>
  <span class="kw">return</span>((<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">+</span>y<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">1</span>] <span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>y)<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">2</span>]<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>y)<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">3</span>]<span class="op">*</span>(y<span class="op">/</span><span class="dv">4</span>)<span class="op">^</span>gsize[<span class="dv">4</span>])
}

u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)  <span class="co">#for accept/reject step</span>
v &lt;-<span class="st"> </span><span class="kw">runif</span>(m, <span class="op">-</span>w, w)  <span class="co">#proposal distribution</span>
x[<span class="dv">1</span>] &lt;-<span class="st"> </span>.<span class="dv">25</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>m) {
  y &lt;-<span class="st"> </span>x[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>v[i]
  <span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span><span class="kw">prob</span>(y, gsize) <span class="op">/</span><span class="st"> </span><span class="kw">prob</span>(x[i<span class="op">-</span><span class="dv">1</span>], gsize))
    x[i] &lt;-<span class="st"> </span>y 
  <span class="cf">else</span>
    x[i] &lt;-<span class="st"> </span>x[i<span class="op">-</span><span class="dv">1</span>]
}
x</code></pre></div>
<pre><code>##    [1] 0.2500000 0.2445717 0.2445717 0.3866367 0.6005120 0.6334139
##    [7] 0.5923993 0.5923993 0.5923993 0.5923993 0.5923993 0.5899970
##   [13] 0.5899970 0.6135391 0.6135391 0.6935199 0.6935199 0.6834161
##   [19] 0.6834161 0.6834161 0.6834161 0.6834161 0.6834161 0.6834161
##   [25] 0.6834161 0.6834161 0.6834161 0.5971431 0.6418971 0.6418971
##   [31] 0.5979666 0.5979666 0.5979666 0.5979666 0.6742087 0.6742087
##   [37] 0.6742087 0.6742087 0.5714398 0.5714398 0.5714398 0.5714398
##   [43] 0.5714398 0.5714398 0.5941882 0.6889811 0.4829839 0.5313021
##   [49] 0.5313021 0.5313021 0.5313021 0.5313021 0.6673212 0.6673212
##   [55] 0.5599472 0.5599472 0.5599472 0.5599472 0.6388800 0.6388800
##   [61] 0.6388800 0.6388800 0.6388800 0.6388800 0.4794509 0.4794509
##   [67] 0.6272984 0.5836516 0.5836516 0.5836516 0.5836516 0.6632333
##   [73] 0.6632333 0.6632333 0.6632333 0.6632333 0.6932605 0.6978363
##   [79] 0.6978363 0.6978363 0.6978363 0.6978363 0.6978363 0.6978363
##   [85] 0.6978363 0.6978363 0.6950903 0.6950903 0.6950903 0.6950903
##   [91] 0.7413087 0.5881310 0.5881310 0.5881310 0.7075983 0.7075983
##   [97] 0.5954445 0.5954445 0.5954445 0.5954445 0.5933400 0.5933400
##  [103] 0.6434949 0.6434949 0.5248080 0.5408174 0.5408174 0.7162131
##  [109] 0.7162131 0.5128425 0.7328315 0.7328315 0.7328315 0.5077249
##  [115] 0.6469746 0.6413230 0.6413230 0.6413230 0.6413230 0.6354044
##  [121] 0.6354769 0.6354769 0.5361427 0.5361427 0.5361427 0.6843965
##  [127] 0.6843965 0.6843965 0.6843965 0.6843965 0.6843965 0.6843965
##  [133] 0.6843965 0.6843965 0.6843965 0.6843965 0.6843965 0.6843965
##  [139] 0.5564918 0.5564918 0.5564918 0.5554803 0.5554803 0.5554803
##  [145] 0.6858348 0.6858348 0.6858348 0.6641507 0.6641507 0.6641507
##  [151] 0.6641507 0.6641507 0.6641507 0.6641507 0.6641507 0.6657353
##  [157] 0.6657353 0.6657353 0.5500079 0.6979424 0.5606955 0.5606955
##  [163] 0.6815155 0.6815155 0.6352437 0.6563100 0.6563100 0.6455852
##  [169] 0.6455852 0.6455852 0.6455852 0.6455852 0.6455852 0.6455852
##  [175] 0.6145231 0.6145231 0.6145231 0.5859979 0.6446044 0.6446044
##  [181] 0.6446044 0.6446044 0.6446044 0.6446044 0.5958875 0.6738200
##  [187] 0.5784377 0.5784377 0.5993741 0.5993741 0.5993741 0.5993741
##  [193] 0.5993741 0.5993741 0.5800354 0.6135329 0.6135329 0.6135329
##  [199] 0.6135329 0.5586332 0.5586332 0.5586332 0.5586332 0.7020860
##  [205] 0.7020860 0.5413081 0.5413081 0.5413081 0.5498534 0.5498534
##  [211] 0.5498534 0.5498534 0.5498534 0.5498534 0.5540449 0.5583217
##  [217] 0.6867960 0.6867960 0.6867960 0.6867960 0.6867960 0.5439346
##  [223] 0.6066848 0.6066848 0.6066848 0.6066848 0.5824779 0.5824779
##  [229] 0.5824779 0.5824779 0.6877730 0.6877730 0.6762168 0.5859159
##  [235] 0.5859159 0.5859159 0.5859159 0.5859159 0.5533329 0.6247409
##  [241] 0.6247409 0.6112532 0.6112532 0.6112532 0.6112532 0.5843729
##  [247] 0.6296421 0.6296421 0.6296421 0.6296421 0.6802423 0.6802423
##  [253] 0.6802423 0.7327897 0.6348631 0.6348631 0.6348631 0.6348631
##  [259] 0.6348631 0.7057187 0.6770386 0.6770386 0.6770386 0.6770386
##  [265] 0.6770386 0.6770386 0.6770386 0.6770386 0.6875471 0.6875471
##  [271] 0.6875471 0.6875471 0.6875471 0.6875471 0.6875471 0.6875471
##  [277] 0.6875471 0.5586271 0.6250323 0.6250323 0.6250323 0.6250323
##  [283] 0.6250323 0.7223840 0.6823238 0.6375707 0.6375707 0.6375707
##  [289] 0.6375707 0.6375707 0.6375707 0.6375707 0.6375707 0.6375707
##  [295] 0.6375707 0.6375707 0.6079177 0.6168220 0.6168220 0.5788946
##  [301] 0.5415845 0.5415845 0.5415845 0.5415845 0.6915415 0.5882749
##  [307] 0.5882749 0.5882749 0.5882749 0.5882749 0.6313783 0.6313783
##  [313] 0.6313783 0.5465481 0.5465911 0.5875483 0.5875483 0.5875483
##  [319] 0.5875483 0.6407378 0.5193754 0.5193754 0.5061061 0.5061061
##  [325] 0.4576605 0.4576605 0.4576605 0.4576605 0.4576605 0.5890358
##  [331] 0.5890358 0.5890358 0.5890358 0.5890358 0.5942947 0.5942947
##  [337] 0.5942947 0.5585409 0.6571372 0.6571372 0.6571372 0.6355650
##  [343] 0.6355650 0.6355650 0.6355650 0.6355650 0.6355650 0.6853396
##  [349] 0.6853396 0.6853396 0.6384419 0.6384419 0.6384419 0.6384419
##  [355] 0.6438164 0.6438164 0.6438164 0.6209646 0.6209646 0.6209646
##  [361] 0.6209646 0.6209646 0.6209646 0.6209646 0.6209646 0.6209646
##  [367] 0.6209646 0.6209646 0.6209646 0.6209646 0.6209646 0.6209646
##  [373] 0.6209646 0.5921751 0.5921751 0.5921751 0.6833835 0.7264027
##  [379] 0.7264027 0.7264027 0.6067428 0.6067428 0.6067428 0.6067428
##  [385] 0.6067428 0.6067428 0.6067428 0.6067428 0.6067428 0.6067428
##  [391] 0.6067428 0.6067428 0.6067428 0.5925553 0.5574059 0.7002188
##  [397] 0.7002188 0.5862418 0.5862418 0.5862418 0.5862418 0.5991346
##  [403] 0.5991346 0.5991346 0.5991346 0.5991346 0.6515172 0.5275050
##  [409] 0.5275050 0.5275050 0.6682813 0.6323956 0.6323956 0.6323956
##  [415] 0.6323956 0.6323956 0.5702238 0.5702238 0.5702238 0.5702238
##  [421] 0.6461460 0.6461460 0.6461460 0.6461460 0.6461460 0.5792971
##  [427] 0.6557857 0.5963483 0.5963483 0.5963483 0.5705385 0.5705385
##  [433] 0.5705385 0.6552413 0.6552413 0.6622895 0.6622895 0.5291939
##  [439] 0.6907953 0.6735151 0.5689259 0.5689259 0.5689259 0.5689259
##  [445] 0.5689259 0.6193054 0.6193054 0.5470056 0.5470056 0.5470056
##  [451] 0.5759091 0.6755504 0.6755504 0.5817772 0.5817772 0.5817772
##  [457] 0.6309435 0.6309435 0.6309435 0.6309435 0.6762789 0.6507091
##  [463] 0.6185320 0.6185320 0.6185320 0.6185320 0.6185320 0.6185320
##  [469] 0.6260992 0.6260992 0.6796280 0.7418578 0.5021499 0.7152549
##  [475] 0.7152549 0.7152549 0.5445687 0.5403831 0.5403831 0.5403831
##  [481] 0.5403831 0.5403831 0.5403831 0.5403831 0.5424257 0.5424257
##  [487] 0.5547205 0.6741568 0.6183818 0.6183818 0.6502418 0.6502418
##  [493] 0.6502418 0.6502418 0.6502418 0.6502418 0.6502418 0.6364064
##  [499] 0.6364064 0.6472826 0.6472826 0.6472826 0.6472826 0.6472826
##  [505] 0.6437191 0.6437191 0.6090276 0.6090276 0.6090276 0.6062625
##  [511] 0.6062625 0.6062625 0.6062625 0.6062625 0.6062625 0.5827789
##  [517] 0.5827789 0.6740613 0.6129858 0.6178542 0.6178542 0.6178542
##  [523] 0.6178542 0.6178542 0.6178542 0.6531460 0.6531460 0.6053594
##  [529] 0.6053594 0.5972581 0.5972581 0.5972581 0.5972581 0.5972581
##  [535] 0.5972581 0.5972581 0.6351210 0.6351210 0.6351210 0.6351210
##  [541] 0.6351210 0.6351210 0.6351210 0.6351210 0.6351210 0.6351210
##  [547] 0.6873209 0.6873209 0.6354120 0.6354120 0.6261357 0.6261357
##  [553] 0.6070188 0.6070188 0.6070188 0.6070188 0.6070188 0.6070188
##  [559] 0.6070188 0.6070188 0.6070188 0.6070188 0.6070188 0.6070188
##  [565] 0.6070188 0.6588269 0.6588269 0.6588269 0.5974324 0.5974324
##  [571] 0.7019589 0.6839391 0.6839391 0.6839391 0.6839391 0.7006310
##  [577] 0.7006310 0.7006310 0.7006310 0.7006310 0.7006310 0.7006310
##  [583] 0.7006310 0.6366314 0.6907366 0.6907366 0.6907366 0.6907366
##  [589] 0.5532546 0.5532546 0.6393860 0.6393860 0.6393860 0.6393860
##  [595] 0.6393860 0.6677725 0.6449780 0.6449780 0.6668614 0.5827234
##  [601] 0.5849262 0.5849262 0.5849262 0.5849262 0.5849262 0.5849262
##  [607] 0.5849262 0.5849262 0.6477059 0.6477059 0.6477059 0.6477059
##  [613] 0.6477059 0.6477059 0.6477059 0.6477059 0.6477059 0.6477059
##  [619] 0.6477059 0.6477059 0.6477059 0.6477059 0.6413460 0.6413460
##  [625] 0.6413460 0.6413460 0.6413460 0.6413460 0.6413460 0.5442157
##  [631] 0.5442157 0.7109125 0.5595630 0.5595630 0.7105505 0.5688145
##  [637] 0.6976425 0.6976425 0.6976425 0.6976425 0.6976425 0.6976425
##  [643] 0.6976425 0.6886913 0.6886913 0.6886913 0.6886913 0.6184784
##  [649] 0.6297180 0.5927517 0.6659075 0.6659075 0.6659075 0.6659075
##  [655] 0.6659075 0.6152078 0.6152078 0.6152078 0.6152078 0.6258473
##  [661] 0.6258473 0.6258473 0.6258473 0.6258473 0.6258473 0.6258473
##  [667] 0.6258473 0.6258473 0.6258473 0.6549389 0.5876722 0.5876722
##  [673] 0.5876722 0.5876722 0.5876722 0.5876722 0.5876722 0.5876722
##  [679] 0.5876722 0.5876722 0.6336882 0.6336882 0.6336882 0.6336882
##  [685] 0.6939092 0.6939092 0.6939092 0.6939092 0.6265701 0.6175671
##  [691] 0.6175671 0.6175671 0.6175671 0.6175671 0.6175671 0.6512407
##  [697] 0.6512407 0.5649966 0.5649966 0.5649966 0.5514493 0.6976922
##  [703] 0.6976922 0.6976922 0.5885872 0.5885872 0.6398197 0.6398197
##  [709] 0.6398197 0.6898298 0.6898298 0.5536731 0.6439166 0.6103022
##  [715] 0.5553788 0.5553788 0.5553788 0.5553788 0.5995372 0.5995372
##  [721] 0.5995372 0.5995372 0.5995372 0.5995372 0.5995372 0.5995372
##  [727] 0.5995372 0.5995372 0.5995372 0.5995372 0.5995372 0.5995372
##  [733] 0.5995372 0.5995372 0.5995372 0.6355877 0.6355877 0.6355877
##  [739] 0.6355877 0.6355877 0.6355877 0.6263932 0.6033458 0.6033458
##  [745] 0.6033458 0.6033458 0.6033458 0.6033458 0.6033458 0.6033458
##  [751] 0.6033458 0.6033458 0.6033458 0.6464787 0.5709983 0.7109134
##  [757] 0.7109134 0.5906441 0.5906441 0.6159192 0.6095157 0.6095157
##  [763] 0.6537239 0.6537239 0.5951598 0.5951598 0.6307129 0.6456967
##  [769] 0.6783413 0.5885634 0.5885634 0.5885634 0.5885634 0.6279351
##  [775] 0.6279351 0.6074891 0.6074891 0.6074891 0.6074891 0.6074891
##  [781] 0.6074891 0.6074891 0.6074891 0.6074891 0.5814669 0.5814669
##  [787] 0.5881686 0.6210915 0.6210915 0.6210915 0.6210915 0.6210915
##  [793] 0.6210915 0.6210915 0.5321708 0.5321708 0.4954374 0.4954374
##  [799] 0.4824553 0.4824553 0.5393551 0.5393551 0.6150177 0.6150177
##  [805] 0.6150177 0.6150177 0.6150177 0.6150177 0.6150177 0.6150177
##  [811] 0.7195391 0.5268666 0.6142133 0.6142133 0.5349036 0.5548537
##  [817] 0.5548537 0.5548537 0.5548537 0.6896531 0.6896531 0.6896531
##  [823] 0.6699160 0.5371406 0.5370818 0.5330761 0.6124800 0.6124800
##  [829] 0.6124800 0.6124800 0.6124800 0.6124800 0.6124800 0.7360547
##  [835] 0.6943991 0.6943991 0.6943991 0.6943991 0.6943991 0.4492734
##  [841] 0.4492734 0.4934030 0.4934030 0.4934030 0.7081137 0.7081137
##  [847] 0.7081137 0.5840256 0.6780659 0.7067814 0.7067814 0.7067814
##  [853] 0.5380991 0.5952287 0.5952287 0.5952287 0.6344519 0.6344519
##  [859] 0.6344519 0.6344519 0.6344519 0.6486006 0.6665473 0.5881286
##  [865] 0.5881286 0.5881286 0.6711340 0.6711340 0.6711340 0.6711340
##  [871] 0.6711340 0.6733179 0.6375826 0.6375826 0.6190232 0.6190232
##  [877] 0.5515635 0.6444176 0.6444176 0.6444176 0.5961228 0.6980269
##  [883] 0.6980269 0.6980269 0.6980269 0.6980269 0.6980269 0.6864003
##  [889] 0.6864003 0.6864003 0.6864003 0.6864003 0.6864003 0.6864003
##  [895] 0.6864003 0.6604553 0.6604553 0.6604553 0.6604553 0.6604553
##  [901] 0.6604553 0.6604553 0.6604553 0.6604553 0.6604553 0.5968515
##  [907] 0.5968515 0.5968515 0.6006372 0.6006372 0.6006372 0.6006372
##  [913] 0.6006372 0.6006372 0.5606135 0.5606135 0.5606135 0.5606135
##  [919] 0.6343507 0.6343507 0.6169788 0.6169788 0.6169788 0.6553096
##  [925] 0.6553096 0.6553096 0.6553096 0.6303626 0.6303626 0.6303626
##  [931] 0.6303626 0.6303626 0.6303626 0.6303626 0.6646484 0.6646484
##  [937] 0.6343518 0.6343518 0.6343518 0.6343518 0.6343518 0.6343518
##  [943] 0.6343518 0.6282988 0.6282988 0.6207806 0.6207806 0.6376071
##  [949] 0.6376071 0.6831052 0.6831052 0.6831052 0.6422588 0.6422588
##  [955] 0.6422588 0.6422588 0.6422588 0.6422588 0.6422588 0.6136674
##  [961] 0.6421852 0.6415365 0.5630316 0.5880343 0.6910158 0.6910158
##  [967] 0.6910158 0.6910158 0.5665660 0.5665660 0.5894242 0.6963032
##  [973] 0.6963032 0.6060600 0.6060600 0.6060600 0.5893883 0.6302347
##  [979] 0.7226481 0.7338034 0.5903590 0.5903590 0.5903590 0.5903590
##  [985] 0.5903590 0.5903590 0.5903590 0.6151132 0.6151132 0.6151132
##  [991] 0.6165435 0.6165435 0.5544995 0.5449307 0.5796849 0.5796849
##  [997] 0.6060842 0.6060842 0.6060842 0.5745554 0.5745554 0.5326869
## [1003] 0.5326869 0.6184231 0.6184231 0.6184231 0.6184231 0.6184231
## [1009] 0.6184231 0.6184231 0.6184231 0.6749441 0.5963538 0.5963538
## [1015] 0.5963538 0.6661532 0.6661532 0.5984048 0.5984048 0.5984048
## [1021] 0.5984048 0.6519142 0.6519142 0.6519142 0.6519142 0.6519142
## [1027] 0.6519142 0.6519142 0.6519142 0.6519142 0.5782395 0.5782395
## [1033] 0.5782395 0.5782395 0.5782395 0.6721065 0.5474735 0.5474735
## [1039] 0.6758212 0.6758212 0.6758212 0.5855250 0.6698805 0.6698805
## [1045] 0.6698805 0.6698805 0.6383252 0.6383252 0.6383252 0.6408856
## [1051] 0.6303581 0.6303581 0.6303581 0.6303581 0.6303581 0.6598626
## [1057] 0.6598626 0.6598626 0.6438276 0.6438276 0.6762421 0.6762421
## [1063] 0.6762421 0.5572276 0.5572276 0.4843668 0.4843668 0.6273289
## [1069] 0.6273289 0.6273289 0.6747705 0.6747705 0.5942344 0.5942344
## [1075] 0.5942344 0.5942344 0.5942344 0.5942344 0.5942344 0.5942344
## [1081] 0.5613605 0.6663889 0.6663889 0.6663889 0.6663889 0.6539047
## [1087] 0.6539047 0.6539047 0.7229796 0.5548844 0.5548844 0.5548844
## [1093] 0.5548844 0.6026558 0.6026558 0.6026558 0.6026558 0.6026558
## [1099] 0.6026558 0.5994972 0.5994972 0.5994972 0.5994972 0.5994972
## [1105] 0.5994972 0.5994972 0.5994972 0.5994972 0.5994972 0.5994972
## [1111] 0.6133652 0.6133652 0.6133652 0.6330975 0.6330975 0.6330975
## [1117] 0.6330975 0.6330975 0.5758061 0.7290566 0.5778582 0.5778582
## [1123] 0.5438399 0.6898922 0.5786152 0.5786152 0.6493256 0.6493256
## [1129] 0.6493256 0.6493256 0.6493256 0.6817923 0.6819659 0.6819659
## [1135] 0.6819659 0.6819659 0.6819659 0.6819659 0.6819659 0.6819659
## [1141] 0.6819659 0.6819659 0.6819659 0.6819659 0.6819659 0.6819659
## [1147] 0.6135182 0.6135182 0.6691014 0.5562938 0.5562938 0.6515297
## [1153] 0.7125687 0.7125687 0.6024639 0.6024639 0.6024639 0.6024639
## [1159] 0.6024639 0.6024639 0.6024639 0.6024639 0.6089116 0.6089116
## [1165] 0.6215545 0.6215545 0.6465138 0.6310063 0.6310063 0.6310063
## [1171] 0.6310063 0.6310063 0.6310063 0.6310063 0.5704156 0.5704156
## [1177] 0.5791145 0.5791145 0.5791145 0.5791145 0.6559682 0.6559682
## [1183] 0.6559682 0.6559682 0.6559682 0.6559682 0.6559682 0.6559682
## [1189] 0.6559682 0.6559682 0.6559682 0.6559682 0.6559682 0.6559682
## [1195] 0.6559682 0.6967228 0.6967228 0.7242592 0.7242592 0.7242592
## [1201] 0.7242592 0.5982456 0.5809570 0.5809570 0.6024393 0.6842282
## [1207] 0.5609289 0.5609289 0.5917007 0.5954630 0.5830706 0.6775309
## [1213] 0.5705548 0.5705548 0.5705548 0.5884265 0.5884265 0.5884265
## [1219] 0.5884265 0.5884265 0.5884265 0.5884265 0.5354241 0.5354241
## [1225] 0.5354241 0.5862645 0.5862645 0.6170872 0.6170872 0.5972361
## [1231] 0.5040975 0.5512709 0.5512709 0.5512709 0.5512709 0.5512709
## [1237] 0.5512709 0.6850896 0.6850896 0.7126925 0.7126925 0.5774802
## [1243] 0.6104219 0.5783476 0.5783476 0.6509936 0.6509936 0.6509936
## [1249] 0.6509936 0.7123356 0.7123356 0.7123356 0.7123356 0.7123356
## [1255] 0.7123356 0.7123356 0.7123356 0.7123356 0.5507600 0.6185557
## [1261] 0.6185557 0.6185557 0.5323569 0.5928341 0.5928341 0.5928341
## [1267] 0.5928341 0.5928341 0.5928341 0.5928341 0.5928341 0.5928341
## [1273] 0.6140984 0.6140984 0.5892474 0.6169463 0.6169463 0.6169463
## [1279] 0.6169463 0.5818107 0.6030136 0.6030136 0.6030136 0.6030136
## [1285] 0.6030136 0.6030136 0.5470497 0.6968732 0.6968732 0.6968732
## [1291] 0.5336396 0.7169070 0.7169070 0.7169070 0.5135618 0.5135618
## [1297] 0.5135618 0.6126958 0.6126958 0.6126958 0.6126958 0.6126958
## [1303] 0.5982828 0.5982828 0.5982828 0.5982828 0.5840352 0.5840352
## [1309] 0.6534062 0.6534062 0.6534062 0.6534062 0.6534062 0.6534062
## [1315] 0.6534062 0.6534062 0.7525027 0.7525027 0.7525027 0.7525027
## [1321] 0.7525027 0.6783679 0.5227000 0.6184073 0.6956537 0.5411911
## [1327] 0.5411911 0.5411911 0.6586917 0.6868225 0.6868225 0.6733592
## [1333] 0.7586789 0.7586789 0.5273031 0.5273031 0.5273031 0.5273031
## [1339] 0.5273031 0.7327850 0.5162908 0.7015288 0.5599773 0.5599773
## [1345] 0.5618018 0.5895025 0.5895025 0.5895025 0.5895025 0.6570625
## [1351] 0.6570625 0.6570625 0.6570625 0.6570625 0.6570625 0.6570625
## [1357] 0.6570625 0.6570625 0.6635506 0.6196473 0.6196473 0.6676605
## [1363] 0.6225696 0.6225696 0.6225696 0.6030198 0.6534808 0.6534808
## [1369] 0.6534808 0.6998300 0.6998300 0.5095984 0.7090968 0.7090968
## [1375] 0.6448547 0.6448547 0.6448547 0.6448547 0.6448547 0.6448547
## [1381] 0.6448547 0.6448547 0.5868895 0.6934598 0.6934598 0.6934598
## [1387] 0.6934598 0.6934598 0.6410285 0.6683246 0.6683246 0.6683246
## [1393] 0.6715760 0.6715760 0.7014172 0.7014172 0.7014172 0.6842361
## [1399] 0.6842361 0.6842361 0.6842361 0.6842361 0.6842361 0.6842361
## [1405] 0.6842361 0.6842361 0.5388659 0.5388659 0.5388659 0.5388659
## [1411] 0.7602572 0.7602572 0.7602572 0.7602572 0.7465151 0.5551488
## [1417] 0.5551488 0.6352995 0.6352995 0.6352995 0.6352995 0.6352995
## [1423] 0.6352995 0.6352995 0.6352995 0.6352995 0.6352995 0.6352995
## [1429] 0.6352995 0.6352995 0.6352995 0.6352995 0.6985342 0.5800620
## [1435] 0.6347250 0.6347250 0.6347250 0.6347250 0.6347250 0.6347250
## [1441] 0.6347250 0.6347250 0.6347250 0.6347250 0.6347250 0.6347250
## [1447] 0.6347250 0.5650483 0.5650483 0.5650483 0.5650483 0.5650483
## [1453] 0.5650483 0.5650483 0.5650483 0.5650483 0.5650483 0.5650483
## [1459] 0.5486108 0.5486108 0.6924121 0.6924121 0.5426949 0.6342850
## [1465] 0.6342850 0.6342850 0.6342850 0.6342850 0.6342850 0.6342850
## [1471] 0.6378831 0.6378831 0.6378831 0.6378831 0.6378831 0.6378831
## [1477] 0.6378831 0.5853131 0.5853131 0.5853131 0.5853131 0.5853131
## [1483] 0.5844784 0.5844784 0.5844784 0.5844784 0.5844784 0.5844784
## [1489] 0.7441924 0.7441924 0.6226650 0.6226650 0.6820914 0.6820914
## [1495] 0.6820914 0.6820914 0.6820914 0.7128141 0.7014371 0.7014371
## [1501] 0.6790396 0.6790396 0.6790396 0.4995399 0.6619369 0.6619369
## [1507] 0.6619369 0.6619369 0.6496820 0.6496820 0.6496820 0.6496820
## [1513] 0.6496820 0.6189180 0.6025574 0.6463577 0.6295840 0.6604310
## [1519] 0.6150451 0.6150451 0.6150451 0.6150451 0.6150451 0.5596724
## [1525] 0.6286395 0.6286395 0.6753577 0.5611609 0.5611609 0.5611609
## [1531] 0.5611609 0.6804432 0.6804432 0.6804432 0.6804432 0.6804432
## [1537] 0.6804432 0.6804432 0.6804432 0.6804432 0.6804432 0.5621480
## [1543] 0.5621480 0.7199870 0.6744153 0.6744153 0.6744153 0.6987254
## [1549] 0.6987254 0.6987254 0.6987254 0.5530903 0.5530903 0.5530903
## [1555] 0.5550983 0.6910863 0.6910863 0.5720292 0.5720292 0.5720292
## [1561] 0.5720292 0.5720292 0.5720292 0.5720292 0.5720292 0.6673250
## [1567] 0.6745470 0.6745470 0.5714173 0.6845758 0.6845758 0.6845758
## [1573] 0.6796191 0.6067645 0.6067645 0.6417042 0.6417042 0.6417042
## [1579] 0.6417042 0.5107383 0.5765470 0.6695698 0.6695698 0.6026406
## [1585] 0.6396301 0.6396301 0.6396301 0.6396301 0.6396301 0.6396301
## [1591] 0.6733062 0.6733062 0.6105939 0.6105939 0.6105939 0.6105939
## [1597] 0.6105939 0.6105939 0.5961721 0.6099959 0.6099959 0.6099959
## [1603] 0.6099959 0.6099959 0.6099959 0.6099959 0.6099959 0.6099959
## [1609] 0.6099959 0.6099959 0.6220030 0.6220030 0.6220030 0.6220030
## [1615] 0.6258686 0.6258686 0.6258686 0.6258686 0.6178635 0.6178635
## [1621] 0.6178635 0.6059530 0.6059530 0.6059530 0.6624539 0.6624539
## [1627] 0.6624539 0.6624539 0.6624539 0.6624539 0.7386442 0.5720265
## [1633] 0.5720265 0.5720265 0.5934223 0.5934223 0.5934223 0.5934223
## [1639] 0.5934223 0.5934223 0.5934223 0.5577949 0.5577949 0.6408529
## [1645] 0.6408529 0.6408529 0.6408529 0.6408529 0.6408529 0.6408529
## [1651] 0.6408529 0.6408529 0.6408529 0.6408529 0.6408529 0.6580209
## [1657] 0.6580209 0.6580209 0.6580209 0.6580209 0.6580209 0.6580209
## [1663] 0.6417755 0.6417755 0.6417755 0.6417755 0.6417755 0.6417755
## [1669] 0.6680898 0.6680898 0.6680898 0.6680898 0.6680898 0.6680898
## [1675] 0.5861799 0.5919999 0.5919999 0.5919999 0.6443277 0.6443277
## [1681] 0.6073865 0.6073865 0.6073865 0.6489021 0.6123262 0.6123262
## [1687] 0.6123262 0.7149567 0.7149567 0.7149567 0.6571109 0.6571109
## [1693] 0.6571109 0.5524393 0.5524393 0.5524393 0.5500558 0.5500558
## [1699] 0.5500558 0.5500558 0.5500558 0.5500558 0.5720855 0.6120355
## [1705] 0.6120355 0.6120355 0.6120355 0.6120355 0.6120355 0.6361075
## [1711] 0.6361075 0.6361075 0.6361075 0.6361075 0.6361075 0.7075091
## [1717] 0.5517455 0.5517455 0.5517455 0.5517455 0.5517455 0.6612898
## [1723] 0.6612898 0.6612898 0.7143400 0.7143400 0.7143400 0.7143400
## [1729] 0.7143400 0.7535560 0.6314313 0.6314313 0.5843844 0.5843844
## [1735] 0.5843844 0.5843844 0.5843844 0.5382689 0.5739043 0.5739043
## [1741] 0.5739043 0.7037632 0.7037632 0.7037632 0.7037632 0.7037632
## [1747] 0.5602898 0.6896507 0.6896507 0.6896507 0.6896507 0.6896507
## [1753] 0.6896507 0.6440656 0.6440656 0.6440656 0.6440656 0.6440656
## [1759] 0.6440656 0.5966399 0.5966399 0.5966399 0.5966399 0.5966399
## [1765] 0.5966399 0.5490270 0.5490270 0.7207305 0.5618263 0.5552868
## [1771] 0.5552868 0.6608234 0.5682461 0.6833448 0.6838689 0.6838689
## [1777] 0.6838689 0.6838689 0.7459385 0.6977515 0.4968904 0.4968904
## [1783] 0.4968904 0.5817301 0.5817301 0.6632832 0.6632832 0.6632832
## [1789] 0.6632832 0.6632832 0.6632832 0.6632832 0.6632832 0.6632832
## [1795] 0.6632832 0.6632832 0.6632832 0.6936211 0.6292032 0.6292032
## [1801] 0.6292032 0.6292032 0.6292032 0.6292032 0.6292032 0.6292032
## [1807] 0.6292032 0.5347276 0.6172158 0.6172158 0.6172158 0.6172158
## [1813] 0.5498441 0.7239744 0.4801977 0.5254805 0.5254805 0.5254805
## [1819] 0.6707517 0.6707517 0.6707517 0.5559093 0.5559093 0.5559093
## [1825] 0.5559093 0.5559093 0.5930874 0.6455267 0.6455267 0.6455267
## [1831] 0.6455267 0.6455267 0.5891996 0.5891996 0.6502339 0.6502339
## [1837] 0.6502339 0.6502339 0.6502339 0.6502339 0.6502339 0.5366036
## [1843] 0.5366036 0.5366036 0.6742338 0.5732766 0.5359111 0.6884682
## [1849] 0.6884682 0.6884682 0.5756635 0.5756635 0.5756635 0.5756635
## [1855] 0.5756635 0.5756635 0.5398458 0.5398458 0.5398458 0.5398458
## [1861] 0.5398458 0.5509644 0.6988734 0.6203437 0.5852282 0.5852282
## [1867] 0.5852282 0.6065549 0.6065549 0.6267656 0.6108322 0.6108322
## [1873] 0.6108322 0.6182914 0.5395041 0.5732753 0.6729909 0.6729909
## [1879] 0.6500055 0.6500055 0.6500055 0.6500055 0.6500055 0.6500055
## [1885] 0.6500055 0.6500055 0.6500055 0.6500055 0.6500055 0.6500055
## [1891] 0.6723093 0.6723093 0.6723093 0.6723093 0.6723093 0.6723093
## [1897] 0.6955101 0.5693360 0.6527618 0.6527618 0.6307023 0.6307023
## [1903] 0.6307023 0.6307023 0.6042775 0.6890381 0.5591917 0.5272904
## [1909] 0.5272904 0.7066488 0.7066488 0.5318343 0.6690805 0.6690805
## [1915] 0.6690805 0.7228716 0.7228716 0.6538125 0.6538125 0.6538125
## [1921] 0.6103578 0.7211728 0.5209192 0.5209192 0.4900467 0.7359043
## [1927] 0.4903763 0.6621612 0.6621612 0.6621612 0.6621612 0.6541574
## [1933] 0.6541574 0.6670070 0.6670070 0.6670070 0.5120894 0.5366345
## [1939] 0.6371230 0.6371230 0.6371230 0.6508818 0.6508818 0.5559897
## [1945] 0.5559897 0.5559897 0.6455829 0.6440440 0.6171240 0.6171240
## [1951] 0.6494088 0.6666384 0.6446513 0.6446513 0.6446513 0.6446513
## [1957] 0.6446513 0.6446513 0.6446513 0.6446513 0.6446513 0.6446513
## [1963] 0.6446513 0.6107686 0.6107686 0.6107686 0.6030841 0.6065467
## [1969] 0.6065467 0.6159613 0.6159613 0.6159613 0.6785092 0.7075841
## [1975] 0.7075841 0.7075841 0.7075841 0.7075841 0.5495176 0.7051171
## [1981] 0.5398779 0.5398779 0.5398779 0.5398779 0.6328377 0.6442692
## [1987] 0.6442692 0.6442692 0.6442692 0.6442692 0.6442692 0.6442692
## [1993] 0.6442692 0.6442692 0.6442692 0.6442692 0.6442692 0.6442692
## [1999] 0.6442692 0.6442692 0.6442692 0.6442692 0.5844418 0.5844418
## [2005] 0.5844418 0.5844418 0.5844418 0.6206878 0.6949447 0.6949447
## [2011] 0.6949447 0.5754714 0.5754714 0.5754714 0.5787691 0.5616194
## [2017] 0.5616194 0.5616194 0.5480382 0.6874463 0.6874463 0.6874463
## [2023] 0.6874463 0.5765509 0.5765509 0.5765509 0.6763481 0.6763481
## [2029] 0.6763481 0.5857911 0.5857911 0.5857911 0.5857911 0.5857911
## [2035] 0.5544694 0.5544694 0.5544694 0.5544694 0.5544694 0.6548631
## [2041] 0.6833391 0.6833391 0.6833391 0.6833391 0.6833391 0.7387662
## [2047] 0.7387662 0.7387662 0.7142173 0.6558268 0.5482977 0.6067427
## [2053] 0.6391498 0.6426019 0.6570129 0.6570129 0.6570129 0.6570129
## [2059] 0.6570129 0.6168874 0.6168874 0.6168874 0.6168874 0.6168874
## [2065] 0.6298618 0.5929519 0.5929519 0.5929519 0.7272456 0.5332462
## [2071] 0.5332462 0.5332462 0.5332462 0.7120424 0.7064087 0.7064087
## [2077] 0.7064087 0.5353440 0.7038096 0.7038096 0.7038096 0.7038096
## [2083] 0.7038096 0.7038096 0.6957562 0.6559151 0.6559151 0.6559151
## [2089] 0.6550284 0.7000769 0.6994803 0.5351024 0.6178091 0.6302704
## [2095] 0.6302704 0.5799722 0.5799722 0.5799722 0.5799722 0.6663937
## [2101] 0.6663937 0.5810682 0.5952215 0.5390875 0.6877096 0.6877096
## [2107] 0.6877096 0.5556049 0.5683058 0.6646982 0.6646982 0.6485013
## [2113] 0.6485013 0.6485013 0.6480635 0.6480635 0.6480635 0.6480635
## [2119] 0.6480635 0.6480635 0.6480635 0.6480635 0.6480635 0.6480635
## [2125] 0.6480635 0.6480635 0.6480635 0.6480635 0.6480635 0.6480635
## [2131] 0.6480635 0.6480635 0.6480635 0.6480635 0.7096012 0.7485275
## [2137] 0.7485275 0.6508262 0.6254163 0.6254163 0.6254163 0.6588113
## [2143] 0.5620699 0.5680281 0.5680281 0.5546031 0.5546031 0.5546031
## [2149] 0.5546031 0.5546031 0.6097621 0.6097621 0.6097621 0.6097621
## [2155] 0.6097621 0.6097621 0.6097621 0.6097621 0.6097621 0.6097621
## [2161] 0.6097621 0.6097621 0.6097621 0.6097621 0.6051488 0.6051488
## [2167] 0.5600382 0.5600382 0.6553414 0.6553414 0.5700217 0.5700217
## [2173] 0.5700217 0.5700217 0.5700217 0.5823618 0.5823618 0.5823618
## [2179] 0.5823618 0.5823618 0.5823618 0.5823618 0.6752836 0.6752836
## [2185] 0.6752836 0.6752836 0.6752836 0.6752836 0.6938025 0.6938025
## [2191] 0.6938025 0.6938025 0.6938025 0.6938025 0.6302619 0.6302619
## [2197] 0.6302619 0.6302619 0.6302619 0.6302619 0.6302619 0.6289930
## [2203] 0.4880895 0.4880895 0.6743301 0.6743301 0.5823459 0.5823459
## [2209] 0.6691624 0.6333968 0.6333968 0.6333968 0.6333968 0.6097356
## [2215] 0.6097356 0.6097356 0.6455603 0.6455603 0.6455603 0.6455603
## [2221] 0.6455603 0.5659956 0.5659956 0.5568246 0.5144589 0.5144589
## [2227] 0.5144589 0.5144589 0.5114598 0.6896921 0.6896921 0.5697278
## [2233] 0.5697278 0.5043907 0.5051397 0.5051397 0.5051397 0.5051397
## [2239] 0.5400755 0.5400755 0.6089087 0.6089087 0.6089087 0.6089087
## [2245] 0.6089087 0.6089087 0.5830098 0.5523163 0.6213152 0.6213152
## [2251] 0.6590028 0.6675312 0.6675312 0.6675312 0.6675312 0.6244999
## [2257] 0.6244999 0.6498122 0.6498122 0.6498122 0.6498122 0.5848524
## [2263] 0.6526510 0.6221626 0.6221626 0.6221626 0.6221626 0.6009208
## [2269] 0.6009208 0.6009208 0.6009208 0.6009208 0.6009208 0.6009208
## [2275] 0.5495074 0.6232047 0.5808812 0.5808812 0.5475281 0.5475281
## [2281] 0.5475281 0.5475281 0.5475281 0.5475281 0.5475281 0.5896255
## [2287] 0.5896255 0.5896255 0.5896255 0.5896255 0.5896255 0.5896255
## [2293] 0.7176508 0.6020957 0.6020957 0.6020957 0.5860618 0.5860618
## [2299] 0.7334448 0.7334448 0.6882468 0.6047973 0.6047973 0.6047973
## [2305] 0.6047973 0.6657368 0.6657368 0.6388364 0.5767074 0.5845894
## [2311] 0.5845894 0.5845894 0.5946477 0.5946477 0.6463444 0.6463444
## [2317] 0.6463444 0.7056064 0.7056064 0.7056064 0.7056064 0.6782627
## [2323] 0.6782627 0.6782627 0.6432037 0.6815216 0.6287975 0.6287975
## [2329] 0.6287975 0.6287975 0.6287975 0.6287975 0.6287975 0.6287975
## [2335] 0.6287975 0.6287975 0.5572130 0.5572130 0.5572130 0.5572130
## [2341] 0.5572130 0.5572130 0.5843154 0.5843154 0.5843154 0.5843154
## [2347] 0.5843154 0.6740181 0.5668108 0.5668108 0.5668108 0.5668108
## [2353] 0.5555501 0.6998415 0.5122829 0.5122829 0.5122829 0.6598593
## [2359] 0.6482643 0.7202645 0.7202645 0.4973568 0.4973568 0.6143435
## [2365] 0.6143435 0.6407617 0.6718201 0.6759627 0.6759627 0.6330737
## [2371] 0.6120446 0.6120446 0.6120446 0.5820751 0.5820751 0.5820751
## [2377] 0.5820751 0.5820751 0.5820751 0.5820751 0.5508071 0.6695337
## [2383] 0.6695337 0.6695337 0.7254432 0.7254432 0.7254432 0.6727224
## [2389] 0.6727224 0.6337356 0.6337356 0.6337356 0.5404074 0.5404074
## [2395] 0.7061356 0.7061356 0.6613920 0.6613920 0.6562600 0.6038059
## [2401] 0.6038059 0.6038059 0.6038059 0.6038059 0.6038059 0.6038059
## [2407] 0.6038059 0.6038059 0.6038059 0.6038059 0.7153082 0.7153082
## [2413] 0.5407027 0.5407027 0.5407027 0.6028329 0.5615792 0.5867534
## [2419] 0.5867534 0.5867534 0.5867534 0.5867534 0.5867534 0.5867534
## [2425] 0.5867534 0.5867534 0.5867534 0.5867534 0.5867534 0.6332444
## [2431] 0.6221025 0.6062969 0.6062969 0.6258673 0.6258673 0.6258673
## [2437] 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673
## [2443] 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673
## [2449] 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673 0.6258673
## [2455] 0.6258673 0.6258673 0.6334499 0.6334499 0.6334499 0.6731081
## [2461] 0.6731081 0.6731081 0.6731081 0.6731081 0.6731081 0.6357579
## [2467] 0.6357579 0.6357579 0.6657630 0.6657630 0.6657630 0.6657630
## [2473] 0.6657630 0.6657630 0.6657630 0.6657630 0.6657630 0.6662121
## [2479] 0.6662121 0.6662121 0.7137999 0.7137999 0.7137999 0.7137999
## [2485] 0.5040794 0.5040794 0.5796386 0.5796386 0.6337812 0.6337812
## [2491] 0.6337812 0.6337812 0.6337812 0.6337812 0.6337812 0.6337812
## [2497] 0.6337812 0.6337812 0.6337812 0.6337812 0.6337812 0.6337812
## [2503] 0.6337812 0.6337812 0.6337812 0.6022465 0.6022465 0.6022465
## [2509] 0.6022465 0.6022465 0.6022465 0.5714026 0.5714026 0.5714026
## [2515] 0.5714026 0.5714026 0.5714026 0.5714026 0.5714026 0.5714026
## [2521] 0.5714026 0.5714026 0.5714026 0.6135249 0.6135249 0.6093898
## [2527] 0.6093898 0.5996069 0.5996069 0.5996069 0.5996069 0.5996069
## [2533] 0.6832098 0.6021328 0.6021328 0.6021328 0.6021328 0.7132905
## [2539] 0.7132905 0.7132905 0.5184750 0.7384455 0.7384455 0.6754540
## [2545] 0.6754540 0.6552783 0.6552783 0.5867414 0.5638484 0.6370261
## [2551] 0.6370261 0.6370261 0.6370261 0.6809476 0.6809476 0.6809476
## [2557] 0.6799862 0.5939431 0.5939431 0.5712649 0.5712649 0.5391561
## [2563] 0.5391561 0.5391561 0.6891563 0.6186505 0.5618611 0.6656226
## [2569] 0.6656226 0.6223146 0.6223146 0.6223146 0.6223146 0.6223146
## [2575] 0.6223146 0.6223146 0.6223146 0.6223146 0.7187288 0.7187288
## [2581] 0.4887933 0.7350465 0.7350465 0.7350465 0.6429346 0.6429346
## [2587] 0.6429346 0.6429346 0.5105331 0.5105331 0.5405396 0.6310650
## [2593] 0.6310650 0.6310650 0.6481263 0.6481263 0.6725739 0.6725739
## [2599] 0.6725739 0.6297510 0.6297510 0.6499423 0.6499423 0.6499423
## [2605] 0.5849564 0.5849564 0.5849564 0.5849564 0.5849564 0.5849564
## [2611] 0.5849564 0.6580733 0.6512921 0.6151746 0.6204132 0.5666018
## [2617] 0.5666018 0.5666018 0.6653020 0.6062523 0.6062523 0.6062523
## [2623] 0.6062523 0.6062523 0.6062523 0.6062523 0.6062523 0.5819129
## [2629] 0.5819129 0.5819129 0.6291497 0.5582401 0.5582401 0.5582401
## [2635] 0.5894295 0.5894295 0.5894295 0.5894295 0.5894295 0.5894295
## [2641] 0.6572781 0.6572781 0.6572781 0.6572781 0.6572781 0.6572781
## [2647] 0.6572781 0.6520189 0.6520189 0.6589466 0.6378402 0.6353197
## [2653] 0.6130468 0.6130468 0.6130468 0.6130468 0.5925864 0.5925864
## [2659] 0.5925864 0.5925864 0.6316086 0.6316086 0.6316086 0.6316086
## [2665] 0.4865103 0.5069925 0.5069925 0.5069925 0.5143401 0.5143401
## [2671] 0.7434957 0.7466118 0.7466118 0.6330649 0.6330649 0.7295177
## [2677] 0.7295177 0.7295177 0.6931397 0.6931397 0.6931397 0.6774477
## [2683] 0.6774477 0.6774477 0.5772712 0.5772712 0.5772712 0.5772712
## [2689] 0.5772712 0.5772712 0.5772712 0.6265574 0.6265574 0.6265574
## [2695] 0.6265574 0.6592841 0.6592841 0.6592841 0.6592841 0.6592841
## [2701] 0.6592841 0.6592841 0.6592841 0.6592841 0.6592841 0.6592841
## [2707] 0.6592841 0.6592841 0.6592841 0.6592841 0.6592841 0.6592841
## [2713] 0.6192301 0.6192301 0.6192301 0.6192301 0.6192301 0.5884829
## [2719] 0.5884829 0.5884829 0.5884829 0.5884829 0.5884829 0.5884829
## [2725] 0.5884829 0.5884829 0.5884829 0.5884829 0.5884829 0.5884829
## [2731] 0.5884829 0.5884829 0.5884829 0.5831014 0.5831014 0.5831014
## [2737] 0.5831014 0.5831014 0.6257218 0.6747483 0.6138981 0.6138981
## [2743] 0.6018656 0.6018656 0.6018656 0.6555763 0.6555763 0.6555763
## [2749] 0.6555763 0.6555763 0.6045534 0.5495172 0.5495172 0.5495172
## [2755] 0.5495172 0.6535420 0.6181700 0.6181700 0.6516349 0.6516349
## [2761] 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029
## [2767] 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029
## [2773] 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029 0.6553029
## [2779] 0.6553029 0.6553029 0.6553029 0.6553029 0.6321923 0.6129962
## [2785] 0.6129962 0.6129962 0.6129962 0.6129962 0.6129962 0.6454529
## [2791] 0.6454529 0.6733617 0.6733617 0.6733617 0.6733617 0.6733617
## [2797] 0.6733617 0.6733617 0.6353621 0.6353621 0.6353621 0.6353621
## [2803] 0.6353621 0.5982947 0.5982947 0.5982947 0.5982947 0.5628793
## [2809] 0.5628793 0.5796333 0.5796333 0.6001305 0.6001305 0.6001305
## [2815] 0.6515794 0.6515794 0.6515794 0.6515794 0.5498552 0.5809741
## [2821] 0.5809741 0.5809741 0.5809741 0.5809741 0.5809741 0.5809741
## [2827] 0.6281511 0.6281511 0.6272691 0.7443633 0.7443633 0.5083226
## [2833] 0.5739043 0.5739043 0.5739043 0.5739043 0.5739043 0.5739043
## [2839] 0.5739043 0.5739043 0.5739043 0.6004745 0.6004745 0.6004745
## [2845] 0.6652474 0.6652474 0.6652474 0.6652474 0.6652474 0.6738513
## [2851] 0.6738513 0.6738513 0.6738513 0.6738513 0.6738513 0.6738513
## [2857] 0.6738513 0.6581044 0.6581044 0.6581044 0.6581044 0.6581044
## [2863] 0.5347956 0.5769476 0.5769476 0.5769476 0.5769476 0.5769476
## [2869] 0.5769476 0.5769476 0.5769476 0.5769476 0.5769476 0.5769476
## [2875] 0.5769476 0.6983526 0.6983526 0.5551365 0.5551365 0.5551365
## [2881] 0.5551365 0.6292557 0.6369622 0.6369622 0.6369622 0.6102565
## [2887] 0.6102565 0.6102565 0.6102565 0.6286679 0.6286679 0.6286679
## [2893] 0.5483329 0.5912941 0.5912941 0.6695571 0.6695571 0.6674986
## [2899] 0.6674986 0.7206217 0.7307795 0.6014855 0.6014855 0.6083281
## [2905] 0.6083281 0.6083281 0.6083281 0.5706389 0.5706389 0.6603075
## [2911] 0.6603075 0.6603075 0.6030495 0.6030495 0.6030495 0.6030495
## [2917] 0.6510739 0.6510739 0.6510739 0.6510739 0.6510739 0.6510739
## [2923] 0.6510739 0.6510739 0.6510739 0.6173562 0.5946780 0.5946780
## [2929] 0.5946780 0.6584597 0.6584597 0.6584597 0.6584597 0.6584597
## [2935] 0.6584597 0.6584597 0.5274788 0.5274788 0.5274788 0.6981715
## [2941] 0.5532733 0.6746190 0.5619526 0.5619526 0.5619526 0.5619526
## [2947] 0.5619526 0.5619526 0.5619526 0.5619526 0.5619526 0.5619526
## [2953] 0.5619526 0.6027862 0.6027862 0.5982195 0.5982195 0.5651629
## [2959] 0.5651629 0.5651629 0.6820972 0.6709047 0.6013598 0.6013598
## [2965] 0.5884061 0.5884061 0.5884061 0.5884061 0.5884061 0.5884061
## [2971] 0.7770403 0.6444258 0.6471614 0.6471614 0.6471614 0.6471614
## [2977] 0.6471614 0.6583580 0.6380108 0.6380108 0.6380108 0.6380108
## [2983] 0.6380108 0.6380108 0.6380108 0.6547762 0.6547762 0.6547762
## [2989] 0.5126593 0.5633776 0.6341494 0.6606548 0.6606548 0.6687307
## [2995] 0.6687307 0.6687307 0.6687307 0.6687307 0.6687307 0.6687307
## [3001] 0.6687307 0.6739180 0.6820839 0.6820839 0.6820839 0.6487929
## [3007] 0.5975769 0.5975769 0.6327457 0.6327457 0.6327457 0.6676945
## [3013] 0.6676945 0.6308193 0.5918092 0.5918092 0.5624791 0.5909238
## [3019] 0.5909238 0.6249175 0.6249175 0.6249175 0.6249175 0.6249175
## [3025] 0.6016494 0.5799275 0.5799275 0.5799275 0.5799275 0.5182685
## [3031] 0.5182685 0.5897110 0.5938900 0.5938900 0.5938900 0.6942570
## [3037] 0.6942570 0.6942570 0.6942570 0.7142418 0.6262695 0.6262695
## [3043] 0.6262695 0.6262695 0.6262695 0.5515067 0.5515067 0.5983664
## [3049] 0.5983664 0.5983664 0.5983664 0.6194034 0.5990358 0.5990358
## [3055] 0.5990358 0.5990358 0.7303730 0.6176385 0.6176385 0.6127331
## [3061] 0.6127331 0.6127331 0.5540222 0.5985271 0.7176400 0.7352178
## [3067] 0.7352178 0.6070977 0.6070977 0.7116068 0.7116068 0.7116068
## [3073] 0.5528020 0.7167393 0.5828535 0.5828535 0.7199427 0.7199427
## [3079] 0.7199427 0.7199427 0.7199427 0.7199427 0.7199427 0.7199427
## [3085] 0.7291934 0.5884124 0.5884124 0.5884124 0.5884124 0.6428189
## [3091] 0.6354630 0.6354630 0.6354630 0.6354630 0.6354630 0.6354630
## [3097] 0.6354630 0.6354630 0.6354630 0.6354630 0.6573014 0.6573014
## [3103] 0.6366499 0.7002659 0.6564912 0.6564912 0.5985857 0.5985857
## [3109] 0.6531896 0.6531896 0.6531896 0.6531896 0.7057187 0.7057187
## [3115] 0.7057187 0.7057187 0.5928965 0.5928965 0.5928965 0.5928965
## [3121] 0.5928965 0.5928965 0.5928965 0.5928965 0.6988909 0.5942811
## [3127] 0.5942811 0.5942811 0.5942811 0.5383685 0.5383685 0.5383685
## [3133] 0.5140720 0.6673560 0.5201989 0.5201989 0.5201989 0.6032694
## [3139] 0.6032694 0.6448135 0.6448135 0.6448135 0.6448135 0.7072555
## [3145] 0.7348438 0.6476779 0.6476779 0.5817097 0.5751278 0.5804736
## [3151] 0.5672607 0.5672607 0.5672607 0.5672607 0.5672607 0.5598780
## [3157] 0.5598780 0.5598780 0.4971766 0.4971766 0.4971766 0.6412574
## [3163] 0.6412574 0.6412574 0.5975413 0.6578418 0.6299590 0.6299590
## [3169] 0.6409550 0.6409550 0.6409550 0.5872432 0.5872432 0.5872432
## [3175] 0.6860874 0.4955961 0.4955961 0.4955961 0.5968896 0.5968896
## [3181] 0.5968896 0.6433730 0.6433730 0.6433730 0.6433730 0.6433730
## [3187] 0.6433730 0.6347746 0.6347746 0.6347746 0.6347746 0.6347746
## [3193] 0.6347746 0.6347746 0.5792230 0.6919630 0.6919630 0.7085020
## [3199] 0.7085020 0.7085020 0.7085020 0.5468533 0.5468533 0.6099282
## [3205] 0.6099282 0.6099282 0.6099282 0.6099282 0.6099282 0.6099282
## [3211] 0.6099282 0.6099282 0.6501056 0.6193115 0.5716152 0.5716152
## [3217] 0.5716152 0.5312955 0.5312955 0.5100061 0.4830666 0.5215991
## [3223] 0.5215991 0.5215991 0.5210193 0.5651339 0.5341663 0.5341663
## [3229] 0.5341663 0.6773486 0.6773486 0.5865681 0.5546557 0.5546557
## [3235] 0.5546557 0.5546557 0.5546557 0.6612286 0.6612286 0.6612286
## [3241] 0.5146069 0.5146069 0.6295028 0.6295028 0.6295028 0.6295028
## [3247] 0.6295028 0.5372798 0.5372798 0.6874704 0.7016644 0.7016644
## [3253] 0.6428589 0.6428589 0.6428589 0.6428589 0.6428589 0.6428589
## [3259] 0.6428589 0.6428589 0.6428589 0.6428589 0.6428589 0.6428589
## [3265] 0.6428589 0.6428589 0.6428589 0.6428589 0.5343363 0.5822387
## [3271] 0.5822387 0.5822387 0.5793006 0.5657344 0.6532808 0.6532808
## [3277] 0.6532808 0.6532808 0.6877024 0.6877024 0.6751927 0.6751927
## [3283] 0.6701824 0.6502485 0.6502485 0.5903959 0.5903959 0.5903959
## [3289] 0.5903959 0.5903959 0.6081158 0.6376804 0.6376804 0.6376804
## [3295] 0.6376804 0.6376804 0.6376804 0.5789762 0.5789762 0.6634757
## [3301] 0.6634757 0.6634757 0.6634757 0.6634757 0.6634757 0.6634757
## [3307] 0.6634757 0.6634757 0.6634757 0.5999523 0.5999523 0.5999523
## [3313] 0.5999523 0.5999523 0.5999523 0.6402540 0.6624277 0.6407198
## [3319] 0.6407198 0.6407198 0.6407198 0.6407198 0.5702411 0.5702411
## [3325] 0.5702411 0.5702411 0.6082672 0.6111505 0.6111505 0.6275722
## [3331] 0.5994278 0.5994278 0.6212557 0.6212557 0.6212557 0.6212557
## [3337] 0.6212557 0.6212557 0.6212557 0.6212557 0.6270844 0.6270844
## [3343] 0.6270844 0.6270844 0.7160295 0.4887052 0.4887052 0.4887052
## [3349] 0.7070684 0.5612052 0.5612052 0.5612052 0.5612052 0.5834852
## [3355] 0.5834852 0.5834852 0.5612453 0.5612453 0.5612453 0.5612453
## [3361] 0.5612453 0.5612453 0.5612453 0.5612453 0.5612453 0.5282501
## [3367] 0.5498263 0.5498263 0.5498263 0.5498263 0.6815655 0.6815655
## [3373] 0.5975240 0.5975240 0.5975240 0.5884968 0.5884968 0.5884968
## [3379] 0.5884968 0.5884968 0.5884968 0.5529232 0.5529232 0.6254893
## [3385] 0.6254893 0.6254893 0.6475178 0.6475178 0.6475178 0.6177806
## [3391] 0.6177806 0.5543333 0.5543333 0.7101876 0.7254123 0.7254123
## [3397] 0.7254123 0.7030215 0.6472811 0.6472811 0.6984219 0.6491645
## [3403] 0.6491645 0.5008214 0.5419185 0.5419185 0.5419185 0.5419185
## [3409] 0.5419185 0.5419185 0.5536503 0.5536503 0.6514667 0.6692692
## [3415] 0.6692692 0.6692692 0.6692692 0.6126655 0.6126655 0.6126655
## [3421] 0.6126655 0.6126655 0.6126655 0.6126655 0.6126655 0.6126655
## [3427] 0.6086091 0.6086091 0.6086091 0.6086091 0.6156270 0.6077057
## [3433] 0.6077057 0.6877966 0.6877966 0.6877966 0.6877966 0.6877966
## [3439] 0.6877966 0.6877966 0.6877966 0.6234773 0.6234773 0.6234773
## [3445] 0.6474846 0.6474846 0.6474846 0.6474846 0.6474846 0.6474846
## [3451] 0.6474846 0.6474846 0.6474846 0.5091990 0.5091990 0.6515970
## [3457] 0.6889612 0.6889612 0.6889612 0.5933365 0.5933365 0.5933365
## [3463] 0.5933365 0.5933365 0.5933365 0.6080571 0.6080571 0.6080571
## [3469] 0.6080571 0.6080571 0.6080571 0.6080571 0.6568180 0.6568180
## [3475] 0.6568180 0.6568180 0.6568180 0.6568180 0.6568180 0.6568180
## [3481] 0.6568180 0.6568180 0.6568180 0.6568180 0.6568180 0.6568180
## [3487] 0.6568180 0.6568180 0.6568180 0.6166950 0.5844770 0.5844770
## [3493] 0.6665932 0.6665932 0.6665932 0.6665932 0.6665932 0.6665932
## [3499] 0.6665932 0.6665932 0.6665932 0.6665932 0.6665932 0.5693793
## [3505] 0.6363214 0.6363214 0.6363214 0.6885630 0.6885630 0.6105836
## [3511] 0.6105836 0.6105836 0.6105836 0.6105836 0.6105836 0.6105836
## [3517] 0.6105836 0.6105836 0.6105836 0.6105836 0.6105836 0.6105836
## [3523] 0.6612644 0.5249141 0.5249141 0.5249141 0.5249141 0.5249141
## [3529] 0.7416607 0.7416607 0.6124559 0.6124559 0.6124559 0.5700898
## [3535] 0.6809410 0.6809410 0.6809410 0.6809410 0.6809410 0.6809410
## [3541] 0.6583402 0.6583402 0.6583402 0.6583402 0.6583402 0.6583402
## [3547] 0.6144729 0.6144729 0.6144729 0.6144729 0.6144729 0.6144729
## [3553] 0.6144729 0.6144729 0.6144729 0.6144729 0.6130421 0.6130421
## [3559] 0.6130421 0.6130421 0.5380929 0.5380929 0.6751680 0.6751680
## [3565] 0.6751680 0.6751680 0.6299141 0.6299141 0.6299141 0.5569910
## [3571] 0.5569537 0.6834826 0.6834826 0.5058499 0.5058499 0.5058499
## [3577] 0.5058499 0.5058499 0.6545003 0.6545003 0.6545003 0.6545003
## [3583] 0.6545003 0.6545003 0.6545003 0.6341297 0.6341297 0.5779323
## [3589] 0.5768935 0.5561137 0.6758491 0.6758491 0.6758491 0.6758491
## [3595] 0.6758491 0.6758491 0.6758491 0.6758491 0.6758491 0.6758491
## [3601] 0.5798595 0.5798595 0.5798595 0.5798595 0.5798595 0.6288654
## [3607] 0.6674221 0.5524088 0.6679358 0.6679358 0.6679358 0.6679358
## [3613] 0.6679358 0.6602382 0.6602382 0.6602382 0.6602382 0.6602382
## [3619] 0.6602382 0.6602382 0.6602382 0.6602382 0.6602382 0.6602382
## [3625] 0.6602382 0.6602382 0.6602382 0.6602382 0.6602382 0.6892698
## [3631] 0.6892698 0.6892698 0.6892698 0.6968280 0.6968280 0.6447167
## [3637] 0.6050967 0.6050967 0.6726261 0.6726261 0.6726261 0.6726261
## [3643] 0.6726261 0.6726261 0.6726261 0.6599385 0.6599385 0.6599385
## [3649] 0.6599385 0.6599385 0.6470832 0.6470832 0.6470832 0.6470832
## [3655] 0.6199783 0.6199783 0.6199783 0.6199783 0.5062734 0.5062734
## [3661] 0.5770384 0.5770384 0.5770384 0.5770384 0.5603723 0.5603723
## [3667] 0.5603723 0.5603723 0.5603723 0.5603723 0.5328087 0.5328087
## [3673] 0.5328087 0.5328087 0.5516541 0.5516541 0.6306109 0.6709210
## [3679] 0.6858777 0.6858777 0.6858777 0.4849826 0.5986283 0.5986283
## [3685] 0.5986283 0.5986283 0.5986283 0.5986283 0.5986283 0.5986283
## [3691] 0.6206094 0.6206094 0.6206094 0.6206094 0.6206094 0.6206094
## [3697] 0.6206094 0.6206094 0.6206094 0.6206094 0.7031344 0.7031344
## [3703] 0.7031344 0.6067994 0.6067994 0.6067994 0.6067994 0.6067994
## [3709] 0.6511797 0.6511797 0.6511797 0.6511797 0.6511797 0.7091613
## [3715] 0.6434815 0.6434815 0.6434815 0.6430753 0.6430753 0.6430753
## [3721] 0.5667676 0.5667676 0.5667676 0.5667676 0.5667676 0.5667676
## [3727] 0.5928763 0.5928763 0.5928763 0.5928763 0.5928763 0.5928763
## [3733] 0.6125907 0.5875572 0.5875572 0.5875572 0.5875572 0.6264361
## [3739] 0.6264361 0.6264361 0.6264361 0.6264361 0.6427863 0.6427863
## [3745] 0.6427863 0.5858171 0.5858171 0.5858171 0.6712364 0.6712364
## [3751] 0.6712364 0.6712364 0.6712364 0.6712364 0.6712364 0.6730050
## [3757] 0.6730050 0.6730050 0.6812527 0.6488704 0.6488704 0.6124103
## [3763] 0.6124103 0.6124103 0.6984782 0.6984782 0.6984782 0.5110058
## [3769] 0.5110058 0.5704557 0.5704557 0.5704557 0.5704557 0.5704557
## [3775] 0.5704557 0.5704557 0.5704557 0.5717842 0.5931685 0.5931685
## [3781] 0.5931685 0.5931685 0.5931685 0.5855428 0.6729682 0.6729682
## [3787] 0.6359157 0.6359157 0.6359157 0.6359157 0.6359157 0.6359157
## [3793] 0.6359157 0.6359157 0.6359157 0.6359157 0.6359157 0.6359157
## [3799] 0.5548768 0.6485448 0.5819771 0.5819771 0.5819771 0.5819771
## [3805] 0.5819771 0.5819771 0.5819771 0.5819771 0.6116497 0.6116497
## [3811] 0.6019947 0.6019947 0.6019947 0.6019947 0.6019947 0.6481747
## [3817] 0.6427822 0.6089337 0.6089337 0.6089337 0.6089337 0.6089337
## [3823] 0.6089337 0.6089337 0.6089337 0.6089337 0.6661644 0.6661644
## [3829] 0.6661644 0.6661644 0.6661644 0.6181419 0.6181419 0.6385209
## [3835] 0.6385209 0.6385209 0.6188796 0.6188796 0.6188796 0.6188796
## [3841] 0.6188796 0.6188796 0.6189540 0.6189540 0.6189540 0.6189540
## [3847] 0.6189540 0.6189540 0.6189540 0.6977025 0.6977025 0.6977025
## [3853] 0.6977025 0.6977025 0.6977025 0.6977025 0.6790355 0.6790355
## [3859] 0.6392452 0.6939868 0.6939868 0.6939868 0.6939868 0.7250855
## [3865] 0.7250855 0.6408129 0.6844399 0.6098467 0.6098467 0.6098467
## [3871] 0.6098467 0.5160310 0.6644868 0.5873460 0.5873460 0.5848696
## [3877] 0.5405579 0.5405579 0.5405579 0.5405579 0.5405579 0.5405579
## [3883] 0.5405579 0.5436941 0.5436941 0.6078463 0.6078463 0.6153561
## [3889] 0.6153561 0.6153561 0.6153561 0.6153561 0.6153561 0.6153561
## [3895] 0.6638910 0.6638910 0.6658353 0.6658353 0.6658353 0.6658353
## [3901] 0.5522565 0.5926453 0.6509381 0.6509381 0.6509381 0.6244518
## [3907] 0.6244518 0.6244518 0.6416410 0.6416410 0.6416410 0.6416410
## [3913] 0.6541251 0.6541251 0.6704062 0.6141981 0.6141981 0.6141981
## [3919] 0.6141981 0.6141981 0.6141981 0.6141981 0.6141981 0.6141981
## [3925] 0.6928719 0.6928719 0.6946552 0.5595123 0.5595123 0.5513187
## [3931] 0.6824152 0.6824152 0.6824152 0.6824152 0.6824152 0.6824152
## [3937] 0.5682482 0.5682482 0.6903406 0.6903406 0.6903406 0.7177085
## [3943] 0.7177085 0.7177085 0.7177085 0.7177085 0.7188897 0.7188897
## [3949] 0.5974383 0.5974383 0.5974383 0.5974383 0.6833670 0.6833670
## [3955] 0.6833670 0.6833670 0.6833670 0.6833670 0.6833670 0.6833670
## [3961] 0.6222643 0.6222643 0.6222643 0.6135493 0.6135493 0.6519723
## [3967] 0.6519723 0.6519723 0.6519723 0.6082257 0.6347667 0.6347667
## [3973] 0.6347667 0.6347667 0.6347667 0.6347667 0.6219780 0.6219780
## [3979] 0.5811549 0.5811549 0.5811549 0.5811549 0.5811549 0.5811549
## [3985] 0.5811549 0.5811549 0.5811549 0.5811549 0.5811549 0.5811549
## [3991] 0.5880526 0.5880526 0.6612648 0.6612648 0.6612648 0.6612648
## [3997] 0.6612648 0.6612648 0.5676703 0.6989272 0.6989272 0.6989272
## [4003] 0.6989272 0.6445052 0.6445052 0.6445052 0.6445052 0.6553021
## [4009] 0.6553021 0.6553021 0.7353753 0.6041131 0.5727954 0.5727954
## [4015] 0.6495813 0.6495813 0.6495813 0.6495813 0.6495813 0.6457083
## [4021] 0.6457083 0.5403906 0.5403906 0.5403906 0.5403906 0.5403906
## [4027] 0.5403906 0.5403906 0.5403906 0.5403906 0.6381192 0.6381192
## [4033] 0.6381192 0.6522811 0.6522811 0.6522811 0.6522811 0.6522811
## [4039] 0.6522811 0.6522811 0.6522811 0.6522811 0.6522811 0.6012041
## [4045] 0.6012041 0.6060274 0.6710486 0.6710486 0.6710486 0.6660880
## [4051] 0.7236919 0.5722113 0.5897366 0.5897366 0.6165329 0.6165329
## [4057] 0.6165329 0.6165329 0.6165329 0.6165329 0.6165329 0.6165329
## [4063] 0.6165329 0.6165329 0.6165329 0.6650980 0.5884443 0.6909081
## [4069] 0.6717685 0.6717685 0.4783974 0.4783974 0.4783974 0.4783974
## [4075] 0.4783974 0.4783974 0.4540322 0.4540322 0.6200808 0.5405579
## [4081] 0.5405579 0.5405579 0.5405579 0.5405579 0.5187328 0.5187328
## [4087] 0.5187328 0.5187328 0.5187328 0.6090521 0.6195287 0.6195287
## [4093] 0.6195287 0.6195287 0.5635817 0.5635817 0.5594885 0.5719947
## [4099] 0.5719947 0.5719947 0.5719947 0.5719947 0.5719947 0.5719947
## [4105] 0.5952861 0.5952861 0.6093854 0.6093854 0.6493923 0.6493923
## [4111] 0.6493923 0.6493923 0.6493923 0.6493923 0.6493923 0.6121934
## [4117] 0.6121934 0.6121934 0.5710086 0.6070725 0.6413702 0.6413702
## [4123] 0.6734299 0.6734299 0.5844834 0.5844834 0.5844834 0.5844834
## [4129] 0.5844834 0.5844834 0.6447037 0.6447037 0.6447037 0.6447037
## [4135] 0.6447037 0.6447037 0.6447037 0.6733178 0.6733178 0.6246061
## [4141] 0.6246061 0.6671424 0.5676766 0.5676766 0.5099629 0.6601431
## [4147] 0.6601431 0.6788181 0.6788181 0.6788181 0.6788181 0.6558621
## [4153] 0.5976170 0.5976170 0.5976170 0.5976170 0.5976170 0.5976170
## [4159] 0.5976170 0.7043592 0.7043592 0.7043592 0.7043592 0.6827230
## [4165] 0.6834218 0.6834218 0.5589196 0.5589196 0.5550154 0.6581872
## [4171] 0.6581872 0.6581872 0.6581872 0.5722514 0.5722514 0.5722514
## [4177] 0.5722514 0.6236800 0.6236800 0.6236800 0.6236800 0.6236800
## [4183] 0.5725013 0.6252567 0.6252567 0.6252567 0.6252567 0.6252567
## [4189] 0.6252567 0.6252567 0.6252567 0.6252567 0.6252567 0.5464377
## [4195] 0.6221090 0.6221090 0.5630060 0.5713565 0.6710138 0.6710138
## [4201] 0.6710138 0.6392284 0.6110511 0.6110511 0.6110511 0.6110511
## [4207] 0.5675673 0.6680133 0.6680133 0.6680133 0.6103283 0.6103283
## [4213] 0.6103283 0.6387996 0.6020319 0.6020319 0.6020319 0.5848375
## [4219] 0.5848375 0.6591481 0.6591481 0.5518626 0.6869609 0.7047379
## [4225] 0.7047379 0.7540931 0.6289984 0.5623155 0.5623155 0.5623155
## [4231] 0.5481770 0.5481770 0.5481770 0.5880163 0.5880163 0.5880163
## [4237] 0.5616664 0.7162020 0.7162020 0.7343335 0.7343335 0.5835166
## [4243] 0.5835166 0.5835166 0.5835166 0.5976905 0.5976905 0.5976905
## [4249] 0.6198362 0.6105167 0.6266560 0.6064219 0.6064219 0.6079565
## [4255] 0.6518428 0.6518428 0.6518428 0.6518428 0.6335538 0.6335538
## [4261] 0.6401773 0.6401773 0.6389901 0.6389901 0.5822399 0.5822399
## [4267] 0.5992420 0.5992420 0.6554356 0.6554356 0.6597312 0.6811387
## [4273] 0.5687170 0.5687170 0.5687170 0.5687170 0.5687170 0.7393118
## [4279] 0.5383029 0.5383029 0.5383029 0.6255579 0.6255579 0.6980160
## [4285] 0.6099036 0.6099036 0.5761933 0.5761933 0.5605539 0.5605539
## [4291] 0.5605539 0.5605539 0.5605539 0.6126251 0.6126251 0.6126251
## [4297] 0.6126251 0.6126251 0.6126251 0.6126251 0.6126251 0.6126251
## [4303] 0.6126251 0.6126251 0.5813946 0.5813946 0.5813946 0.5360355
## [4309] 0.5360355 0.7142242 0.7142242 0.5935202 0.5935202 0.6530282
## [4315] 0.6530282 0.6530282 0.6623675 0.6623675 0.6623675 0.5962861
## [4321] 0.5667998 0.5667998 0.5667998 0.5667998 0.5667998 0.5667998
## [4327] 0.5508542 0.4946188 0.4946188 0.6164533 0.6164533 0.6164533
## [4333] 0.7559942 0.7574599 0.7098949 0.7073866 0.7073866 0.7073866
## [4339] 0.7073866 0.6487824 0.6487824 0.6487824 0.6487824 0.6487824
## [4345] 0.6487824 0.6487824 0.6022631 0.6022631 0.6022631 0.6011514
## [4351] 0.6011514 0.6011514 0.6011514 0.6011514 0.6011514 0.6011514
## [4357] 0.6011514 0.6011514 0.5020612 0.5020612 0.5017159 0.6682775
## [4363] 0.6682775 0.6682775 0.6682775 0.6682775 0.6682775 0.6132685
## [4369] 0.5725472 0.5725472 0.5725472 0.6401610 0.6401610 0.6164323
## [4375] 0.6164323 0.5535887 0.6728122 0.6728122 0.6728122 0.6068083
## [4381] 0.6349915 0.6349915 0.6825126 0.6825126 0.6825126 0.6825126
## [4387] 0.6825126 0.6729301 0.6729301 0.6729301 0.5821956 0.5368654
## [4393] 0.7103096 0.7103096 0.7654556 0.7654556 0.5499896 0.5499896
## [4399] 0.5499896 0.5304680 0.6271316 0.6271316 0.5571918 0.5571918
## [4405] 0.5571918 0.5571918 0.5571918 0.5571918 0.5571918 0.5822110
## [4411] 0.5822110 0.5822110 0.5822110 0.5822110 0.7045504 0.7045504
## [4417] 0.6424570 0.6035380 0.6035380 0.6035380 0.6035380 0.6035380
## [4423] 0.6035380 0.6295524 0.6295524 0.6295524 0.6448772 0.6448772
## [4429] 0.6448772 0.6448772 0.6448772 0.6448772 0.6521491 0.6521491
## [4435] 0.6521491 0.6521491 0.6024809 0.6024809 0.6517103 0.5924834
## [4441] 0.6770271 0.6770271 0.6770271 0.6954513 0.6954513 0.6954513
## [4447] 0.7088982 0.6750117 0.6750117 0.6750117 0.6750117 0.6750117
## [4453] 0.6750117 0.6985263 0.6985263 0.6513702 0.6513702 0.6273981
## [4459] 0.6273981 0.6273981 0.6396642 0.6396642 0.6396642 0.6396642
## [4465] 0.6396642 0.6396642 0.6396642 0.6396642 0.6396642 0.6214562
## [4471] 0.6214562 0.6214562 0.6214562 0.6214562 0.6462208 0.6462208
## [4477] 0.6747475 0.6676380 0.6676380 0.6676380 0.6676380 0.6676380
## [4483] 0.6676380 0.6676380 0.6676380 0.6676380 0.6676380 0.6474066
## [4489] 0.6474066 0.6474066 0.6474066 0.6474066 0.6474066 0.6474066
## [4495] 0.6474066 0.6474066 0.6474066 0.6474066 0.6312846 0.5701944
## [4501] 0.6482643 0.6482643 0.6482643 0.6482643 0.6482643 0.6248431
## [4507] 0.5879899 0.5879899 0.5879899 0.5879899 0.5550288 0.5550288
## [4513] 0.5849520 0.5849520 0.5849520 0.5849520 0.6211344 0.6211344
## [4519] 0.6211344 0.5591026 0.5591026 0.6172850 0.6172850 0.6172850
## [4525] 0.5937237 0.5930733 0.5930733 0.5930733 0.5930733 0.7211825
## [4531] 0.7211825 0.7211825 0.7211825 0.7211825 0.6667709 0.6957212
## [4537] 0.6957212 0.6281570 0.6358552 0.6358552 0.7234204 0.7485169
## [4543] 0.7485169 0.7344340 0.7344340 0.7344340 0.7344340 0.7344340
## [4549] 0.7344340 0.5460074 0.5253979 0.5253979 0.5253979 0.5147942
## [4555] 0.5147942 0.5147942 0.5147942 0.5147942 0.4958383 0.5786940
## [4561] 0.5786940 0.5786940 0.5786940 0.5786940 0.5568026 0.5568026
## [4567] 0.5735661 0.5735661 0.5735661 0.5735661 0.6444768 0.6444768
## [4573] 0.6444768 0.6444768 0.6444768 0.6444768 0.6444768 0.7167541
## [4579] 0.5883630 0.5883630 0.5883630 0.5883630 0.6468437 0.6352702
## [4585] 0.6352702 0.6352702 0.6352702 0.6352702 0.6165434 0.6165434
## [4591] 0.6351614 0.6351614 0.6351614 0.6077828 0.6077828 0.5924229
## [4597] 0.5924229 0.5924229 0.5924229 0.5924229 0.6635952 0.5542755
## [4603] 0.5542755 0.5542755 0.5107063 0.5107063 0.6690556 0.5634775
## [4609] 0.4401196 0.4401196 0.5163266 0.5163266 0.5163266 0.5163266
## [4615] 0.6235238 0.6235238 0.6235238 0.6235238 0.6235238 0.6235238
## [4621] 0.6235238 0.6632602 0.5125435 0.5125435 0.5125435 0.5780563
## [4627] 0.6794385 0.7245192 0.6737173 0.6737173 0.6737173 0.6142964
## [4633] 0.6142964 0.6142964 0.6142964 0.6458555 0.6458555 0.6458555
## [4639] 0.6458555 0.6458555 0.6458555 0.6458555 0.6458555 0.6458555
## [4645] 0.6164394 0.6164394 0.6162916 0.6162916 0.6162916 0.6162916
## [4651] 0.6162916 0.5781836 0.5781836 0.5781836 0.5781836 0.5585611
## [4657] 0.5585611 0.5585611 0.5585611 0.5585611 0.5585611 0.6010326
## [4663] 0.5918121 0.6440511 0.6440511 0.5121834 0.5121834 0.6626412
## [4669] 0.6626412 0.6626412 0.6626412 0.6626412 0.5604245 0.6055465
## [4675] 0.7859298 0.6183212 0.6183212 0.6183212 0.6068442 0.6068442
## [4681] 0.6068442 0.6068442 0.6068442 0.6068442 0.6068442 0.7129572
## [4687] 0.7129572 0.7129572 0.5814512 0.6640981 0.6640981 0.6640981
## [4693] 0.5684769 0.5684769 0.5684769 0.5684769 0.5684769 0.5684769
## [4699] 0.5684769 0.5684769 0.5684769 0.5784760 0.5784760 0.5784760
## [4705] 0.5784760 0.5784760 0.5784760 0.5897899 0.5897899 0.5897899
## [4711] 0.5897899 0.6061490 0.5983973 0.5983973 0.5983973 0.5983973
## [4717] 0.5428852 0.6908842 0.6908842 0.5876029 0.5876029 0.5409107
## [4723] 0.5409107 0.6187601 0.6187601 0.6187601 0.6187601 0.5912109
## [4729] 0.5861810 0.5861810 0.5913678 0.5913678 0.5913678 0.5913678
## [4735] 0.5913678 0.5913678 0.5913678 0.6436712 0.6436712 0.6436712
## [4741] 0.6436712 0.6334609 0.6334609 0.6334609 0.6334609 0.6334609
## [4747] 0.6334609 0.6808089 0.6808089 0.6808089 0.6808089 0.4769664
## [4753] 0.6496131 0.6496131 0.7664220 0.5262317 0.5916658 0.6221320
## [4759] 0.6095746 0.6095746 0.6321078 0.6321078 0.6321078 0.6321078
## [4765] 0.6788313 0.6788313 0.5589736 0.5589736 0.5589736 0.5589736
## [4771] 0.5589736 0.5589736 0.5589736 0.5589736 0.6806747 0.6806747
## [4777] 0.6240847 0.6652378 0.6652378 0.6652378 0.6652557 0.6652557
## [4783] 0.6652557 0.5408575 0.5408575 0.5408575 0.6981574 0.6981574
## [4789] 0.5393328 0.5393328 0.5393328 0.6726811 0.6726811 0.6007702
## [4795] 0.6007702 0.6007702 0.6007702 0.6007702 0.5757781 0.5757781
## [4801] 0.4995907 0.4995907 0.4995907 0.5333510 0.5333510 0.6226732
## [4807] 0.6226732 0.6226732 0.6226732 0.6226732 0.6226732 0.6043676
## [4813] 0.6043676 0.6043676 0.6025955 0.6025955 0.6025955 0.6201654
## [4819] 0.6201654 0.6201654 0.6201654 0.6201654 0.6201654 0.5831293
## [4825] 0.5831293 0.6116536 0.6116536 0.6116536 0.6116536 0.6022291
## [4831] 0.5606030 0.5606030 0.5606030 0.6581800 0.5762106 0.6618851
## [4837] 0.6098598 0.6098598 0.6098598 0.6250880 0.6638054 0.6638054
## [4843] 0.6638054 0.6638054 0.6889441 0.5590402 0.6425984 0.6425984
## [4849] 0.6425984 0.6425984 0.6230094 0.6230094 0.5400236 0.5400236
## [4855] 0.5660835 0.5660835 0.5660835 0.5660835 0.5660835 0.7223035
## [4861] 0.7223035 0.5922607 0.5922607 0.5922607 0.5922607 0.5787046
## [4867] 0.6458533 0.6458533 0.6458533 0.6458533 0.5823640 0.5823640
## [4873] 0.5823640 0.5823640 0.5823640 0.5823640 0.6209036 0.6209036
## [4879] 0.6209036 0.6209036 0.6209036 0.6209036 0.5742404 0.5742404
## [4885] 0.5742404 0.5742404 0.5742404 0.6444854 0.6444854 0.6444854
## [4891] 0.6444854 0.6444854 0.6444854 0.6444854 0.6444854 0.6602449
## [4897] 0.6602449 0.6602449 0.6602449 0.6602449 0.6602449 0.5579387
## [4903] 0.5579387 0.5579387 0.5579387 0.5583397 0.5583397 0.6757562
## [4909] 0.6263458 0.6263458 0.6672016 0.6672016 0.6672016 0.6672016
## [4915] 0.6672016 0.6672016 0.4951717 0.5138466 0.6323340 0.7037620
## [4921] 0.7037620 0.7037620 0.6950489 0.6950489 0.6170725 0.6170725
## [4927] 0.6170725 0.6281561 0.6281561 0.6281561 0.6281561 0.6281561
## [4933] 0.6281561 0.6281561 0.6281561 0.6281561 0.6281561 0.6281561
## [4939] 0.6281561 0.6066788 0.6066788 0.6066788 0.6755066 0.6755066
## [4945] 0.6881926 0.6881926 0.6817018 0.6817018 0.5497927 0.5497927
## [4951] 0.6694845 0.6694845 0.6694845 0.6694845 0.6694845 0.6694845
## [4957] 0.6694845 0.6694845 0.6933355 0.6933355 0.6933355 0.6163983
## [4963] 0.6163983 0.6163983 0.6163983 0.6163983 0.6107501 0.6136497
## [4969] 0.6950654 0.6950654 0.6950654 0.6140102 0.6140102 0.6021406
## [4975] 0.6021406 0.6021406 0.6021406 0.6021406 0.6021406 0.6021406
## [4981] 0.6021406 0.6021406 0.6021406 0.6662402 0.6669374 0.6669374
## [4987] 0.6669374 0.7200059 0.6232079 0.6232079 0.6232079 0.6603988
## [4993] 0.6603988 0.6279635 0.6279635 0.6279635 0.6279635 0.6279635
## [4999] 0.6279635 0.6279635</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xtheta &lt;-<span class="st"> </span>x[(burn<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span>m]
theta.hat &lt;-<span class="st"> </span><span class="kw">mean</span>(xtheta)
theta.hat</code></pre></div>
<pre><code>## [1] 0.6227168</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##the estimate of posterior distribution of theta is shown above.</code></pre></div>
</div>
<div id="question-1-5" class="section level2">
<h2>Question 1</h2>
<p>Write a function to compute the cdf of the Cauchy distribution, which has density<span class="math display">\[\frac{1}{\theta\pi(1+[(x-\eta)/\theta]^2)},-\infty&lt;x&lt;\infty\]</span> where<span class="math inline">\(\theta&gt;0\)</span>. Compare your results to the results from the R function pcauchy.(Also see the source code in pcauchy.c.)</p>
</div>
<div id="answer-19" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
q &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">222</span>,<span class="op">-</span><span class="dv">22</span>,<span class="op">-</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">44</span>,<span class="dv">444</span>,<span class="ot">Inf</span>)
m &lt;-<span class="kw">length</span>(q)
CDF &lt;-<span class="st"> </span><span class="kw">numeric</span>(m) <span class="co">#for CDF with different p</span>
eta &lt;-<span class="st"> </span><span class="dv">0</span>;theta &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co">#the location parameter and the scale parameter of Cauchy density</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(x, eta, theta) {
<span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>((x<span class="op">-</span>eta)<span class="op">/</span>theta)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>theta<span class="op">/</span>pi
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m ){
  
CDF[i] &lt;-<span class="st"> </span><span class="kw">integrate</span>(f,<span class="dt">lower=</span><span class="op">-</span><span class="ot">Inf</span>,<span class="dt">upper=</span>q[i],<span class="dt">rel.tol=</span>.Machine<span class="op">$</span>double.eps<span class="op">^</span><span class="fl">0.25</span>,<span class="dt">eta=</span>eta,<span class="dt">theta=</span>theta)<span class="op">$</span>value
}
pcauchy &lt;-<span class="st"> </span><span class="kw">pcauchy</span>(q,<span class="dt">location =</span> eta, <span class="dt">scale =</span> theta)
<span class="kw">data.frame</span>(q,pcauchy,CDF)</code></pre></div>
<pre><code>##      q     pcauchy         CDF
## 1 -222 0.001433819 0.001433819
## 2  -22 0.014458679 0.014458679
## 3   -2 0.147583618 0.147583618
## 4    0 0.500000000 0.500000000
## 5    4 0.922020870 0.922020870
## 6   44 0.992766930 0.992766930
## 7  444 0.999283087 0.999283087
## 8  Inf 1.000000000 1.000000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##As the result shows above, the caculated CDF is the same to the results of pcauchy function with different q.</code></pre></div>
</div>
<div id="question-2-5" class="section level2">
<h2>Question 2</h2>
<p>A-B-O blood type problem <span class="math inline">\(\blacktriangleright\)</span> Let the three alleles be A, B, and O.</p>
<p>Genotype AA <span class="math inline">\(~~\)</span> BB <span class="math inline">\(~~\)</span> OO <span class="math inline">\(~~\)</span> AO <span class="math inline">\(~~\)</span> BO <span class="math inline">\(~~\)</span> AB</p>
<p>Frequency p2 <span class="math inline">\(~~\)</span> q2 <span class="math inline">\(~~\)</span> r2 <span class="math inline">\(~~\)</span> 2pr <span class="math inline">\(~~\)</span> 2qr <span class="math inline">\(~~\)</span> 2pq <span class="math inline">\(~~\)</span> 1</p>
<p>Count <span class="math inline">\(~~~~~n_{AA}\)</span> <span class="math inline">\(n_{BB}\)</span> <span class="math inline">\(n_{OO}\)</span> <span class="math inline">\(n_{AO}\)</span> <span class="math inline">\(n_{BO}\)</span> <span class="math inline">\(n_{AB}~~\)</span> n</p>
<p><span class="math inline">\(\blacktriangleright\)</span> Observed data: <span class="math inline">\(n_{A??} = n_{AA} + n_{AO} = 28 ~~~(A-type),\)</span></p>
<p><span class="math inline">\(n_{B??} = n_{BB} + n_{BO} = 24 ~~(B-type), n_{OO} = 41~~ (O-type), n_{AB} = 70 ~~(AB-type).\)</span></p>
<p><span class="math inline">\(\blacktriangleright\)</span> Use EM algorithm to solve MLE of p and q (consider missing data <span class="math inline">\(n_{AA} and n_{BB}\)</span>).</p>
<p><span class="math inline">\(\blacktriangleright\)</span> Record the maximum likelihood values in M-steps, are they increasing?</p>
</div>
<div id="answer-20" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#declare the varibles</span>
nA &lt;-<span class="st"> </span><span class="dv">28</span>;nB &lt;-<span class="st"> </span><span class="dv">24</span>;nAB &lt;-<span class="st"> </span><span class="dv">70</span>;nOO &lt;-<span class="st"> </span><span class="dv">41</span> <span class="co">#observed data</span>
L &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.3</span>,<span class="fl">0.2</span>) <span class="co">#initial values for p q </span>
tol &lt;-<span class="st"> </span>.Machine<span class="op">$</span>double.eps<span class="op">^</span><span class="fl">0.5</span> <span class="co"># for caculation accuracy</span>
n &lt;-<span class="st"> </span><span class="dv">10000</span> <span class="co">#max. number of iterations</span>
EI &lt;-<span class="st"> </span>M &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)<span class="co"># for the values of &quot;M-step&quot;</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span>L[<span class="dv">1</span>];q &lt;-<span class="st"> </span>L[<span class="dv">2</span>]   <span class="co">#initial values</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
  a&lt;-p<span class="op">/</span>(<span class="dv">2</span><span class="op">-</span>p<span class="op">-</span><span class="dv">2</span><span class="op">*</span>q)
  b&lt;-q<span class="op">/</span>(<span class="dv">2</span><span class="op">-</span><span class="dv">2</span><span class="op">*</span>p<span class="op">-</span>q)
  fp=nA<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>a)<span class="op">+</span>nAB
  fq=nB<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>b)<span class="op">+</span>nAB
  fpq=nA<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>a)<span class="op">+</span>nB<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>b)<span class="op">+</span><span class="dv">2</span><span class="op">*</span>nOO
  
  M[i]&lt;-fp<span class="op">*</span><span class="kw">log</span>(p)<span class="op">+</span>fpq<span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>p<span class="op">-</span>q)<span class="op">+</span>fq<span class="op">*</span><span class="kw">log</span>(q) <span class="co">#Record the    maximum likelihood values in M-steps</span>
  
  x&lt;-p; y&lt;-q                <span class="co">#store ith values of p and q</span>
  p&lt;-fp<span class="op">/</span>(fp<span class="op">+</span>fq<span class="op">+</span>fpq); q&lt;-fq<span class="op">/</span>(fp<span class="op">+</span>fq<span class="op">+</span>fpq) <span class="co">#update the parameters</span>
  <span class="co">#k&lt;-k+1     #the times until converge</span>
  <span class="cf">if</span> (<span class="kw">abs</span>(p<span class="op">-</span>x)<span class="op">/</span>x<span class="op">&lt;</span>tol <span class="op">&amp;&amp;</span><span class="st"> </span><span class="kw">abs</span>(q<span class="op">-</span>y)<span class="op">/</span>y<span class="op">&lt;</span>tol) <span class="cf">break</span>  <span class="co">#control the iterations</span>
  p.hat&lt;-p; q.hat&lt;-q
 
}
EI&lt;-M[<span class="dv">1</span><span class="op">:</span>i]<span class="co">#the values of &quot;M-step&quot;</span>
<span class="kw">data.frame</span>(p.hat,q.hat)</code></pre></div>
<pre><code>##       p.hat     q.hat
## 1 0.3273442 0.3104267</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##the estimates of p q is shown above.</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">i ##the times until converge</code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span>EI </code></pre></div>
<pre><code>##  [1] 369.1241 357.5134 357.4589 357.4683 357.4700 357.4703 357.4703
##  [8] 357.4703 357.4703 357.4703</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,i,<span class="dv">1</span>)
<span class="kw">plot</span>(x,EI)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##the maximum likelihood values in M-steps are  increasing</code></pre></div>
</div>
<div id="question-1-6" class="section level2">
<h2>Question 1</h2>
<p>Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">formulas &lt;-<span class="st"> </span><span class="kw">list</span>(
mpg <span class="op">~</span><span class="st"> </span>disp,
mpg <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>disp),
mpg <span class="op">~</span><span class="st"> </span>disp <span class="op">+</span><span class="st"> </span>wt,
mpg <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>disp) <span class="op">+</span><span class="st"> </span>wt
)</code></pre></div>
</div>
<div id="answer-21" class="section level2">
<h2>Answer</h2>
<p>For loops</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> out_formulas &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">'list'</span>, <span class="kw">length</span>(formulas))
   <span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(formulas)) {
       out_formulas[[i]] &lt;-<span class="st"> </span><span class="kw">lm</span>(formulas[[i]], <span class="dt">data =</span> mtcars)
   }
   out_formulas</code></pre></div>
<pre><code>## [[1]]
## 
## Call:
## lm(formula = formulas[[i]], data = mtcars)
## 
## Coefficients:
## (Intercept)         disp  
##    29.59985     -0.04122  
## 
## 
## [[2]]
## 
## Call:
## lm(formula = formulas[[i]], data = mtcars)
## 
## Coefficients:
## (Intercept)    I(1/disp)  
##       10.75      1557.67  
## 
## 
## [[3]]
## 
## Call:
## lm(formula = formulas[[i]], data = mtcars)
## 
## Coefficients:
## (Intercept)         disp           wt  
##    34.96055     -0.01772     -3.35083  
## 
## 
## [[4]]
## 
## Call:
## lm(formula = formulas[[i]], data = mtcars)
## 
## Coefficients:
## (Intercept)    I(1/disp)           wt  
##      19.024     1142.560       -1.798</code></pre>
<p>lapply()</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lapply</span>(formulas, lm, <span class="dt">data =</span> mtcars)</code></pre></div>
<pre><code>## [[1]]
## 
## Call:
## FUN(formula = X[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)         disp  
##    29.59985     -0.04122  
## 
## 
## [[2]]
## 
## Call:
## FUN(formula = X[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)    I(1/disp)  
##       10.75      1557.67  
## 
## 
## [[3]]
## 
## Call:
## FUN(formula = X[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)         disp           wt  
##    34.96055     -0.01772     -3.35083  
## 
## 
## [[4]]
## 
## Call:
## FUN(formula = X[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)    I(1/disp)           wt  
##      19.024     1142.560       -1.798</code></pre>
</div>
<div id="question-2-6" class="section level2">
<h2>Question 2</h2>
<p>Fit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below by using a for loop and lapply().Can you do it without an anonymous function?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bootstraps &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) {
rows &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(mtcars), <span class="dt">rep =</span> <span class="ot">TRUE</span>)
mtcars[rows, ]
})</code></pre></div>
</div>
<div id="answer-22" class="section level2">
<h2>Answer</h2>
<p>for loops</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out_bootstrap &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">'list'</span>, <span class="kw">length</span>(bootstraps))
   <span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(bootstraps)) {
       out_bootstrap[[i]] &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg<span class="op">~</span>disp, <span class="dt">data =</span> bootstraps[[i]])
   }
   out_bootstrap</code></pre></div>
<pre><code>## [[1]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.80773     -0.03727  
## 
## 
## [[2]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     30.0288      -0.0414  
## 
## 
## [[3]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    28.21033     -0.03938  
## 
## 
## [[4]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.27404     -0.04105  
## 
## 
## [[5]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    28.40443     -0.03625  
## 
## 
## [[6]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    31.85595     -0.05339  
## 
## 
## [[7]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.56716     -0.04323  
## 
## 
## [[8]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    30.16414     -0.04504  
## 
## 
## [[9]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     31.4601      -0.0474  
## 
## 
## [[10]]
## 
## Call:
## lm(formula = mpg ~ disp, data = bootstraps[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     30.6666      -0.0445</code></pre>
<p>lapply()</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">lapply</span>(bootstraps, lm, <span class="dt">formula =</span> mpg<span class="op">~</span>disp)</code></pre></div>
<pre><code>## [[1]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.80773     -0.03727  
## 
## 
## [[2]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     30.0288      -0.0414  
## 
## 
## [[3]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    28.21033     -0.03938  
## 
## 
## [[4]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.27404     -0.04105  
## 
## 
## [[5]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    28.40443     -0.03625  
## 
## 
## [[6]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    31.85595     -0.05339  
## 
## 
## [[7]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    29.56716     -0.04323  
## 
## 
## [[8]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##    30.16414     -0.04504  
## 
## 
## [[9]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     31.4601      -0.0474  
## 
## 
## [[10]]
## 
## Call:
## FUN(formula = ..1, data = X[[i]])
## 
## Coefficients:
## (Intercept)         disp  
##     30.6666      -0.0445</code></pre>
</div>
<div id="question-3-4" class="section level2">
<h2>Question 3</h2>
<p>For each model in the previous two exercises, extract R2 using the function below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rsq &lt;-<span class="st"> </span><span class="cf">function</span>(mod) <span class="kw">summary</span>(mod)<span class="op">$</span>r.squared</code></pre></div>
</div>
<div id="answer-23" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lapply</span>(out_formulas, rsq)</code></pre></div>
<pre><code>## [[1]]
## [1] 0.7183433
## 
## [[2]]
## [1] 0.8596865
## 
## [[3]]
## [1] 0.7809306
## 
## [[4]]
## [1] 0.8838038</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lapply</span>(out_bootstrap, rsq)</code></pre></div>
<pre><code>## [[1]]
## [1] 0.6686576
## 
## [[2]]
## [1] 0.7890333
## 
## [[3]]
## [1] 0.8116387
## 
## [[4]]
## [1] 0.6129198
## 
## [[5]]
## [1] 0.6668057
## 
## [[6]]
## [1] 0.706948
## 
## [[7]]
## [1] 0.6042403
## 
## [[8]]
## [1] 0.7926823
## 
## [[9]]
## [1] 0.8304639
## 
## [[10]]
## [1] 0.6723284</code></pre>
</div>
<div id="question-4-3" class="section level2">
<h2>Question 4</h2>
<p>The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trials &lt;-<span class="st"> </span><span class="kw">replicate</span>(
<span class="dv">100</span>,
<span class="kw">t.test</span>(<span class="kw">rpois</span>(<span class="dv">10</span>, <span class="dv">10</span>), <span class="kw">rpois</span>(<span class="dv">7</span>, <span class="dv">10</span>)),
<span class="dt">simplify =</span> <span class="ot">FALSE</span>
)</code></pre></div>
<p>Extra challenge: get rid of the anonymous function by using [[ directly.</p>
</div>
<div id="answer-24" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sapply</span>(trials, <span class="cf">function</span>(mod) mod<span class="op">$</span>p.value)</code></pre></div>
<pre><code>##   [1] 0.933072580 0.618953383 0.942073405 0.193798815 0.444068133
##   [6] 0.002598581 0.092756759 0.883504364 0.326336671 0.270886628
##  [11] 0.342089422 0.800529866 0.867669794 0.324694584 0.636548159
##  [16] 0.327085189 0.656376022 0.021375253 0.530652804 0.169211959
##  [21] 0.979291855 0.485105423 0.468224795 0.170489016 0.330892025
##  [26] 0.834380887 0.165173976 0.053761844 0.126676886 0.001210360
##  [31] 0.702417848 0.720555589 0.398574027 0.447662966 0.826263756
##  [36] 0.107905279 0.189739388 0.159376215 0.810961349 0.647785543
##  [41] 0.522316012 0.496859331 0.398541433 0.885543258 0.345979148
##  [46] 0.903662801 0.899269809 0.435484295 0.101222534 0.900360359
##  [51] 0.827640244 0.011946256 0.675886595 0.306849081 0.241652207
##  [56] 0.762387058 0.855655105 0.424268825 0.922714135 0.500802132
##  [61] 0.754655660 0.990624671 0.055288465 0.271851602 0.022082298
##  [66] 0.235912739 0.030257561 0.876457846 0.039883956 0.004150275
##  [71] 0.650624910 0.805700235 0.403066276 0.232500580 0.329012061
##  [76] 0.660466807 0.747080236 0.280432440 0.394342935 0.335170856
##  [81] 0.929993039 0.195571616 0.696747784 0.791389423 0.490980460
##  [86] 0.435381465 0.045913818 0.768196505 0.178611321 0.650810533
##  [91] 0.299008431 0.205624115 0.693690387 0.128106993 0.111436310
##  [96] 0.575039133 0.933328198 0.664945649 0.023161890 0.523574061</code></pre>
<p>Extra challenge:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sapply</span>(trials, <span class="st">`</span><span class="dt">[[</span><span class="st">`</span>, <span class="st">'p.value'</span>)</code></pre></div>
<pre><code>##   [1] 0.933072580 0.618953383 0.942073405 0.193798815 0.444068133
##   [6] 0.002598581 0.092756759 0.883504364 0.326336671 0.270886628
##  [11] 0.342089422 0.800529866 0.867669794 0.324694584 0.636548159
##  [16] 0.327085189 0.656376022 0.021375253 0.530652804 0.169211959
##  [21] 0.979291855 0.485105423 0.468224795 0.170489016 0.330892025
##  [26] 0.834380887 0.165173976 0.053761844 0.126676886 0.001210360
##  [31] 0.702417848 0.720555589 0.398574027 0.447662966 0.826263756
##  [36] 0.107905279 0.189739388 0.159376215 0.810961349 0.647785543
##  [41] 0.522316012 0.496859331 0.398541433 0.885543258 0.345979148
##  [46] 0.903662801 0.899269809 0.435484295 0.101222534 0.900360359
##  [51] 0.827640244 0.011946256 0.675886595 0.306849081 0.241652207
##  [56] 0.762387058 0.855655105 0.424268825 0.922714135 0.500802132
##  [61] 0.754655660 0.990624671 0.055288465 0.271851602 0.022082298
##  [66] 0.235912739 0.030257561 0.876457846 0.039883956 0.004150275
##  [71] 0.650624910 0.805700235 0.403066276 0.232500580 0.329012061
##  [76] 0.660466807 0.747080236 0.280432440 0.394342935 0.335170856
##  [81] 0.929993039 0.195571616 0.696747784 0.791389423 0.490980460
##  [86] 0.435381465 0.045913818 0.768196505 0.178611321 0.650810533
##  [91] 0.299008431 0.205624115 0.693690387 0.128106993 0.111436310
##  [96] 0.575039133 0.933328198 0.664945649 0.023161890 0.523574061</code></pre>
</div>
<div id="question-5" class="section level2">
<h2>Question 5</h2>
<p>Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?</p>
</div>
<div id="answer-25" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">library</span>(parallel)
   mcvMap &lt;-<span class="st"> </span><span class="cf">function</span>(f, FUN.VALUE , ...) {
       out &lt;-<span class="st"> </span><span class="kw">mcMap</span>(f, ...)
       <span class="kw">vapply</span>(out, identity, FUN.VALUE)
   }</code></pre></div>
</div>
<div id="question-1-7" class="section level2">
<h2>Question 1</h2>
<p>Make a faster version of chisq.test() that only computes the chi-square test statistic when the input is two numeric vectors with no missing values. You can try simplifying chisq.test()or by coding from the mathematical definition(<a href="http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test">http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test</a>).</p>
</div>
<div id="answer-26" class="section level2">
<h2>Answer</h2>
<table>
<thead>
<tr class="header">
<th>n_11</th>
<th>n_12</th>
<th>n_13</th>
<th>n_14</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n_21</td>
<td>n_22</td>
<td>n_23</td>
<td>n_24</td>
</tr>
</tbody>
</table>
<p>the <span class="math inline">\(X^2=\sum_{i=1}^{2}\sum_{j=1}^{4}(n_ij-n_{i??}n_{??j}/n)^2/(n_{i??}n_{??j}/n)\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">expected &lt;-<span class="st"> </span><span class="cf">function</span>(colsum, rowsum, total) {
  (colsum <span class="op">/</span><span class="st"> </span>total) <span class="op">*</span><span class="st"> </span>(rowsum <span class="op">/</span><span class="st"> </span>total) <span class="op">*</span><span class="st"> </span>total
}                      <span class="co">#for $n_{i??}n_{??j}/n$</span>

chi_stat &lt;-<span class="st"> </span><span class="cf">function</span>(observed, expected) {
  ((observed <span class="op">-</span><span class="st"> </span>expected) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>expected
}


chisq_test2 &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) {<span class="co">#x for the first row, y for the second row</span>
  total &lt;-<span class="st"> </span><span class="kw">sum</span>(x) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(y)
  rowsum_x &lt;-<span class="st"> </span><span class="kw">sum</span>(x)
  rowsum_y &lt;-<span class="st"> </span><span class="kw">sum</span>(y)
  chistat &lt;-<span class="st"> </span><span class="dv">0</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x)) {
    colsum &lt;-<span class="st"> </span>x[i] <span class="op">+</span><span class="st"> </span>y[i]
    expected_x &lt;-<span class="st"> </span><span class="kw">expected</span>(colsum, rowsum_x, total)
    expected_y &lt;-<span class="st"> </span><span class="kw">expected</span>(colsum, rowsum_y, total)
    chistat &lt;-<span class="st"> </span>chistat <span class="op">+</span><span class="st"> </span><span class="kw">chi_stat</span>(x[i], expected_x) 
    chistat &lt;-<span class="st"> </span>chistat <span class="op">+</span><span class="st"> </span><span class="kw">chi_stat</span>(y[i], expected_y)
  }
  chistat
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#examples of the use of the new chisq_test2</span>

<span class="kw">print</span>(<span class="kw">chisq_test2</span>(<span class="kw">seq</span>(<span class="dv">3</span>, <span class="dv">8</span>), <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">9</span>)))</code></pre></div>
<pre><code>## [1] 0.04762132</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">chisq.test</span>(<span class="kw">seq</span>(<span class="dv">3</span>, <span class="dv">8</span>), <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">9</span>)))</code></pre></div>
<pre><code>## Warning in chisq.test(seq(3, 8), seq(4, 9)): Chi-squared approximation may
## be incorrect</code></pre>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  seq(3, 8) and seq(4, 9)
## X-squared = 30, df = 25, p-value = 0.2243</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##there is a doubt that the value of chisq from the new chisq_test is much different from the chisq.test function</code></pre></div>
</div>
<div id="question-2-7" class="section level2">
<h2>Question 2</h2>
<p>Can you make a faster version of table() for the case of an input of two integer vectors with no missing values? Can you use it to speed up your chi-square test?</p>
</div>
<div id="answer-27" class="section level2">
<h2>Answer</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">table2 &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) {
  x_val &lt;-<span class="st"> </span><span class="kw">unique</span>(x)
  y_val &lt;-<span class="st"> </span><span class="kw">unique</span>(y)
  mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(0L, <span class="kw">length</span>(x_val), <span class="kw">length</span>(y_val))
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x)) {
    mat[<span class="kw">which</span>(x_val <span class="op">==</span><span class="st"> </span>x[[i]]), <span class="kw">which</span>(y_val <span class="op">==</span><span class="st"> </span>y[[i]])] &lt;-
<span class="st">      </span>mat[<span class="kw">which</span>(x_val <span class="op">==</span><span class="st"> </span>x[[i]]),  <span class="kw">which</span>(y_val <span class="op">==</span><span class="st"> </span>y[[i]])] <span class="op">+</span><span class="st"> </span>1L
  }
  dimnames &lt;-<span class="st"> </span><span class="kw">list</span>(x_val, y_val)
  <span class="kw">names</span>(dimnames) &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="kw">as.list</span>(<span class="kw">match.call</span>())[<span class="op">-</span><span class="dv">1</span>])  <span class="co"># R has names for dimnames... :/</span>
  tab &lt;-<span class="st"> </span><span class="kw">array</span>(mat, <span class="dt">dim =</span> <span class="kw">dim</span>(mat), <span class="dt">dimnames =</span> dimnames)
  <span class="kw">class</span>(tab) &lt;-<span class="st"> &quot;table&quot;</span>
  tab
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#examples of the use of the new table2()</span>
a &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(a, a), <span class="kw">table2</span>(a, a))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(a, b), <span class="kw">table2</span>(a, b))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)
d &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(c, d), <span class="kw">table2</span>(c, d))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">e &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(a, e), <span class="kw">table2</span>(a, e))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(<span class="kw">table</span>(b, e), <span class="kw">table2</span>(b, e))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(<span class="kw">table</span>(e, e), <span class="kw">table2</span>(e, e))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(f, f), <span class="kw">table2</span>(f, f))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(<span class="kw">table</span>(e, f), <span class="kw">table2</span>(e, f))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">9</span>)
<span class="kw">identical</span>(<span class="kw">table</span>(g, g), <span class="kw">table2</span>(g, g))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(<span class="kw">table</span>(g, f), <span class="kw">table2</span>(g, f))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>apply table2() to chisq_test2</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">expected &lt;-<span class="st"> </span><span class="cf">function</span>(colsum, rowsum, total) {
  (colsum <span class="op">/</span><span class="st"> </span>total) <span class="op">*</span><span class="st"> </span>(rowsum <span class="op">/</span><span class="st"> </span>total) <span class="op">*</span><span class="st"> </span>total
}                      <span class="co">#for $n_{i??}n_{??j}/n$</span>

chi_stat &lt;-<span class="st"> </span><span class="cf">function</span>(observed, expected) {
  ((observed <span class="op">-</span><span class="st"> </span>expected) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>expected
}
x &lt;-<span class="st"> </span>y &lt;-<span class="st"> </span><span class="ot">NULL</span>
z &lt;-<span class="st"> </span><span class="kw">table2</span>(x,y)
chisq_test3 &lt;-<span class="st"> </span><span class="cf">function</span>(z) {<span class="co">#x for the first row, y for the second row</span>
  total &lt;-<span class="st"> </span><span class="kw">sum</span>(x) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(y)
  rowsum_x &lt;-<span class="st"> </span><span class="kw">sum</span>(x)
  rowsum_y &lt;-<span class="st"> </span><span class="kw">sum</span>(y)
  chistat &lt;-<span class="st"> </span><span class="dv">0</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x)) {
    colsum &lt;-<span class="st"> </span>x[i] <span class="op">+</span><span class="st"> </span>y[i]
    expected_x &lt;-<span class="st"> </span><span class="kw">expected</span>(colsum, rowsum_x, total)
    expected_y &lt;-<span class="st"> </span><span class="kw">expected</span>(colsum, rowsum_y, total)
    chistat &lt;-<span class="st"> </span>chistat <span class="op">+</span><span class="st"> </span><span class="kw">chi_stat</span>(x[i], expected_x) 
    chistat &lt;-<span class="st"> </span>chistat <span class="op">+</span><span class="st"> </span><span class="kw">chi_stat</span>(y[i], expected_y)
  }
  chistat
}</code></pre></div>
<p>compare the time</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">3</span>, <span class="dv">8</span>)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">9</span>)
<span class="kw">system.time</span>(<span class="kw">print</span>((<span class="kw">chisq_test2</span>(x, y))))</code></pre></div>
<pre><code>## [1] 0.04762132</code></pre>
<pre><code>## 用户 系统 流逝 
## 0.03 0.00 0.03</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(<span class="kw">print</span>(<span class="kw">chisq_test3</span>(<span class="kw">table2</span>(x, y))))</code></pre></div>
<pre><code>## [1] 0.04762132</code></pre>
<pre><code>## 用户 系统 流逝 
##    0    0    0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##we can see that the new table function dose speed up the new chisq_test function</code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
